{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:16<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to USE IT AS A KEY later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        code2convos[file_code] = convo_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user',\n",
      "  'text': 'Load a CSV file into a Pandas in Python. The file is named '\n",
      "          \"'cs412_hw1_dataset.csv' and contains columns like 'Species', \"\n",
      "          \"'Island', 'Sex', 'Diet', 'Year', 'Life Stage', 'Body Mass (g)', \"\n",
      "          \"'Bill Length (mm)', 'Bill Depth (mm)', 'Flipper Length (mm)', and \"\n",
      "          \"'Health Metrics'. \\n\"},\n",
      " {'role': 'assistant',\n",
      "  'text': 'You can load a CSV file into a Pandas DataFrame in Python using the '\n",
      "          \"pandas.read_csv() function. Here's how you can do it for your \"\n",
      "          'specific CSV file:pythonCopy codeimport pandas as pd\\n'\n",
      "          '\\n'\n",
      "          '# Specify the file path\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          '\\n'\n",
      "          '# Load the CSV file into a Pandas DataFrame\\n'\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# Display the first few rows of the DataFrame to verify the data '\n",
      "          'has been loaded\\n'\n",
      "          'print(df.head())\\n'\n",
      "          \"This code assumes that the CSV file 'cs412_hw1_dataset.csv' is in \"\n",
      "          'the same directory as your Python script or Jupyter Notebook. If '\n",
      "          'the file is in a different directory, you can specify the full path '\n",
      "          'to the file in the file_path variable.The pd.read_csv() function '\n",
      "          'will automatically infer the column names from the first row of the '\n",
      "          \"CSV file, so you don't need to explicitly specify the column names \"\n",
      "          'unless they are different from what you provided. You can access '\n",
      "          \"columns in the DataFrame using their names, e.g., df['Species'], \"\n",
      "          \"df['Island'], etc.\"},\n",
      " {'role': 'user',\n",
      "  'text': 'Provide Python code to understand a dataset using Pandas. Find the '\n",
      "          'shape of the dataset, display variable names, display a summary of '\n",
      "          'the dataset with the info() function, and show the first 5 rows '\n",
      "          'using the head() function.\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'You can use Pandas to understand a dataset by performing various '\n",
      "          \"exploratory data analysis (EDA) tasks. Here's a Python code snippet \"\n",
      "          'that accomplishes the tasks you mentioned:pythonCopy codeimport '\n",
      "          'pandas as pd\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# 1. Find the shape of the dataset\\n'\n",
      "          'shape = df.shape\\n'\n",
      "          'print(\"Shape of the dataset (rows, columns):\", shape)\\n'\n",
      "          '\\n'\n",
      "          '# 2. Display variable names (column names)\\n'\n",
      "          'variable_names = df.columns\\n'\n",
      "          'print(\"Variable names (column names):\")\\n'\n",
      "          'for name in variable_names:\\n'\n",
      "          '    print(name)\\n'\n",
      "          '\\n'\n",
      "          '# 3. Display a summary of the dataset with the info() function\\n'\n",
      "          'print(\"\\\\nSummary of the dataset:\")\\n'\n",
      "          'df.info()\\n'\n",
      "          '\\n'\n",
      "          '# 4. Show the first 5 rows using the head() function\\n'\n",
      "          'print(\"\\\\nFirst 5 rows of the dataset:\")\\n'\n",
      "          'print(df.head())\\n'\n",
      "          \"Here's a breakdown of what each part of the code does:It calculates \"\n",
      "          'and prints the shape of the dataset using df.shape, which gives you '\n",
      "          'the number of rows and columns in the DataFrame.It retrieves and '\n",
      "          'prints the variable names (column names) using df.columns.It '\n",
      "          'displays a summary of the dataset, including information about the '\n",
      "          'data types, non-null counts, and memory usage, using the df.info() '\n",
      "          'function.Finally, it displays the first 5 rows of the dataset using '\n",
      "          'df.head() to provide a glimpse of the data.You can run this code to '\n",
      "          'get an initial understanding of your dataset using Pandas.'},\n",
      " {'role': 'user',\n",
      "  'text': 'You will preprocess the data now\\n'\n",
      "          '1. Check for missing values and handle them by either dropping or '\n",
      "          'filling them with the most common values. Ensure that there is '\n",
      "          'enough data for training the model. You can only use %80 data for '\n",
      "          'training and %20 for testing\\n'\n",
      "          '2. Encode labels with mappings using the map function. Mapping '\n",
      "          'names: \\n'\n",
      "          \"   - sex_map = {'female': 1, 'male': 0}\\n\"\n",
      "          \"   - island_map = {'Biscoe': 1, 'Dream': 2, 'Torgensen': 3}\\n\"\n",
      "          \"   - diet_map = {'fish': 1, 'krill': 2, 'squid': 3, 'parental': 4}\\n\"\n",
      "          \"   - life_stage_map = {'chick': 1, 'juvenile': 2, 'adult': 3}\\n\"\n",
      "          \"   - health_metrics_map = {'healthy': 1, 'overweight': 2, \"\n",
      "          \"'underweight': 3}\\n\"\n",
      "          \"The dataset named 'df'.\"},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To preprocess the dataset as per your requirements, you can follow '\n",
      "          'these steps:Check for missing values and handle them.Encode labels '\n",
      "          'with mappings using the map function.Split the data into training '\n",
      "          \"(80%) and testing (20%) sets.Here's the Python code to achieve \"\n",
      "          'this:pythonCopy codeimport pandas as pd\\n'\n",
      "          'from sklearn.model_selection import train_test_split\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# 1. Check for missing values and handle them\\n'\n",
      "          '# You can either drop rows with missing values or fill them with '\n",
      "          'the most common value in the column.\\n'\n",
      "          \"# In this example, we'll fill missing values with the most common \"\n",
      "          'value in each column.\\n'\n",
      "          '\\n'\n",
      "          \"# Fill missing values in the 'Sex' column with the most common \"\n",
      "          'value\\n'\n",
      "          \"most_common_sex = df['Sex'].mode()[0]\\n\"\n",
      "          \"df['Sex'].fillna(most_common_sex, inplace=True)\\n\"\n",
      "          '\\n'\n",
      "          \"# Fill missing values in the 'Island' column with the most common \"\n",
      "          'value\\n'\n",
      "          \"most_common_island = df['Island'].mode()[0]\\n\"\n",
      "          \"df['Island'].fillna(most_common_island, inplace=True)\\n\"\n",
      "          '\\n'\n",
      "          \"# Fill missing values in the 'Diet' column with the most common \"\n",
      "          'value\\n'\n",
      "          \"most_common_diet = df['Diet'].mode()[0]\\n\"\n",
      "          \"df['Diet'].fillna(most_common_diet, inplace=True)\\n\"\n",
      "          '\\n'\n",
      "          \"# Fill missing values in the 'Life Stage' column with the most \"\n",
      "          'common value\\n'\n",
      "          \"most_common_life_stage = df['Life Stage'].mode()[0]\\n\"\n",
      "          \"df['Life Stage'].fillna(most_common_life_stage, inplace=True)\\n\"\n",
      "          '\\n'\n",
      "          \"# Fill missing values in the 'Health Metrics' column with the most \"\n",
      "          'common value\\n'\n",
      "          \"most_common_health_metrics = df['Health Metrics'].mode()[0]\\n\"\n",
      "          \"df['Health Metrics'].fillna(most_common_health_metrics, \"\n",
      "          'inplace=True)\\n'\n",
      "          '\\n'\n",
      "          '# 2. Encode labels with mappings\\n'\n",
      "          \"sex_map = {'female': 1, 'male': 0}\\n\"\n",
      "          \"island_map = {'Biscoe': 1, 'Dream': 2, 'Torgensen': 3}\\n\"\n",
      "          \"diet_map = {'fish': 1, 'krill': 2, 'squid': 3, 'parental': 4}\\n\"\n",
      "          \"life_stage_map = {'chick': 1, 'juvenile': 2, 'adult': 3}\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          '\\n'\n",
      "          \"df['Sex'] = df['Sex'].map(sex_map)\\n\"\n",
      "          \"df['Island'] = df['Island'].map(island_map)\\n\"\n",
      "          \"df['Diet'] = df['Diet'].map(diet_map)\\n\"\n",
      "          \"df['Life Stage'] = df['Life Stage'].map(life_stage_map)\\n\"\n",
      "          \"df['Health Metrics'] = df['Health \"\n",
      "          \"Metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# 3. Split the data into training (80%) and testing (20%) sets\\n'\n",
      "          \"X = df.drop(columns=['Species'])  # Features (excluding 'Species' \"\n",
      "          'column)\\n'\n",
      "          \"y = df['Species']  # Target variable ('Species' column)\\n\"\n",
      "          '\\n'\n",
      "          'X_train, X_test, y_train, y_test = train_test_split(X, y, '\n",
      "          'test_size=0.2, random_state=42)\\n'\n",
      "          '\\n'\n",
      "          '# Now, you can use X_train, X_test, y_train, and y_test for '\n",
      "          'training and testing your machine learning model.\\n'\n",
      "          'This code performs the following steps:Handles missing values by '\n",
      "          'filling them with the most common values in each respective '\n",
      "          'column.Encodes categorical labels with mappings provided.Splits the '\n",
      "          'dataset into training (80%) and testing (20%) sets using '\n",
      "          'train_test_split from scikit-learn, allowing you to use the data '\n",
      "          'for training and testing your machine learning model.'},\n",
      " {'role': 'user',\n",
      "  'text': 'You already provide code for this but please recreate that part for '\n",
      "          'shuffling if needed. \\n'\n",
      "          \"1. Shuffle dataframe named 'df'.\\n\"\n",
      "          \"2. Separate the dataset into a feature matrix 'X' and a target \"\n",
      "          \"vector 'y'. The column 'health_metrics' is y, and all other columns \"\n",
      "          'should be included in X.\\n'\n",
      "          '3. Split the data into training and test sets with 80% of the data '\n",
      "          'for training and 20% for testing. \\n'\n",
      "          'Ensure that the splitting is random.\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': \"Certainly, here's the code to shuffle the DataFrame, separate it \"\n",
      "          \"into feature matrix 'X' and target vector 'y', and split the data \"\n",
      "          'into training and test sets with random shuffling:pythonCopy '\n",
      "          'codeimport pandas as pd\\n'\n",
      "          'from sklearn.model_selection import train_test_split\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# 1. Shuffle the DataFrame\\n'\n",
      "          'df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # '\n",
      "          'Shuffle with random_state for reproducibility\\n'\n",
      "          '\\n'\n",
      "          \"# 2. Separate the dataset into feature matrix 'X' and target vector \"\n",
      "          \"'y'\\n\"\n",
      "          \"X = df.drop(columns=['Health Metrics'])  # Features (excluding \"\n",
      "          \"'Health Metrics' column)\\n\"\n",
      "          \"y = df['Health Metrics']  # Target variable ('Health Metrics' \"\n",
      "          'column)\\n'\n",
      "          '\\n'\n",
      "          '# 3. Split the data into training and test sets with 80% for '\n",
      "          'training and 20% for testing\\n'\n",
      "          'X_train, X_test, y_train, y_test = train_test_split(X, y, '\n",
      "          'test_size=0.2, random_state=42)\\n'\n",
      "          '\\n'\n",
      "          '# Now, you have shuffled data in X_train, X_test, y_train, and '\n",
      "          'y_test for training and testing your machine learning model.\\n'\n",
      "          'In this code:We shuffle the DataFrame using the sample method with '\n",
      "          'frac=1 to shuffle all rows. We also set a random_state for '\n",
      "          'reproducibility.We separate the dataset into the feature matrix '\n",
      "          \"'X', which includes all columns except 'Health Metrics', and the \"\n",
      "          \"target vector 'y', which contains only the 'Health Metrics' \"\n",
      "          'column.We split the shuffled data into training (80%) and test '\n",
      "          '(20%) sets using train_test_split from scikit-learn, ensuring that '\n",
      "          'the splitting is random with a specified random_state.'},\n",
      " {'role': 'user',\n",
      "  'text': 'Calculate and Visualize the correlations of all features in a '\n",
      "          \"Pandas DataFrame with 'health_metrics'. The DataFrame is named \"\n",
      "          \"'df'. Ensure the code includes:\\n\"\n",
      "          '1. Calculation of correlation coefficients.\\n'\n",
      "          '2. Visualization of these correlations in a heatmap.\\n'\n",
      "          'Also, instruct on how to interpret the heatmap to highlight any '\n",
      "          'strong correlations with the target variable. Note: Use lowercase '\n",
      "          \"and underscores for column names, e.g., 'health_metrics' instead of \"\n",
      "          \"'Health Metrics'.\\n\"},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To calculate and visualize the correlations of all features with '\n",
      "          \"the 'health_metrics' column in a Pandas DataFrame named 'df,' \"\n",
      "          'including the calculation of correlation coefficients and creating '\n",
      "          'a heatmap for visualization, you can use the following '\n",
      "          'code:pythonCopy codeimport pandas as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# Calculate correlation coefficients\\n'\n",
      "          \"correlations = df.corr()['health_metrics'].drop('health_metrics')  \"\n",
      "          '# Remove self-correlation and select the target variable\\n'\n",
      "          '\\n'\n",
      "          '# Visualize the correlations in a heatmap\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          'sns.heatmap(df.corr(), annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\n'\n",
      "          \"plt.title('Correlation Heatmap')\\n\"\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation of the heatmap:\\n'\n",
      "          '# - Correlation coefficients range from -1 to 1, where:\\n'\n",
      "          '#   - -1 indicates a perfect negative correlation (as one variable '\n",
      "          'goes up, the other goes down).\\n'\n",
      "          '#   - 1 indicates a perfect positive correlation (both variables '\n",
      "          'move in the same direction).\\n'\n",
      "          '#   - 0 indicates no correlation.\\n'\n",
      "          '# - In the heatmap, positive correlations are shown in warmer '\n",
      "          'colors (e.g., red), while negative correlations are shown in cooler '\n",
      "          'colors (e.g., blue).\\n'\n",
      "          \"# - Strong correlations with the target variable ('health_metrics') \"\n",
      "          'are indicated by values closer to -1 or 1, and these are the '\n",
      "          'features that have the most influence on the target.\\n'\n",
      "          '\\n'\n",
      "          '# To identify strong correlations with the target variable, you can '\n",
      "          'look for rows or columns in the heatmap with notably dark or light '\n",
      "          'colors (depending on the sign of the correlation).\\n'\n",
      "          'This code performs the following steps:Calculates the correlation '\n",
      "          'coefficients between all columns (features) and the '\n",
      "          \"'health_metrics' column using the corr() method. It then selects \"\n",
      "          \"the correlations for all features except 'health_metrics' \"\n",
      "          'itself.Creates a heatmap using Seaborn to visualize the '\n",
      "          'correlations. In the heatmap, positive correlations are represented '\n",
      "          'by warmer colors (e.g., red), while negative correlations are '\n",
      "          'represented by cooler colors (e.g., blue).The interpretation of the '\n",
      "          'heatmap is provided in the comments. Strong correlations with the '\n",
      "          \"target variable ('health_metrics') are indicated by values closer \"\n",
      "          'to -1 or 1, which are represented by notably dark or light colors '\n",
      "          'in the heatmap.'},\n",
      " {'role': 'user',\n",
      "  'text': \"ValueError: could not convert string to float: 'Chinstrap'\\n\"\n",
      "          'please recreate the code based on this error'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'The error message \"ValueError: could not convert string to float: '\n",
      "          '\\'Chinstrap\\'\" suggests that you are trying to calculate '\n",
      "          \"correlations between a string column ('Species' in this case) and \"\n",
      "          \"the 'health_metrics' column, which contains non-numeric values. To \"\n",
      "          'calculate correlations, you need to convert the categorical column '\n",
      "          \"('Species') into a numeric format, such as one-hot encoding or \"\n",
      "          \"label encoding. Let's update the code to handle this situation \"\n",
      "          \"using label encoding for the 'Species' column:pythonCopy codeimport \"\n",
      "          'pandas as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          'from sklearn.preprocessing import LabelEncoder\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# 1. Label encode the 'Species' column\\n\"\n",
      "          'label_encoder = LabelEncoder()\\n'\n",
      "          \"df['Species_encoded'] = label_encoder.fit_transform(df['Species'])\\n\"\n",
      "          '\\n'\n",
      "          '# 2. Calculate correlation coefficients\\n'\n",
      "          \"correlations = df.corr()['health_metrics'].drop(['health_metrics', \"\n",
      "          \"'Species_encoded'])\\n\"\n",
      "          '\\n'\n",
      "          '# 3. Visualize the correlations in a heatmap\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          'sns.heatmap(df.corr(), annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\n'\n",
      "          \"plt.title('Correlation Heatmap')\\n\"\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation of the heatmap remains the same as described in '\n",
      "          'the previous response.\\n'\n",
      "          'In this updated code:We use LabelEncoder from scikit-learn to '\n",
      "          \"convert the 'Species' column into a numeric format \"\n",
      "          \"('Species_encoded'). This allows us to calculate correlations with \"\n",
      "          \"'health_metrics' since it's not possible to directly calculate \"\n",
      "          'correlations with string values.We calculate the correlation '\n",
      "          \"coefficients, excluding 'health_metrics' and 'Species_encoded', as \"\n",
      "          'they are not relevant for this purpose.We create the heatmap to '\n",
      "          'visualize the correlations as previously explained.Now, this code '\n",
      "          'should work without raising the \"ValueError\" and provide '\n",
      "          \"correlations with the 'health_metrics' column.\"},\n",
      " {'role': 'user',\n",
      "  'text': 'Dataset includes both numerical and categorical columns. I need to '\n",
      "          'calculate the correlations of all numerical features with a target '\n",
      "          \"variable 'health_metrics'. However, I'm encountering a ValueError \"\n",
      "          'because of non-numeric columns. Modify the code for checking if the '\n",
      "          'value is a numerical one first After calculating the correlations, '\n",
      "          'also guide me on how to visualize these correlations in a heatmap '\n",
      "          'using seaborn or matplotlib. Please ensure that all column names '\n",
      "          'are in lowercase and use underscores instead of spaces.\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To calculate the correlations of only numerical features with the '\n",
      "          \"target variable 'health_metrics' and avoid issues with non-numeric \"\n",
      "          'columns, you can modify the code as follows:pythonCopy codeimport '\n",
      "          'pandas as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# Filter out only the numerical columns\\n'\n",
      "          \"numerical_columns = df.select_dtypes(include=['number'])\\n\"\n",
      "          '\\n'\n",
      "          '# Calculate correlation coefficients\\n'\n",
      "          'correlations = '\n",
      "          \"numerical_columns.corr()['health_metrics'].drop('health_metrics')\\n\"\n",
      "          '\\n'\n",
      "          '# Visualize the correlations in a heatmap\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          \"sns.heatmap(correlations.to_frame(), annot=True, cmap='coolwarm', \"\n",
      "          'fmt=\".2f\")\\n'\n",
      "          \"plt.title('Correlation Heatmap')\\n\"\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation of the heatmap remains the same as described in '\n",
      "          'the previous response.\\n'\n",
      "          'In this modified code:We first filter out only the numerical '\n",
      "          \"columns using select_dtypes(include=['number']). This ensures that \"\n",
      "          'we are calculating correlations only with numerical features.We '\n",
      "          \"calculate the correlation coefficients with the 'health_metrics' \"\n",
      "          'column and drop the correlation with itself (which is always 1).We '\n",
      "          'create the heatmap to visualize the correlations using Seaborn as '\n",
      "          'previously explained.The heatmap will now display correlations only '\n",
      "          \"between numerical features and the 'health_metrics' target \"\n",
      "          'variable. You can interpret it as described in the previous '\n",
      "          'response, looking for notably dark or light colors to identify '\n",
      "          'strong correlations with the target variable.'},\n",
      " {'role': 'user',\n",
      "  'text': \"I have a dataset in a Pandas DataFrame named 'df' with both \"\n",
      "          'numerical and categorical columns. The target variable '\n",
      "          \"'health_metrics' is categorical with values like 'overweight', \"\n",
      "          \"'underweight', etc. I need to encode this target variable \"\n",
      "          'numerically and then calculate the correlations of all features '\n",
      "          'with this encoded target. Please guide me on how to encode '\n",
      "          \"'health_metrics' into a numerical form and then compute \"\n",
      "          'correlations with other features. Additionally, provide '\n",
      "          'instructions on visualizing these correlations in a heatmap. '\n",
      "          'Remember to use lowercase and underscores for column names.\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': \"To encode the categorical target variable 'health_metrics' into a \"\n",
      "          'numerical form and calculate correlations with other features, you '\n",
      "          \"can follow these steps:Encode 'health_metrics' into numerical \"\n",
      "          'values.Calculate correlations between all features (both numerical '\n",
      "          'and encoded categorical) with the encoded '\n",
      "          \"'health_metrics'.Visualize these correlations in a heatmap using \"\n",
      "          \"Seaborn or Matplotlib.Here's the Python code to achieve \"\n",
      "          'this:pythonCopy codeimport pandas as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# 1. Encode 'health_metrics' into numerical values\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          \"df['health_metrics_encoded'] = \"\n",
      "          \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# 2. Calculate correlations with all features, including the '\n",
      "          'encoded target\\n'\n",
      "          'correlations = '\n",
      "          \"df.corr()['health_metrics_encoded'].drop(['health_metrics_encoded', \"\n",
      "          \"'health_metrics'])\\n\"\n",
      "          '\\n'\n",
      "          '# 3. Visualize the correlations in a heatmap\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          \"sns.heatmap(correlations.to_frame(), annot=True, cmap='coolwarm', \"\n",
      "          'fmt=\".2f\")\\n'\n",
      "          \"plt.title('Correlation Heatmap')\\n\"\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation of the heatmap:\\n'\n",
      "          '# - Darker colors indicate stronger correlations, whether positive '\n",
      "          \"or negative, with the encoded 'health_metrics'.\\n\"\n",
      "          '# - Positive correlations are represented by values closer to 1, '\n",
      "          'while negative correlations are closer to -1.\\n'\n",
      "          \"In this code:We encode the categorical 'health_metrics' column into \"\n",
      "          'numerical values using the provided health_metrics_map. The encoded '\n",
      "          \"values are stored in a new column named 'health_metrics_encoded.'We \"\n",
      "          'calculate the correlations between all features (both numerical and '\n",
      "          \"the encoded 'health_metrics') with the encoded \"\n",
      "          \"'health_metrics_encoded' column.We create a heatmap to visualize \"\n",
      "          'these correlations. Darker colors indicate stronger correlations, '\n",
      "          'and you can interpret them as described in the comments.This code '\n",
      "          'will help you visualize the correlations between all features and '\n",
      "          \"the encoded 'health_metrics' target variable.\"},\n",
      " {'role': 'user',\n",
      "  'text': \"I've encoded the categorical target variable 'health_metrics' into \"\n",
      "          \"a numerical format. However, I'm facing a ValueError: could not \"\n",
      "          'convert string to float when trying to calculate feature '\n",
      "          'correlations. How can I modify my code to calculate correlations '\n",
      "          \"only between numerical features and the encoded 'health_metrics' \"\n",
      "          \"column, excluding any other categorical columns like 'species'? \"\n",
      "          'Please provide a Python code snippet that correctly computes these '\n",
      "          'correlations and a way to visualize them in a heatmap.\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To calculate correlations only between numerical features and the '\n",
      "          \"encoded 'health_metrics' column while excluding other categorical \"\n",
      "          \"columns like 'species,' you can follow these steps:Encode the \"\n",
      "          \"'health_metrics' column into numerical values.Select only the \"\n",
      "          'numerical columns for correlation calculation.Calculate the '\n",
      "          'correlations.Visualize these correlations in a heatmap using '\n",
      "          \"Seaborn or Matplotlib.Here's a Python code snippet that \"\n",
      "          'accomplishes this:pythonCopy codeimport pandas as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# 1. Encode 'health_metrics' into numerical values\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          \"df['health_metrics_encoded'] = \"\n",
      "          \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# 2. Select only the numerical columns for correlation calculation\\n'\n",
      "          \"numerical_columns = df.select_dtypes(include=['number'])\\n\"\n",
      "          '\\n'\n",
      "          '# 3. Calculate correlations\\n'\n",
      "          'correlations = '\n",
      "          \"numerical_columns.corrwith(df['health_metrics_encoded']).sort_values(ascending=False)\\n\"\n",
      "          '\\n'\n",
      "          '# 4. Visualize the correlations in a heatmap\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          \"sns.heatmap(correlations.to_frame(), annot=True, cmap='coolwarm', \"\n",
      "          'fmt=\".2f\")\\n'\n",
      "          \"plt.title('Correlations with Encoded health_metrics')\\n\"\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation of the heatmap:\\n'\n",
      "          '# - Darker colors indicate stronger positive or negative '\n",
      "          'correlations between numerical features and the encoded '\n",
      "          \"'health_metrics'.\\n\"\n",
      "          '# - Positive correlations are represented by values closer to 1, '\n",
      "          'while negative correlations are closer to -1.\\n'\n",
      "          \"In this code:We encode the categorical 'health_metrics' column into \"\n",
      "          'numerical values, as you did before.We select only the numerical '\n",
      "          \"columns using select_dtypes(include=['number']), ensuring that we \"\n",
      "          'are including only numerical features for correlation '\n",
      "          'calculation.We calculate the correlations between the selected '\n",
      "          \"numerical columns and the encoded 'health_metrics_encoded' column \"\n",
      "          'using corrwith.We create a heatmap to visualize these correlations, '\n",
      "          'where darker colors indicate stronger correlations, and you can '\n",
      "          'interpret them as described in the comments.This code should '\n",
      "          'correctly calculate and visualize the correlations between '\n",
      "          \"numerical features and the encoded 'health_metrics' column while \"\n",
      "          \"excluding other categorical columns like 'species.'\"},\n",
      " {'role': 'user',\n",
      "  'text': 'With computed correlations between features and an encoded target '\n",
      "          'variable, guide me on how to select a subset of features that are '\n",
      "          'likely strong predictors for the target. Explain how to interpret '\n",
      "          'the correlation values to identify these features and provide a '\n",
      "          'Python code example for selecting them based on their correlation '\n",
      "          'strengths. Emphasize the justification for choosing these features '\n",
      "          'based on the correlation analysis.'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To select a subset of features that are likely strong predictors '\n",
      "          'for the target variable based on correlation analysis, you can '\n",
      "          'follow these steps:Identify the features with the highest positive '\n",
      "          'and negative correlation values with the target variable.Choose a '\n",
      "          'threshold for correlation strength that determines which features '\n",
      "          'to select.Justify your selection based on the correlation values '\n",
      "          \"and domain knowledge.Here's a Python code example that demonstrates \"\n",
      "          'how to select features based on correlation strengths:pythonCopy '\n",
      "          'codeimport pandas as pd\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          \"df['health_metrics_encoded'] = \"\n",
      "          \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# Calculate correlations between numerical features and the encoded '\n",
      "          \"'health_metrics'\\n\"\n",
      "          'correlations = '\n",
      "          \"df.corrwith(df['health_metrics_encoded']).sort_values(ascending=False)\\n\"\n",
      "          '\\n'\n",
      "          '# Set a threshold for selecting strong predictors\\n'\n",
      "          'correlation_threshold = 0.2  # You can adjust this threshold based '\n",
      "          'on your requirements\\n'\n",
      "          '\\n'\n",
      "          '# Select features with correlations above the threshold (positive '\n",
      "          'and negative)\\n'\n",
      "          'selected_features = correlations[(correlations > '\n",
      "          'correlation_threshold) | (correlations < -correlation_threshold)]\\n'\n",
      "          '\\n'\n",
      "          '# Display the selected features and their correlation values\\n'\n",
      "          'print(\"Selected Features:\")\\n'\n",
      "          'print(selected_features)\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation and justification:\\n'\n",
      "          '# - Features with positive correlations indicate that as the '\n",
      "          \"feature increases, the likelihood of 'health_metrics' being \"\n",
      "          \"'overweight' or 'underweight' also increases.\\n\"\n",
      "          '# - Features with negative correlations indicate the opposite, as '\n",
      "          \"the feature decreases, the likelihood of 'health_metrics' being \"\n",
      "          \"'overweight' or 'underweight' increases.\\n\"\n",
      "          '# - By setting a threshold (e.g., 0.2), you can choose features '\n",
      "          \"that have a relatively strong impact on 'health_metrics'.\\n\"\n",
      "          '# - The threshold can be adjusted based on your domain knowledge '\n",
      "          'and the specific requirements of your predictive model.\\n'\n",
      "          '\\n'\n",
      "          '# You can further analyze these selected features and perform '\n",
      "          'machine learning modeling with them.\\n'\n",
      "          'In this code:We calculate the correlations between numerical '\n",
      "          \"features and the encoded 'health_metrics' column.We set a threshold \"\n",
      "          '(correlation_threshold) to determine which features are considered '\n",
      "          'strong predictors. You can adjust this threshold based on your '\n",
      "          'domain knowledge and requirements. Features with correlations above '\n",
      "          'or below this threshold (positive or negative) are selected.We '\n",
      "          'display the selected features and their correlation values, '\n",
      "          'providing an initial list of potential predictors for the '\n",
      "          \"'health_metrics' target variable.Remember that correlation does not \"\n",
      "          'imply causation, and the selected features should be further '\n",
      "          'analyzed and validated in the context of your specific prediction '\n",
      "          'or classification problem. Domain knowledge and domain-specific '\n",
      "          'expertise are crucial for making informed decisions about feature '\n",
      "          'selection.'},\n",
      " {'role': 'user',\n",
      "  'text': 'I need to propose two hypothetical features that could enhance the '\n",
      "          \"predictive accuracy for the target variable 'health_metrics'. Can \"\n",
      "          'you suggest two potential new features, explaining how they might '\n",
      "          'be derived from the existing data or external sources, and their '\n",
      "          \"expected impact on the model's accuracy? Also, provide a \"\n",
      "          'hypothetical example of how to calculate and show the correlations '\n",
      "          'of these new features with the target variable using Python. Note '\n",
      "          \"that the target variable 'health_metrics' is categorical and has \"\n",
      "          'been numerically encoded.\"\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'Certainly! Here are two hypothetical features that could enhance '\n",
      "          \"predictive accuracy for the target variable 'health_metrics' based \"\n",
      "          \"on the existing data and their expected impact on the model's \"\n",
      "          'accuracy:Daily Caloric Intake (New Feature 1):Derivation: Calculate '\n",
      "          'the daily caloric intake of each penguin based on their diet and '\n",
      "          'body mass. You can estimate the caloric intake required for '\n",
      "          'different diets (e.g., fish, krill, squid, parental) and then '\n",
      "          'calculate the daily caloric intake by multiplying the estimated '\n",
      "          \"value by the penguin's body mass (in grams).Expected Impact: \"\n",
      "          'Penguins with insufficient daily caloric intake compared to their '\n",
      "          'dietary requirements may have a higher likelihood of being '\n",
      "          \"'underweight.' Conversely, those with excessive caloric intake may \"\n",
      "          \"have a higher likelihood of being 'overweight.' This feature could \"\n",
      "          \"provide valuable information to the model about the penguin's \"\n",
      "          'nutrition and health status.Seasonality Indicator (New Feature '\n",
      "          '2):Derivation: Determine the seasonality of data collection by '\n",
      "          \"examining the 'Year' column. You can categorize the years into \"\n",
      "          \"different seasons (e.g., summer, winter) based on the hemisphere's \"\n",
      "          \"calendar and location of the penguins' habitat.Expected Impact: \"\n",
      "          'Seasonal changes may influence the availability of food and, '\n",
      "          'consequently, the health of penguins. For example, during certain '\n",
      "          'seasons, food sources may be more abundant, leading to better '\n",
      "          'health. This feature can help the model account for '\n",
      "          \"seasonality-related variations in 'health_metrics.'Here's a \"\n",
      "          'hypothetical Python code snippet to calculate and visualize the '\n",
      "          'correlations of these new features with the encoded '\n",
      "          \"'health_metrics' target variable:pythonCopy codeimport pandas as \"\n",
      "          'pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          \"df['health_metrics_encoded'] = \"\n",
      "          \"df['health_metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# Hypothetical Feature 1: Daily Caloric Intake\\n'\n",
      "          '# Calculate daily caloric intake (hypothetical calculation)\\n'\n",
      "          \"caloric_intake = df['Diet'].map({'fish': 500, 'krill': 300, \"\n",
      "          \"'squid': 400, 'parental': 600}) * df['Body Mass (g)']\\n\"\n",
      "          '\\n'\n",
      "          '# Hypothetical Feature 2: Seasonality Indicator\\n'\n",
      "          '# Categorize years into seasons (hypothetical categorization)\\n'\n",
      "          \"seasonality = df['Year'].map({2017: 'Winter', 2018: 'Spring', 2019: \"\n",
      "          \"'Summer', 2020: 'Autumn'})\\n\"\n",
      "          '\\n'\n",
      "          '# Calculate correlations with the new features\\n'\n",
      "          'correlation_caloric_intake = '\n",
      "          \"df['health_metrics_encoded'].corr(caloric_intake)\\n\"\n",
      "          'correlation_seasonality = '\n",
      "          \"df['health_metrics_encoded'].corr(seasonality)\\n\"\n",
      "          '\\n'\n",
      "          '# Visualize the correlations\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          \"sns.barplot(x=['Daily Caloric Intake', 'Seasonality'], \"\n",
      "          'y=[correlation_caloric_intake, correlation_seasonality])\\n'\n",
      "          \"plt.title('Correlations of New Features with Encoded \"\n",
      "          \"health_metrics')\\n\"\n",
      "          \"plt.ylabel('Correlation Coefficient')\\n\"\n",
      "          'plt.ylim(-1, 1)\\n'\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation:\\n'\n",
      "          '# - Positive correlations indicate that the feature is positively '\n",
      "          \"related to 'health_metrics.'\\n\"\n",
      "          '# - Negative correlations indicate a negative relationship.\\n'\n",
      "          '# - The higher the absolute correlation coefficient, the stronger '\n",
      "          \"the feature's influence on 'health_metrics.'\\n\"\n",
      "          'In this code, we calculate the correlations of the hypothetical new '\n",
      "          \"features ('Daily Caloric Intake' and 'Seasonality Indicator') with \"\n",
      "          \"the encoded 'health_metrics' target variable and visualize them \"\n",
      "          'using a bar plot. Positive correlations suggest a positive '\n",
      "          \"relationship with 'health_metrics,' while negative correlations \"\n",
      "          'suggest a negative relationship. The magnitude of the correlation '\n",
      "          'coefficient indicates the strength of the relationship.'},\n",
      " {'role': 'user',\n",
      "  'text': \"Encountered a KeyError for the column 'Diet'. How can I identify \"\n",
      "          'and correct the issue causing this error? Please guide me on how to '\n",
      "          'solve If the column name is different, provide guidance on how to '\n",
      "          'access it correctly in Python. Additionally, if the column does not '\n",
      "          'exist, suggest ways to handle this situation.\"\\n'},\n",
      " {'role': 'assistant',\n",
      "  'text': \"If you encountered a KeyError for the column 'Diet,' it suggests \"\n",
      "          \"that the column 'Diet' does not exist in your DataFrame. To \"\n",
      "          'identify and correct the issue, you can follow these steps:Check '\n",
      "          \"the column names: Verify that the column name 'Diet' exists in your \"\n",
      "          \"DataFrame. It's possible that the column name is different from \"\n",
      "          'what you expected. You can print the list of column names to '\n",
      "          \"confirm.Handle missing columns: If the 'Diet' column is missing, \"\n",
      "          'you can consider the following options:Check for typos: Ensure that '\n",
      "          'you have spelled the column name correctly. Column names are '\n",
      "          'case-sensitive.Confirm dataset structure: Review the dataset or its '\n",
      "          \"documentation to make sure that the 'Diet' column is supposed to be \"\n",
      "          'present.Update column name: If the column name is different, you '\n",
      "          \"can access it using the correct name.Here's how you can check the \"\n",
      "          'column names and handle the situation if the column name is '\n",
      "          \"different or if the column doesn't exist:pythonCopy codeimport \"\n",
      "          'pandas as pd\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# 1. Check the column names\\n'\n",
      "          'print(\"Column names in the DataFrame:\")\\n'\n",
      "          'print(df.columns)\\n'\n",
      "          '\\n'\n",
      "          '# 2. Handle missing columns\\n'\n",
      "          \"if 'Diet' not in df.columns:\\n\"\n",
      "          \"    # If 'Diet' is not found, you can handle it based on your \"\n",
      "          'needs.\\n'\n",
      "          '    # For example, you can access a different column with a similar '\n",
      "          'purpose if available, or perform other data handling tasks.\\n'\n",
      "          '    print(\"The \\'Diet\\' column is missing. Please check the dataset '\n",
      "          'structure or handle this situation accordingly.\")\\n'\n",
      "          'else:\\n'\n",
      "          \"    # If 'Diet' exists, you can access it as df['Diet'].\\n\"\n",
      "          \"    diet_column = df['Diet']\\n\"\n",
      "          \"    # Now, you can use the 'diet_column' for your calculations.\\n\"\n",
      "          '    print(\"The \\'Diet\\' column exists, and you can access it.\")\\n'\n",
      "          \"By following these steps, you can identify whether the 'Diet' \"\n",
      "          'column is present in your DataFrame, handle situations where the '\n",
      "          'column name is different, or take appropriate actions if the column '\n",
      "          \"doesn't exist.\"},\n",
      " {'role': 'user',\n",
      "  'text': 'i find out the error is because you used capital letters on column '\n",
      "          'names dont do it again. Also daily calorie intake  correlecian '\n",
      "          'coefficient is 0 (straight line) and seasonality is no line at all '\n",
      "          'please solve these issues'},\n",
      " {'role': 'assistant',\n",
      "  'text': 'I apologize for the oversight in using capital letters for column '\n",
      "          \"names. To resolve the correlation issues, let's make sure we are \"\n",
      "          'using the correct column names and address any issues with the '\n",
      "          \"calculations. Here's the updated code:pythonCopy codeimport pandas \"\n",
      "          'as pd\\n'\n",
      "          'import seaborn as sns\\n'\n",
      "          'import matplotlib.pyplot as plt\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          \"# Encode the 'health_metrics' column into numerical values\\n\"\n",
      "          \"health_metrics_map = {'healthy': 1, 'overweight': 2, 'underweight': \"\n",
      "          '3}\\n'\n",
      "          \"df['health_metrics_encoded'] = df['Health \"\n",
      "          \"Metrics'].map(health_metrics_map)\\n\"\n",
      "          '\\n'\n",
      "          '# Hypothetical Feature 1: Daily Caloric Intake\\n'\n",
      "          '# Calculate daily caloric intake (hypothetical calculation)\\n'\n",
      "          \"diet_caloric_map = {'fish': 500, 'krill': 300, 'squid': 400, \"\n",
      "          \"'parental': 600}\\n\"\n",
      "          \"df['Daily Caloric Intake'] = df['Diet'].map(diet_caloric_map) * \"\n",
      "          \"df['Body Mass (g)']\\n\"\n",
      "          '\\n'\n",
      "          '# Hypothetical Feature 2: Seasonality Indicator\\n'\n",
      "          '# Categorize years into seasons (hypothetical categorization)\\n'\n",
      "          \"seasonality_map = {2007: 'Winter', 2008: 'Spring', 2009: 'Summer', \"\n",
      "          \"2010: 'Autumn'}\\n\"\n",
      "          \"df['Seasonality'] = df['Year'].map(seasonality_map)\\n\"\n",
      "          '\\n'\n",
      "          '# Calculate correlations with the new features\\n'\n",
      "          'correlation_caloric_intake = '\n",
      "          \"df['health_metrics_encoded'].corr(df['Daily Caloric Intake'])\\n\"\n",
      "          'correlation_seasonality = '\n",
      "          \"df['health_metrics_encoded'].corr(df['Seasonality'])\\n\"\n",
      "          '\\n'\n",
      "          '# Visualize the correlations\\n'\n",
      "          'plt.figure(figsize=(10, 6))\\n'\n",
      "          \"sns.barplot(x=['Daily Caloric Intake', 'Seasonality'], \"\n",
      "          'y=[correlation_caloric_intake, correlation_seasonality])\\n'\n",
      "          \"plt.title('Correlations of New Features with Encoded Health \"\n",
      "          \"Metrics')\\n\"\n",
      "          \"plt.ylabel('Correlation Coefficient')\\n\"\n",
      "          'plt.ylim(-1, 1)\\n'\n",
      "          'plt.show()\\n'\n",
      "          '\\n'\n",
      "          '# Interpretation:\\n'\n",
      "          \"# - A correlation of 0 for 'Daily Caloric Intake' suggests no \"\n",
      "          \"linear relationship with 'Health Metrics.'\\n\"\n",
      "          \"# - No line for 'Seasonality' indicates no linear relationship as \"\n",
      "          'well.\\n'\n",
      "          'In this updated code:We corrected the column names to use lowercase '\n",
      "          'and underscores.We addressed the issues with correlation '\n",
      "          \"coefficients. If the correlations for 'Daily Caloric Intake' and \"\n",
      "          \"'Seasonality' are 0 or close to 0, it suggests that there may not \"\n",
      "          'be a strong linear relationship between these features and the '\n",
      "          \"encoded 'Health Metrics.' In such cases, it's essential to explore \"\n",
      "          'other feature engineering or selection techniques to improve model '\n",
      "          'accuracy.'},\n",
      " {'role': 'user',\n",
      "  'text': 'Provide guidance on using GridSearchCV in scikit-learn to tune '\n",
      "          'hyperparameters of a DecisionTreeClassifier. I want to choose two '\n",
      "          'hyperparameters to tune based on the Scikit-learn decision tree '\n",
      "          'documentation. Explain how to set up GridSearchCV with a '\n",
      "          'cross-validation value of 5 and use validation accuracy to '\n",
      "          'determine the best hyperparameters. The dataset is in a DataFrame '\n",
      "          \"named 'df' and the target variable is 'health_metrics'.\\n\"},\n",
      " {'role': 'assistant',\n",
      "  'text': 'To use GridSearchCV in scikit-learn to tune hyperparameters of a '\n",
      "          'DecisionTreeClassifier, you can follow these steps:Import necessary '\n",
      "          'libraries.Define the parameter grid with the hyperparameters you '\n",
      "          'want to tune.Create a DecisionTreeClassifier.Create a GridSearchCV '\n",
      "          'instance with the classifier and parameter grid.Fit the '\n",
      "          'GridSearchCV object to your data and target variable.Retrieve and '\n",
      "          \"analyze the best hyperparameters.Here's a Python code example with \"\n",
      "          'explanations for each step:pythonCopy codeimport pandas as pd\\n'\n",
      "          'from sklearn.model_selection import GridSearchCV, train_test_split\\n'\n",
      "          'from sklearn.tree import DecisionTreeClassifier\\n'\n",
      "          '\\n'\n",
      "          '# Load the dataset into a Pandas DataFrame\\n'\n",
      "          \"file_path = 'cs412_hw1_dataset.csv'\\n\"\n",
      "          'df = pd.read_csv(file_path)\\n'\n",
      "          '\\n'\n",
      "          '# Split the data into features (X) and target variable (y)\\n'\n",
      "          \"X = df.drop(columns=['Health Metrics'])  # Features (excluding \"\n",
      "          'target variable)\\n'\n",
      "          \"y = df['Health Metrics']  # Target variable\\n\"\n",
      "          '\\n'\n",
      "          '# Define the parameter grid for tuning\\n'\n",
      "          'param_grid = {\\n'\n",
      "          \"    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree \"\n",
      "          '(None for unlimited depth)\\n'\n",
      "          \"    'min_samples_split': [2, 5, 10],  # Minimum number of samples \"\n",
      "          'required to split an internal node\\n'\n",
      "          '}\\n'\n",
      "          '\\n'\n",
      "          '# Create a DecisionTreeClassifier\\n'\n",
      "          'clf = DecisionTreeClassifier(random_state=42)\\n'\n",
      "          '\\n'\n",
      "          '# Create a GridSearchCV instance with cross-validation value of 5\\n'\n",
      "          'grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, '\n",
      "          \"cv=5, scoring='accuracy')\\n\"\n",
      "          '\\n'\n",
      "          '# Fit the GridSearchCV object to the data\\n'\n",
      "          'grid_search.fit(X, y)\\n'\n",
      "          '\\n'\n",
      "          '# Retrieve the best hyperparameters\\n'\n",
      "          \"best_max_depth = grid_search.best_params_['max_depth']\\n\"\n",
      "          'best_min_samples_split = '\n",
      "          \"grid_search.best_params_['min_samples_split']\\n\"\n",
      "          'best_accuracy = grid_search.best_score_\\n'\n",
      "          '\\n'\n",
      "          'print(f\"Best Hyperparameters: Max Depth = {best_max_depth}, Min '\n",
      "          'Samples Split = {best_min_samples_split}\")\\n'\n",
      "          'print(f\"Best Cross-Validation Accuracy: {best_accuracy:.2f}\")\\n'\n",
      "          'In this code:We load the dataset into a Pandas DataFrame and split '\n",
      "          'it into features (X) and the target variable (y).We define the '\n",
      "          'parameter grid (param_grid) with the hyperparameters you want to '\n",
      "          \"tune: 'max_depth' and 'min_samples_split'. You can add more \"\n",
      "          'hyperparameters to the grid if needed.We create a '\n",
      "          'DecisionTreeClassifier (clf) with a fixed random state for '\n",
      "          'reproducibility.We create a GridSearchCV instance (grid_search) '\n",
      "          'with the DecisionTreeClassifier, the parameter grid, 5-fold '\n",
      "          'cross-validation (cv=5), and scoring based on accuracy '\n",
      "          \"(scoring='accuracy').We fit the GridSearchCV object to the data, \"\n",
      "          'which performs a search over the specified hyperparameters and '\n",
      "          'cross-validates to find the best combination.We retrieve and print '\n",
      "          'the best hyperparameters (best_max_depth and '\n",
      "          'best_min_samples_split) and the best cross-validation accuracy '\n",
      "          '(best_accuracy).By running this code, you will find the best '\n",
      "          'hyperparameters for your DecisionTreeClassifier and their '\n",
      "          'corresponding cross-validation accuracy score. These '\n",
      "          'hyperparameters can be used to build a more optimized model for '\n",
      "          'your classification task.'}]\n"
     ]
    }
   ],
   "source": [
    "# let's see one of the conversations\n",
    "pprint(code2convos[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes a text as an input and divides it into code,text,commentCode\n",
    "#by following a similar pattern used in ChatGPT responses that include code example.\n",
    "\n",
    "def distinguisher(response):\n",
    "    index=response.find(\":pythonCopy code\")\n",
    "    index2=response.rfind(\"\\n\")\n",
    "    \n",
    "    if(index!=-1):\n",
    "        text_part = response[:index]+ response[index2:]\n",
    "\n",
    "        code_part = response[index + len(\":pythonCopy code\"):index2].strip()\n",
    "        # Split the code into statements using '\\n' as the delimiter\n",
    "        code_part= code_part.split('\\n')\n",
    "\n",
    "        # Group statements based on whether they start with '#'\n",
    "        comment_code = [s for s in code_part if s.startswith('#') and s!=\"\"]\n",
    "        actual_code = [s for s in code_part if not s.startswith('#')and s!=\"\"]\n",
    "        \n",
    "        return{\"text\":text_part,\"code\":\" \".join(actual_code), \"commentCode\": \" \".join(comment_code) }\n",
    "        \n",
    "    else:\n",
    "        #that means the response does not include a code\n",
    "\n",
    "        text_part = response\n",
    "\n",
    "        code_part = \"\"\n",
    "        \n",
    "    return {\"text\": text_part, \"code\": \"\", \"commentCode\":\"\"}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes the dictionary formatted in the same way as the dictionary provided to us initially\n",
    "#and categorizes the output of ChatGPT as text, code ,commentCode\n",
    "\n",
    "def divideTextAndCode(code2convos):\n",
    "    for key, dictionaries in code2convos.items():\n",
    "        \n",
    "        # Iterate over the list of dictionaries for each key\n",
    "        for dictionary in dictionaries:\n",
    "            # Check if the role is \"assistant\"\n",
    "            if dictionary[\"role\"] == \"assistant\":\n",
    "                # Apply the distinguisher function to the \"text\" field\n",
    "                distinguished_parts = distinguisher(dictionary[\"text\"])\n",
    "                # Update the message dictionary with the modified \"text\" and \"code\" fields\n",
    "                dictionary[\"text\"]=distinguished_parts[\"text\"]\n",
    "                dictionary[\"code\"]=distinguished_parts[\"code\"]\n",
    "                dictionary[\"commentCode\"]=distinguished_parts[\"commentCode\"]\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "divideTextAndCode(code2convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'text': 'Read the .csv file with the pandas library can you do that'},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Certainly! To read a CSV file using the pandas library in Python, you can use the read_csv function. Make sure you have the pandas library installed before running the code. You can install it using:bashCopy codepip install pandas\\nNow, assuming you have a CSV file named \"your_file.csv\", here\\'s an example code to read it using pandas\\nThis code assumes that the CSV file is in the same directory as your Python script or Jupyter Notebook. If the file is in a different directory, you should provide the full path or a relative path from your current working directory.You can customize the read_csv function with various parameters based on your specific CSV file format. For example, you can specify the delimiter, header presence, column names, etc. Refer to the pandas documentation for more details on the available options.',\n",
       "  'code': \"import pandas as pd file_path = 'your_file.csv' df = pd.read_csv(file_path) print(df)\",\n",
       "  'commentCode': \"# Replace 'your_file.csv' with the actual path to your CSV file # Read the CSV file into a pandas DataFrame # Now, 'df' is a DataFrame containing the data from the CSV file\"},\n",
       " {'role': 'user',\n",
       "  'text': 'Understanding the Dataset: (5 pts)\\n\\nFind the shape of the dataset (number of samples & number of attributes). (Hint: You can use the shape function)\\nDisplay variable names (both dependent and independent).\\nDisplay the summary of the dataset. (Hint: You can use the info function)\\nDisplay the first 5 rows from training dataset. (Hint: You can use the head function) can you code it'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! Assuming you've already read your dataset into a pandas DataFrame named df, here's how you can perform the tasks you've mentioned\\nMake sure to replace df with the actual name of your DataFrame if it's different. This code assumes that you have a typical dataset with both independent and dependent variables. The head() function is used to display the first 5 rows of the dataset, and info() provides a concise summary of the DataFrame, including information about the data types and missing values.\",\n",
       "  'code': 'print(\"Shape of the dataset:\", df.shape) print(\"\\\\nVariable names:\") print(\"Independent variables (features):\", df.columns.tolist()) print(\"\\\\nSummary of the dataset:\") df.info() print(\"\\\\nFirst 5 rows from the training dataset:\") print(df.head())',\n",
       "  'commentCode': '# Find the shape of the dataset (number of samples & number of attributes) # Display variable names (both dependent and independent) # Display the summary of the dataset # Display the first 5 rows from the training dataset'},\n",
       " {'role': 'user',\n",
       "  'text': 'Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. Be careful that you have enough data for training the model.\\nEncode categorical labels with the mappings given in the cell below. (Hint: You can use map function) I have to this part and the given code is as following sex_map = {\\'female\\':1, \\'male\\': 0}\\n\\nisland_map = {\\'Biscoe\\': 1,\\n              \\'Dream\\': 2,\\n              \\'Torgensen\\': 3}\\n\\ndiet_map = {\\'fish\\': 1,\\n              \\'krill\\': 2,\\n              \\'squid\\': 3,\\n            \"parental\":4}\\n\\nlife_stage_map = {\\'chick\\': 1,\\n              \\'juvenile\\': 2,\\n              \\'adult\\': 3}\\n\\nhealth_metrics_map = {\\'healthy\\': 1,\\n              \\'overweight\\': 2,'},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Certainly! Let\\'s start by addressing missing values and then proceed with encoding categorical labels using the provided mappings. Assuming your DataFrame is named df, here\\'s how you can perform these tasks\\nMake sure to uncomment either the \"Drop rows with missing values\" or \"Fill missing values with the most common value in each column\" section based on your preference. Choose the option that best fits your data and the amount of missing values in your dataset.',\n",
       "  'code': 'missing_values = df.isnull().sum() print(\"\\\\nMissing values in the dataset:\") print(missing_values) sex_map = {\\'female\\': 1, \\'male\\': 0} island_map = {\\'Biscoe\\': 1, \\'Dream\\': 2, \\'Torgensen\\': 3} diet_map = {\\'fish\\': 1, \\'krill\\': 2, \\'squid\\': 3, \\'parental\\': 4} life_stage_map = {\\'chick\\': 1, \\'juvenile\\': 2, \\'adult\\': 3} health_metrics_map = {\\'healthy\\': 1, \\'overweight\\': 2} df[\\'sex\\'] = df[\\'sex\\'].map(sex_map) df[\\'island\\'] = df[\\'island\\'].map(island_map) df[\\'diet\\'] = df[\\'diet\\'].map(diet_map) df[\\'life_stage\\'] = df[\\'life_stage\\'].map(life_stage_map) df[\\'health_metrics\\'] = df[\\'health_metrics\\'].map(health_metrics_map) print(\"\\\\nUpdated DataFrame after encoding categorical labels:\") print(df.head())',\n",
       "  'commentCode': '# Check for missing values in the dataset # Option 1: Drop rows with missing values # df = df.dropna() # Option 2: Fill missing values with the most common value in each column # df = df.apply(lambda x: x.fillna(x.value_counts().index[0])) # Note: Choose either option 1 or 2 based on your specific scenario and the amount of missing data. # Encoding categorical labels using the provided mappings # Apply the mapping to the respective columns # Display the updated DataFrame'},\n",
       " {'role': 'user',\n",
       "  'text': 'Encode categorical labels with the mappings given in the cell below. (Hint: You can use map function) Ä± have to do this part for species'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! If you have a column named 'species' in your DataFrame that you want to encode using a mapping, you can use the map function. Here's how you can do it using the provided mapping\\nReplace 'species' with the actual name of your column if it's different. The map function is used to replace values in the 'species' column with the corresponding values from the species_map. This will encode the categorical labels in the 'species' column according to the provided mapping.\",\n",
       "  'code': 'species_map = {\\'Adelie\\': 1, \\'Chinstrap\\': 2, \\'Gentoo\\': 3} df[\\'species\\'] = df[\\'species\\'].map(species_map) print(\"\\\\nUpdated DataFrame after encoding \\'species\\' column:\") print(df.head())',\n",
       "  'commentCode': \"# Given species mapping # Apply the mapping to the 'species' column # Display the updated DataFrame\"},\n",
       " {'role': 'user', 'text': 'how can Ä± label the year part'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"If your dataset includes a column with the year information, and you want to label it, you can create a new column for the labels based on the year values. Here's an example assuming you have a column named 'year'\\nIn this example, a new column named 'year_label' is created based on the 'year' column values using the provided mapping (year_labels). Adjust the column names and mapping according to your actual dataset.This will create a new column that represents the labeled version of the 'year' information based on the specified mapping.\",\n",
       "  'code': 'year_labels = {2019: \\'Year_2019\\', 2020: \\'Year_2020\\', 2021: \\'Year_2021\\', 2022: \\'Year_2022\\'} df[\\'year_label\\'] = df[\\'year\\'].map(year_labels) print(\"\\\\nUpdated DataFrame with labeled \\'year\\' column:\") print(df.head())',\n",
       "  'commentCode': \"# Assuming you have a column named 'year' in your DataFrame # If 'year' is not present, replace it with the actual name of your column # Create a mapping for the year labels # Apply the mapping to the 'year' column to create a new labeled column # Display the updated DataFrame\"},\n",
       " {'role': 'user', 'text': 'Is there any short way as labelencoder'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Yes, you can use the LabelEncoder from the sklearn.preprocessing module to encode the 'year' column or any other categorical column with numerical labels. Here's an example\\nIn this example, the LabelEncoder is used to transform the 'year' column into numerical labels, and the result is stored in a new column named 'year_label'. This is a shorter way compared to manually creating a mapping. Keep in mind that LabelEncoder assigns unique numerical labels to each unique value in the column.Remember that this approach assumes that the 'year' column contains categorical values that can be encoded numerically. If the 'year' column is already numerical, you might not need to use LabelEncoder.\",\n",
       "  'code': 'from sklearn.preprocessing import LabelEncoder label_encoder = LabelEncoder() df[\\'year_label\\'] = label_encoder.fit_transform(df[\\'year\\']) print(\"\\\\nUpdated DataFrame with labeled \\'year\\' column:\") print(df.head())',\n",
       "  'commentCode': \"# Assuming you have a column named 'year' in your DataFrame # If 'year' is not present, replace it with the actual name of your column # Create an instance of LabelEncoder # Fit and transform the 'year' column to numerical labels # Display the updated DataFrame\"},\n",
       " {'role': 'user', 'text': 'print(df.head(3)) '},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Sure, if you want to print the first 3 rows of your DataFrame df, you can use the head function as follows\\nThis will display the first 3 rows of your DataFrame. Adjust the argument to head if you want to display a different number of rows.',\n",
       "  'code': 'print(df.head(3))',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': 'Empty DataFrame\\nColumns: [species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex, diet, life_stage, health_metrics, year, year_label]\\nIndex: [] it tells me this why'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"The output you provided indicates that your DataFrame is currently empty. There are a few potential reasons for an empty DataFrame:The CSV file is empty: If the CSV file you read into the DataFrame (df) is empty or contains only headers without any data, you'll end up with an empty DataFrame.Incorrect file path: Ensure that the file path you provided to read the CSV file is correct. Double-check the path and the file name to make sure it points to the actual location of your dataset.Data loading issues: There might be issues with reading the data from the CSV file. Verify that your CSV file is formatted correctly and that it contains the expected data.Here's a generic example of reading a CSV file\\nIf the issue persists, you may want to investigate further by checking the contents of your CSV file or providing additional information about your dataset and how you are loading it into the DataFrame.\",\n",
       "  'code': \"import pandas as pd file_path = 'your_file.csv' df = pd.read_csv(file_path) print(df.head(3))\",\n",
       "  'commentCode': \"# Replace 'your_file.csv' with the actual path to your CSV file # Read the CSV file into a pandas DataFrame # Display the first 3 rows to check the content\"},\n",
       " {'role': 'user',\n",
       "  'text': 'Shuffle the dataset.\\nSeperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\\nSplit training and test sets as 80% and 20%, respectively. Can you do this part'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! To shuffle the dataset, separate the dependent and independent variables, and split the data into training and test sets, you can use the shuffle and train_test_split functions from sklearn.model_selection. Here's an example\\nIn this example:The dataset is shuffled using the sample method with frac=1 to shuffle the entire DataFrame.The independent variables (X) are all columns except 'health_metrics'.The dependent variable (y) is the 'health_metrics' column.The train_test_split function is used to split the data into training and test sets. The test_size parameter is set to 0.2, indicating an 80%/20% split.The shapes of the resulting training and test sets are then displayed.Adjust the column names as needed based on your actual dataset structure.\",\n",
       "  'code': 'from sklearn.model_selection import train_test_split df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True) X = df_shuffled.drop(columns=[\\'health_metrics\\']) y = df_shuffled[\\'health_metrics\\'] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) print(\"Shape of X_train:\", X_train.shape) print(\"Shape of X_test:\", X_test.shape) print(\"Shape of y_train:\", y_train.shape) print(\"Shape of y_test:\", y_test.shape)',\n",
       "  'commentCode': '# Shuffle the dataset # Separate independent variables (X) and dependent variable (y) # Split the dataset into training and test sets (80% training, 20% test) # Display the shapes of the training and test sets'},\n",
       " {'role': 'user',\n",
       "  'text': 'df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True) is this for shuffling'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Yes, that's correct. The line df.sample(frac=1, random_state=42).reset_index(drop=True) is used for shuffling the DataFrame df. Let me break it down:df.sample(frac=1, random_state=42): This randomly samples the entire DataFrame (frac=1 means it takes the entire DataFrame) with a random seed (random_state=42 ensures reproducibility)..reset_index(drop=True): After shuffling, the indices are reset, and drop=True means the old index column is dropped.So, after this line is executed, df_shuffled contains a shuffled version of the original DataFrame df. Each row is randomly ordered, and the indices are reset.\",\n",
       "  'code': '',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user', 'text': \"don't we have to use shuffle command\"},\n",
       " {'role': 'assistant',\n",
       "  'text': \"You are correct, and I appreciate the clarification. The df.sample(frac=1, random_state=42).reset_index(drop=True) is indeed a way to shuffle the DataFrame, and it's equivalent to shuffling using the shuffle method from sklearn.utils. Both approaches achieve the same result.If you prefer to use shuffle from sklearn.utils, you can do it like this\\nThis accomplishes the same shuffling effect. Both methods are commonly used, and you can choose the one that you find more readable or convenient. Thank you for bringing this up!\",\n",
       "  'code': 'from sklearn.utils import shuffle df_shuffled = shuffle(df, random_state=42).reset_index(drop=True)',\n",
       "  'commentCode': '# Shuffle the dataset using sklearn.utils.shuffle'},\n",
       " {'role': 'user', 'text': 'reset_index(drop=True) what is this'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"The reset_index(drop=True) method is used to reset the index of a DataFrame and, if drop=True, discard the old index. Let me explain this in more detail:reset_index(): By default, this method resets the index of the DataFrame. When you shuffle or manipulate a DataFrame, the index might get out of order or contain gaps. The reset_index() method is used to reset the DataFrame's index to the default integer-based one and creates a new DataFrame.drop=True: This parameter is optional, and when set to True, it discards the old index column. Without drop=True, the old index becomes a new column in the DataFrame.Here's an example to illustrate\\nIn the above example, reset_index(drop=True) is used to reset the index and drop the old index column. This is often used after operations like shuffling, where the original order of rows may not be necessary.\",\n",
       "  'code': 'import pandas as pd data = {\\'A\\': [1, 2, 3], \\'B\\': [4, 5, 6]} df = pd.DataFrame(data) print(\"Original DataFrame:\") print(df) df_reset = df.reset_index(drop=True) print(\"\\\\nDataFrame after resetting the index:\") print(df_reset)',\n",
       "  'commentCode': '# Create a simple DataFrame for demonstration # Display the original DataFrame # Reset the index, dropping the old index column # Display the DataFrame after resetting the index'},\n",
       " {'role': 'user',\n",
       "  'text': \"Correlations of features with health (4 points) Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\\n\\nFeature Selection (3 points) Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\\n\\nHypothetical Driver Features (3 points) Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable. This is the task that you have to code\"},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Certainly! Let\\'s start by calculating the correlations for all features in the dataset, highlighting strong correlations with the target variable (\\'health_metrics\\'), and then proceed with feature selection and proposing two hypothetical features. I\\'ll use the corr method to calculate correlations and seaborn for plotting a heatmap.pythonCopy codeimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Calculate correlations for all features\\ncorrelations = df.corr()\\n\\n# Highlight strong correlations with the target variable (\\'health_metrics\\')\\ntarget_correlations = correlations[\\'health_metrics\\'].sort_values(ascending=False)\\nstrong_correlations = target_correlations[abs(target_correlations) > 0.5]\\n\\n# Plot correlations in a heatmap\\nplt.figure(figsize=(12, 8))\\nsns.heatmap(correlations, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\nplt.title(\\'Correlation Heatmap\\')\\nplt.show()\\n\\n# Display features with strong correlations with the target variable\\nprint(\"\\\\nFeatures with strong correlations with \\'health_metrics\\':\")\\nprint(strong_correlations)\\n\\n# Feature Selection (you can customize this based on your dataset and business context)\\nselected_features = [\\'flipper_length_mm\\', \\'body_mass_g\\', \\'diet\\', \\'sex\\', \\'island\\']\\n\\n# Display the selected features\\nprint(\"\\\\nSelected features for prediction:\")\\nprint(selected_features)\\n\\n# Hypothetical Driver Features\\n# Let\\'s propose two hypothetical features and calculate their correlations with the target variable\\n# You can replace these with meaningful hypothetical features based on your domain knowledge\\n\\n# Hypothetical Feature 1: \\'temperature\\'\\n# Deriving a hypothetical temperature feature\\ndf[\\'temperature\\'] = df[\\'year\\'] * 10  # Just an example, replace with a meaningful calculation\\ncorr_temp = df[\\'temperature\\'].corr(df[\\'health_metrics\\'])\\nprint(\"\\\\nCorrelation between \\'temperature\\' and \\'health_metrics\\':\", corr_temp)\\n\\n# Hypothetical Feature 2: \\'ocean_current_speed\\'\\n# Deriving a hypothetical ocean current speed feature\\ndf[\\'ocean_current_speed\\'] = df[\\'flipper_length_mm\\'] / df[\\'body_mass_g\\']  # Just an example, replace with a meaningful calculation\\ncorr_current_speed = df[\\'ocean_current_speed\\'].corr(df[\\'health_metrics\\'])\\nprint(\"Correlation between \\'ocean_current_speed\\' and \\'health_metrics\\':\", corr_current_speed)\\nIn this code:The correlations are calculated using the corr method.A heatmap is created using seaborn to visualize the correlations.Features with strong correlations with the target variable are displayed.Feature selection is done manually based on correlation values and business context.Two hypothetical features (\\'temperature\\' and \\'ocean_current_speed\\') are proposed, and their correlations with the target variable are calculated.Please customize the feature selection and hypothetical features based on your dataset and domain knowledge.',\n",
       "  'code': '',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': 'orrelations of features with health (4 points) Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap. Just this part'},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Certainly! Here\\'s the code to calculate the correlations for all features in the dataset, highlight strong correlations with the target variable (\\'health_metrics\\'), and plot the results in a heatmap\\nIn this code:The correlations are calculated using the corr method.Strong correlations with the target variable (\\'health_metrics\\') are highlighted.A heatmap is created using seaborn to visualize the correlations.You can adjust the threshold value (0.5 in this case) based on your definition of a \"strong correlation.\" Feel free to customize the code to better suit your specific requirements and preferences.',\n",
       "  'code': 'import seaborn as sns import matplotlib.pyplot as plt correlations = df.corr() target_correlations = correlations[\\'health_metrics\\'].sort_values(ascending=False) strong_correlations = target_correlations[abs(target_correlations) > 0.5] plt.figure(figsize=(12, 8)) sns.heatmap(correlations[[\\'health_metrics\\']], annot=True, cmap=\\'coolwarm\\', fmt=\".2f\") plt.title(\\'Correlation Heatmap with Target Variable (health_metrics)\\') plt.show() print(\"\\\\nFeatures with strong correlations with \\'health_metrics\\':\") print(strong_correlations)',\n",
       "  'commentCode': \"# Calculate correlations for all features # Highlight strong correlations with the target variable ('health_metrics') # Plot correlations in a heatmap # Display features with strong correlations with the target variable\"},\n",
       " {'role': 'user',\n",
       "  'text': '# code here\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n# Calculate correlations for all features\\ncorrelations = df.corr()\\n\\n# Highlight strong correlations with the target variable (\\'health_metrics\\')\\ntarget_correlations = correlations[\\'health_metrics\\'].sort_values(ascending=False)\\nprint(target_correlations)\\n\\n\\n# Plot correlations in a heatmap\\nplt.figure(figsize=(12, 8))\\nsns.heatmap(correlations[[\\'health_metrics\\']], annot=True, cmap=\\'coolwarm\\', fmt=\".2f\")\\nplt.title(\\'Correlation Heatmap with Target Variable (health_metrics)\\')\\nplt.show()'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Your code looks correct and should calculate the correlations for all features in the dataset, print the correlations with the target variable ('health_metrics'), and then plot the results in a heatmap. Just ensure that your DataFrame (df) is correctly loaded with the data.Here's a brief explanation of your code\\n\",\n",
       "  'code': 'import seaborn as sns import matplotlib.pyplot as plt correlations = df.corr()',\n",
       "  'commentCode': \"# Calculate correlations for all features # Print correlations with the target variable ('health\"},\n",
       " {'role': 'user',\n",
       "  'text': 'species             NaN\\nisland              NaN\\nbill_length_mm      NaN\\nbill_depth_mm       NaN\\nflipper_length_mm   NaN\\nbody_mass_g         NaN\\nsex                 NaN\\ndiet                NaN\\nlife_stage          NaN\\nhealth_metrics      NaN\\nyear                NaN\\nyear_label          NaN\\nName: health_metrics, dtype: float64\\n/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:202: RuntimeWarning: All-NaN slice encountered\\n  vmin = np.nanmin(calc_data)\\n/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py:207: RuntimeWarning: All-NaN slice encountered\\n  vmax = np.nanmax(calc_data) WHY I SEE NAN'},\n",
       " {'role': 'assistant',\n",
       "  'text': 'If you\\'re seeing NaN (Not a Number) values in the correlation results, it may indicate that there are missing or non-numeric values in your dataset. The NaN values are likely affecting the calculation of correlations. Here are a few things to check and address:Check for Missing Values:Use df.isnull().sum() to check for missing values in your DataFrame. If there are missing values, you might want to handle them by either filling them or dropping the corresponding rows.pythonCopy code# Check for missing values\\nmissing_values = df.isnull().sum()\\nprint(\"Missing values in the dataset:\")\\nprint(missing_values)\\nEnsure Numeric Data:Ensure that all columns in your DataFrame are numeric. If there are non-numeric columns, they might be causing issues with the correlation calculation.pythonCopy code# Display data types of each column\\nprint(\"Data types of each column:\")\\nprint(df.dtypes)\\nHandle Categorical Data:If you have categorical columns (e.g., \\'species\\', \\'sex\\', \\'diet\\', \\'life_stage\\', etc.), you might want to encode them numerically before calculating correlations.pythonCopy code# Example: Encoding categorical columns\\nfrom sklearn.preprocessing import LabelEncoder\\n\\nlabel_encoder = LabelEncoder()\\ndf[\\'species\\'] = label_encoder.fit_transform(df[\\'species\\'])\\ndf[\\'sex\\'] = label_encoder.fit_transform(df[\\'sex\\'])\\n# ... repeat for other categorical columns ...\\nMake sure to handle missing values and encode categorical variables appropriately, and then rerun the code to calculate correlations. If the issue persists, please provide more details about your dataset and any preprocessing steps you have applied.',\n",
       "  'code': '',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': \"A value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['sex'] = df['sex'].map(sex_map)\\n<ipython-input-101-687cc92bb4e3>:30: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['island'] = df['island'].map(island_map)\\n<ipython-input-101-687cc92bb4e3>:31: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['diet'] = df['diet'].map(diet_map)\\n<ipython-input-101-687cc92bb4e3>:32: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['life_stage'] = df['life_stage'].map(life_stage_map)\\n<ipython-input-101-687cc92bb4e3>:33: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['health_metrics'] = df['health_metrics'].map(health_metrics_map)\\n<ipython-input-101-687cc92bb4e3>:34: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['species'] = df['species'].map(species_map)\\n<ipython-input-101-687cc92bb4e3>:38: SettingWithCopyWarning: \\nA value is trying to be set on a copy of a slice from a DataFrame.\\nTry using .loc[row_indexer,col_indexer] = value instead\\n\\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\\n  df['year'] = label_encoder.fit_transform(df['year']) Bu ne demek istiyor\"},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Bu uyarÄ± (warning) genellikle bir DataFrame Ã¼zerinde yapÄ±lan iÅ\\x9flemler sÄ±rasÄ±nda, orijinal DataFrame'in bir kopyasÄ± Ã¼zerinde deÄ\\x9fiÅ\\x9fiklik yapma durumunda ortaya Ã§Ä±kar. Bu durum, pandas'Ä±n bellek tasarrufu ve performans nedeniyle bazÄ± iÅ\\x9flemlerde kopyalama yerine bir gÃ¶rÃ¼nÃ¼m (view) oluÅ\\x9fturmasÄ±yla ilgilidir.UyarÄ±, genellikle iÅ\\x9flemleri daha gÃ¼venli ve aÃ§Ä±k bir Å\\x9fekilde yapmak iÃ§in df.loc[] kullanmanÄ±n Ã¶nerildiÄ\\x9fi durumlarda ortaya Ã§Ä±kar. loc kullanmak, DataFrame Ã¼zerinde gerÃ§ekten bir atama iÅ\\x9flemi gerÃ§ekleÅ\\x9ftirdiÄ\\x9fi iÃ§in bu tÃ¼r uyarÄ±larÄ± Ã¶nleyebilir.Ã\\x96rneÄ\\x9fin, Å\\x9fu kod\\nBenzer deÄ\\x9fiÅ\\x9fiklikleri diÄ\\x9fer satÄ±rlar iÃ§in de yapabilirsiniz.Ancak, bu uyarÄ±lar sadece bir bilgilendirme amaÃ§lÄ±dÄ±r ve Ã§oÄ\\x9fu durumda iÅ\\x9flemlerinizi etkilemez. EÄ\\x9fer kodunuz beklediÄ\\x9finiz gibi Ã§alÄ±Å\\x9fÄ±yorsa ve uyarÄ±lar sizi rahatsÄ±z etmiyorsa, iÅ\\x9flemlerinizi devam ettirebilirsiniz. Ancak, uyarÄ±larÄ± Ã¶nlemek ve daha aÃ§Ä±k bir kod yazmak iÃ§in loc kullanÄ±mÄ±nÄ± tercih edebilirsiniz.\",\n",
       "  'code': \"df['sex'] = df['sex'].map(sex_map) yerine Å\\x9fu Å\\x9fekilde yazÄ±labilir:pythonCopy codedf.loc[:, 'sex'] = df['sex'].map(sex_map)\",\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': \"Hypothetical Driver Features (3 points) Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable. Can you do this part\"},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Certainly! Let\\'s propose two hypothetical features and calculate their correlations with the target variable (\\'health_metrics\\'). For demonstration purposes, I\\'ll create two simple hypothetical features: \\'temperature\\' and \\'interaction_feature\\'. Please replace these with meaningful features based on your domain knowledge.pythonCopy code# Hypothetical Feature 1: \\'temperature\\'\\n# Deriving a hypothetical temperature feature\\ndf[\\'temperature\\'] = df[\\'year\\'] * 10  # Just an example, replace with a meaningful calculation\\ncorr_temp = df[\\'temperature\\'].corr(df[\\'health_metrics\\'])\\nprint(\"Correlation between \\'temperature\\' and \\'health_metrics\\':\", corr_temp)\\n\\n# Hypothetical Feature 2: \\'interaction_feature\\'\\n# Creating a hypothetical interaction feature\\ndf[\\'interaction_feature\\'] = df[\\'flipper_length_mm\\'] * df[\\'body_mass_g\\']  # Just an example, replace with a meaningful calculation\\ncorr_interaction = df[\\'interaction_feature\\'].corr(df[\\'health_metrics\\'])\\nprint(\"Correlation between \\'interaction_feature\\' and \\'health_metrics\\':\", corr_interaction)\\nIn this example:\\'temperature\\' is a hypothetical feature derived from the \\'year\\' column. The idea here is that the health of penguins might be influenced by the temperature, and \\'year\\' could be a proxy for changing temperature conditions. Replace the calculation with a meaningful one based on your knowledge.\\'interaction_feature\\' is a hypothetical feature created by multiplying \\'flipper_length_mm\\' and \\'body_mass_g\\'. The idea here is that there might be an interaction effect between these two physical characteristics of penguins that could impact health.Note: These are just examples, and you should replace them with features that make sense in the context of your data and domain knowledge. Always ensure that your features have a logical and meaningful interpretation in the context of your problem.',\n",
       "  'code': '',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': 'Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters (Hyperparameters are listed under \"Parameters\" in the documentation). Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)  Can you pick max_depth  and max_samples_split and code it '},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! For a decision tree classifier in scikit-learn, two commonly tuned hyperparameters are max_depth and min_samples_split. Here's an example of how you can use GridSearchCV to tune these hyperparameters\\nIn this example:max_depth is the maximum depth of the tree, and min_samples_split is the minimum number of samples required to split an internal node.The param_grid dictionary defines the hyperparameters and their possible values.GridSearchCV performs a search over the specified hyperparameter values using 5-fold cross-validation and selects the best combination based on accuracy.The best hyperparameter values are printed, and the best model is then evaluated on the test set to get the validation accuracy.Adjust the parameter grid, scoring metric, and other settings based on your specific requirements and the nature of your dataset.\",\n",
       "  'code': 'from sklearn.model_selection import GridSearchCV from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split dt_classifier = DecisionTreeClassifier() param_grid = {     \\'max_depth\\': [3, 5, 7, None],  # None means no maximum depth     \\'min_samples_split\\': [2, 5, 10] } grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring=\\'accuracy\\') grid_search.fit(X_train, y_train) print(\"Best Hyperparameters:\", grid_search.best_params_) best_dt_model = grid_search.best_estimator_ test_accuracy = best_dt_model.score(X_test, y_test) print(\"Validation Accuracy with Best Hyperparameters:\", test_accuracy)',\n",
       "  'commentCode': '# Assuming you have your features (X) and target variable (y) defined # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Define the decision tree classifier # Specify the hyperparameters and their possible values # Create the GridSearchCV object # Fit the model to the data to find the best hyperparameters # Print the best hyperparameter values # Get the best model # Evaluate the model on the test set'},\n",
       " {'role': 'user',\n",
       "  'text': 'Re-train model with the hyperparameters you have chosen in part 5). (10 pts)\\nPlot the tree you have trained. (5 pts)\\nHint: You can import the plot_tree function from the sklearn library. Whe have chosen max depth and min sample split can you code this part'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! After tuning the hyperparameters using GridSearchCV, you can re-train the model with the best hyperparameters and plot the decision tree. Here's how you can do that\\nIn this code:We retrieve the best hyperparameters from the GridSearchCV results.We create a new DecisionTreeClassifier instance with the best hyperparameters.We fit the model to the training data using these hyperparameters.We use plot_tree to visualize the decision tree.Make sure to replace X_train and X_test with your actual training and testing data. The plot_tree function will help you visualize the trained decision tree with the specified hyperparameters.\",\n",
       "  'code': 'from sklearn.tree import DecisionTreeClassifier, plot_tree import matplotlib.pyplot as plt best_max_depth = grid_search.best_params_[\\'max_depth\\'] best_min_samples_split = grid_search.best_params_[\\'min_samples_split\\'] best_dt_model = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split) best_dt_model.fit(X_train, y_train) plt.figure(figsize=(15, 10)) plot_tree(best_dt_model, feature_names=X_train.columns, class_names=best_dt_model.classes_, filled=True, rounded=True) plt.title(\"Decision Tree with Best Hyperparameters\") plt.show()',\n",
       "  'commentCode': '# Assuming you have X_train, X_test, y_train, y_test from previous code # Re-train the model with the best hyperparameters # Create the decision tree classifier with the best hyperparameters # Fit the model to the training data # Plot the decision tree'},\n",
       " {'role': 'user',\n",
       "  'text': 'Re-train model with the hyperparameters you have chosen in part 5). (10 pts) can you code this part and then Plot the tree you have trained. (5 pts) this part seperatly'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! Let's first re-train the model with the best hyperparameters and then plot the trained decision tree separately:Re-train model with the best hyperparameters\\nIn the first part, we re-train the model using the best hyperparameters obtained from the grid search. In the second part, we use plot_tree to visualize the trained decision tree. Adjust the code based on your actual dataset and variable names.\",\n",
       "  'code': 'from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score best_max_depth = grid_search.best_params_[\\'max_depth\\'] best_min_samples_split = grid_search.best_params_[\\'min_samples_split\\'] best_dt_model = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split) best_dt_model.fit(X_train, y_train) y_pred = best_dt_model.predict(X_test) test_accuracy = accuracy_score(y_test, y_pred) print(\"Test Accuracy with Best Hyperparameters:\", test_accuracy) Plot the trained decision tree:pythonCopy codefrom sklearn.tree import plot_tree import matplotlib.pyplot as plt plt.figure(figsize=(15, 10)) plot_tree(best_dt_model, feature_names=X_train.columns, class_names=best_dt_model.classes_, filled=True, rounded=True) plt.title(\"Decision Tree with Best Hyperparameters\") plt.show()',\n",
       "  'commentCode': '# Assuming you have X_train, X_test, y_train, y_test from previous code # Re-train the model with the best hyperparameters # Create the decision tree classifier with the best hyperparameters # Fit the model to the training data # Make predictions on the test set # Evaluate the model accuracy on the test set # Plot the decision tree'},\n",
       " {'role': 'user',\n",
       "  'text': '---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\n<ipython-input-120-c168748c2af7> in <cell line: 8>()\\n      6 # Plot the decision tree\\n      7 plt.figure(figsize=(15, 10))\\n----> 8 plot_tree(best_dt_model, feature_names=X_train.columns, class_names=best_dt_model.classes_, filled=True, rounded=True)\\n      9 plt.title(\"Decision Tree with Best Hyperparameters\")\\n     10 plt.show()\\n\\n3 frames\\n/usr/local/lib/python3.10/dist-packages/sklearn/tree/_export.py in node_to_str(self, tree, node_id, criterion)\\n    371                     characters[2],\\n    372                 )\\n--> 373             node_string += class_name\\n    374 \\n    375         # Clean up any trailing newlines\\n\\nTypeError: can only concatenate str (not \"numpy.int64\") to str'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"It seems like there is an issue with concatenating a NumPy integer (numpy.int64) to a string. This issue is likely related to the class_names argument when using the plot_tree function. The class_names argument expects an iterable of strings representing the class names, but it appears to be receiving an integer.To resolve this issue, we need to convert the class names to strings. If your classes are represented by integers, you can convert them to strings before passing them to the plot_tree function.Here's an updated version of the code\\nIn this updated code, I used list(map(str, best_dt_model.classes_)) to convert the class names to strings before passing them to the plot_tree function. This should resolve the TypeError you encountered. Adjust the code based on your specific dataset and class representation.\",\n",
       "  'code': 'from sklearn.tree import DecisionTreeClassifier, plot_tree import matplotlib.pyplot as plt best_max_depth = grid_search.best_params_[\\'max_depth\\'] best_min_samples_split = grid_search.best_params_[\\'min_samples_split\\'] best_dt_model = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split) best_dt_model.fit(X_train, y_train) plt.figure(figsize=(15, 10)) plot_tree(best_dt_model, feature_names=X_train.columns, class_names=list(map(str, best_dt_model.classes_)), filled=True, rounded=True) plt.title(\"Decision Tree with Best Hyperparameters\") plt.show()',\n",
       "  'commentCode': '# Assuming you have X_train, X_test, y_train, y_test from previous code # Re-train the model with the best hyperparameters # Create the decision tree classifier with the best hyperparameters # Fit the model to the training data # Plot the decision tree'},\n",
       " {'role': 'user',\n",
       "  'text': 'from sklearn.tree import plot_tree\\n\\n#code here\\n\\n\\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\\nimport matplotlib.pyplot as plt\\n\\n# Assuming you have X_train, X_test, y_train, y_test from previous code\\n\\n# Re-train the model with the best hyperparameters\\nbest_max_depth = grid_search.best_params_[\\'max_depth\\']\\nbest_min_samples_split = grid_search.best_params_[\\'min_samples_split\\']\\n\\n# Create the decision tree classifier with the best hyperparameters\\nbest_dt_model_2 = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\\n\\n# Fit the model to the training data\\nbest_dt_model_2.fit(X_train, y_train)\\n\\n# Plot the decision tree\\nplt.figure(figsize=(15, 10))\\nplot_tree(best_dt_model_2, feature_names=X_train.columns, class_names=list(map(str, best_dt_model.classes_)), filled=True, rounded=True)\\nplt.title(\"Decision Tree with Best Hyperparameters\")\\nplt.show()\\n Ä± have uptaded like this we will use that so keep in mind'},\n",
       " {'role': 'assistant',\n",
       "  'text': 'Great! It looks like you\\'ve updated the code correctly. The use of best_dt_model_2 is now consistent throughout the code, and you\\'ve converted the class names to strings before passing them to plot_tree. This should resolve the TypeError.pythonCopy codefrom sklearn.tree import DecisionTreeClassifier, plot_tree\\nimport matplotlib.pyplot as plt\\n\\n# Assuming you have X_train, X_test, y_train, y_test from previous code\\n\\n# Re-train the model with the best hyperparameters\\nbest_max_depth = grid_search.best_params_[\\'max_depth\\']\\nbest_min_samples_split = grid_search.best_params_[\\'min_samples_split\\']\\n\\n# Create the decision tree classifier with the best hyperparameters\\nbest_dt_model_2 = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\\n\\n# Fit the model to the training data\\nbest_dt_model_2.fit(X_train, y_train)\\n\\n# Plot the decision tree\\nplt.figure(figsize=(15, 10))\\nplot_tree(best_dt_model_2, feature_names=X_train.columns, class_names=list(map(str, best_dt_model_2.classes_)), filled=True, rounded=True)\\nplt.title(\"Decision Tree with Best Hyperparameters\")\\nplt.show()\\nThis code should now correctly visualize the decision tree with the best hyperparameters. If you encounter any further issues or have additional questions, feel free to ask!',\n",
       "  'code': '',\n",
       "  'commentCode': ''},\n",
       " {'role': 'user',\n",
       "  'text': 'Predict the labels of testing data using the tree you have trained in step 6  (This is the code that Ä± have just provided). (10 pts)\\nReport the classification accuracy. (2 pts)\\nPlot & investigate the confusion matrix. Fill the following blanks. (8 pts)\\nThe model most frequently mistakes class(es) _____ for class(es) _____.\\n\\nHint: You can use the confusion_matrix function from sklearn.metrics What do Ä± heve to do on this task '},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! Here's the code for predicting labels on the testing data, reporting the classification accuracy, and plotting the confusion matrix\\nIn this code:We use the trained decision tree model (best_dt_model_2) to predict labels on the testing data (X_test).The classification accuracy is then reported using the accuracy_score function.We calculate the confusion matrix using the confusion_matrix function.The confusion matrix is then plotted using seaborn to visually inspect the model's performance.To fill in the blanks regarding the most frequently mistaken classes, you can examine the confusion matrix. Look for entries where the actual class is one value, but the predicted class is another. The confusion matrix heatmap will help you identify which classes are often confused with each other.\",\n",
       "  'code': 'from sklearn.metrics import accuracy_score, confusion_matrix import seaborn as sns import matplotlib.pyplot as plt y_pred_test = best_dt_model_2.predict(X_test) test_accuracy = accuracy_score(y_test, y_pred_test) print(\"Test Accuracy:\", test_accuracy) conf_matrix = confusion_matrix(y_test, y_pred_test) plt.figure(figsize=(8, 6)) sns.heatmap(conf_matrix, annot=True, fmt=\\'d\\', cmap=\\'Blues\\', cbar=False) plt.title(\"Confusion Matrix\") plt.xlabel(\"Predicted Labels\") plt.ylabel(\"True Labels\") plt.show()',\n",
       "  'commentCode': '# Assuming you have X_test and y_test from previous code # Predict labels on the testing data # Report the classification accuracy # Plot the confusion matrix # Plotting the confusion matrix using seaborn'},\n",
       " {'role': 'user',\n",
       "  'text': 'Find the information gain on the first split with Entropy according to the formula INFORMATÄ°ON GAIN= ENTROPY(PARENT) - [AVERAGE ENTROPY(CHÄ°LDREN)]. Can you code it'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! To calculate information gain for the first split using entropy, you'll need to follow these steps:Calculate the entropy of the parent node.Calculate the weighted average entropy of the child nodes.Subtract the weighted average entropy from the entropy of the parent node.Here's an example code snippet to calculate information gain for the first split in a decision tree using entropy\\nPlease note that this example assumes a binary split. If your tree has more than two children at the first split, you'll need to adapt the code accordingly. The calculate_entropy function is used to compute the entropy of a node based on the labels.\",\n",
       "  'code': 'from sklearn.tree import DecisionTreeClassifier from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split import numpy as np iris = load_iris() X = iris.data y = iris.target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) dt_classifier = DecisionTreeClassifier(random_state=42) dt_classifier.fit(X_train, y_train) def calculate_entropy(labels):     unique_labels, label_counts = np.unique(labels, return_counts=True)     probabilities = label_counts / len(labels)     entropy = -np.sum(probabilities * np.log2(probabilities))     return entropy first_split_indices = np.where(dt_classifier.tree_.children_left == 1)[0] parent_entropy = calculate_entropy(y_train) left_child_labels = y_train[first_split_indices] left_child_entropy = calculate_entropy(left_child_labels) right_child_labels = y_train[~np.isin(np.arange(len(y_train)), first_split_indices)] right_child_entropy = calculate_entropy(right_child_labels) weighted_avg_entropy_children = (     (len(left_child_labels) / len(y_train)) * left_child_entropy +     (len(right_child_labels) / len(y_train)) * right_child_entropy ) information_gain = parent_entropy - weighted_avg_entropy_children print(\"Information Gain on the first split:\", information_gain)',\n",
       "  'commentCode': '# Load the iris dataset as an example # Split the dataset into training and testing sets # Create a decision tree classifier (you can use your trained model) # Calculate entropy of a node (parent or child) # Get indices of samples in the first split # Calculate entropy of the parent node # Calculate entropy of the left child node (assuming binary split) # Calculate entropy of the right child node # Calculate the weighted average entropy of the children # Calculate information gain'},\n",
       " {'role': 'user', 'text': 'can you code it with the codes that Ä± provided'},\n",
       " {'role': 'assistant',\n",
       "  'text': \"Certainly! Here's how you can calculate the information gain on the first split using entropy with the decision tree model you trained\\nIn this code:best_dt_model_2.tree_.impurity provides the impurity (entropy) values for each node in the tree.best_dt_model_2.tree_.children_left and best_dt_model_2.tree_.children_right provide indices of the left and right children of each node.We extract the indices of samples in the first split and calculate entropy for the parent, left child, and right child nodes.Information gain is then computed as the difference between the entropy of the parent and the weighted average entropy of the children.This code should work with the decision tree model you trained earlier.\",\n",
       "  'code': 'from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split import numpy as np first_split_indices = np.where(best_dt_model_2.tree_.children_left == 1)[0] parent_entropy = best_dt_model_2.tree_.impurity[0] left_child_labels = y_train[first_split_indices] left_child_entropy = best_dt_model_2.tree_.impurity[best_dt_model_2.tree_.children_left[0]] right_child_labels = y_train[~np.isin(np.arange(len(y_train)), first_split_indices)] right_child_entropy = best_dt_model_2.tree_.impurity[best_dt_model_2.tree_.children_right[0]] weighted_avg_entropy_children = (     (len(left_child_labels) / len(y_train)) * left_child_entropy +     (len(right_child_labels) / len(y_train)) * right_child_entropy ) information_gain = parent_entropy - weighted_avg_entropy_children print(\"Information Gain on the first split:\", information_gain)',\n",
       "  'commentCode': '# Assuming you have X_train, X_test, y_train, y_test, best_dt_model_2 from previous code # Get indices of samples in the first split # Calculate entropy of the parent node # Calculate entropy of the left child node # Calculate entropy of the right child node # Calculate the weighted average entropy of the children # Calculate information gain'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2convos[\"41b82427-7ae2-4c55-b8a3-310bb4abada0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to do:\n",
    "- Prompt matching with questions\n",
    "- Feature Engineering\n",
    "- Question Grades preparation\n",
    "- Train/Test split\n",
    "- Fitting a model for predicting the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Matching\n",
    "> We want to match the prompts with the questions in the Homework Let's\n",
    "> do it with a simple term frequency vectorizing method. For each prompt,\n",
    "> we will come with a vector that represents it. We will do the same\n",
    "> thing with each of the homework questions. Then, we will calculate the\n",
    "> vectors distanance to do the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompts -> butun promptlar tek listede\n",
    "#code2prompts -> keyler html adlari , value olarak da o htmldeki promptların listesi\n",
    "\n",
    "\n",
    "prompts = []\n",
    "code2prompts = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"])\n",
    "            user_prompts.append(conv[\"text\"])\n",
    "    code2prompts[code] = user_prompts    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Give an example of how to plot a heat map of a specific results with \"matplotlib\"',\n",
       " 'How to select a subset of features that are likely strong predictors, justifying them based on calculated correlations',\n",
       " 'How to use isnull()',\n",
       " 'How to do dataset comparison',\n",
       " 'How to separate the dependent variable X from the independent variable y',\n",
       " 'How to split training and testing sets by 80% and 20% respectively',\n",
       " 'How to calculate correlations of all features in a dataset',\n",
       " 'How to select a subset of features that are likely strong predictors, justifying them based on correlations',\n",
       " 'How to choose the best hypermeter?',\n",
       " 'How to apply hypermeter',\n",
       " 'training of hypermeters',\n",
       " 'How can I visualize the trained tree?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2prompts[\"6312a21b-c6be-44f9-ad81-46307b339fb6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_code_comments(data):\n",
    "    user_code_dict = {}\n",
    "    user_comment_dict = {}\n",
    "\n",
    "    for key, values in data.items():\n",
    "        for item in values:\n",
    "            if item['role'] == 'assistant':\n",
    "                user_code_dict[key] = item.get('code', '')\n",
    "                user_comment_dict[key] = item.get('commentCode', '')\n",
    "\n",
    "    return user_code_dict, user_comment_dict\n",
    "\n",
    "# Example usage\n",
    "code_dict, comment_dict = extract_user_code_comments(code2convos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS MODIFIED( point indicators etc. omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"\n",
    "First make a copy of the notebook given to you as a starter.\n",
    "Make sure you choose Connect form upper right.\n",
    "You may upload the data to the section on your left on Colab, than right click on the .csv file and get the path of the file by clicking on \"Copy Path\". You will be using it when loading the data.\n",
    "\n",
    "\"\"\",\n",
    "#####################\n",
    "    \"\"\"Load training dataset Read the .csv file with the pandas library\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"\n",
    "Find the shape of the dataset (number of samples & number of attributes). (Hint: You can use the **shape** function)\n",
    "Display variable names (both dependent and independent).\n",
    "Display the summary of the dataset. (Hint: You can use the **info** function)\n",
    "Display the first 5 rows from training dataset. (Hint: You can use the **head** function)\n",
    "\n",
    "\n",
    "Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. **Be careful that you have enough data for training the  model.**\n",
    "\n",
    "Encode categorical labels with the mappings given in the cell below. (Hint: You can use **map** function)\n",
    "\"\"\",\n",
    "\"\"\"Set X & y, split data\n",
    "\n",
    "Shuffle the dataset.\n",
    "Seperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\n",
    "Split training and test sets as 80% and 20%, respectively.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"\n",
    "\n",
    "Correlations of features with health \n",
    "Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\n",
    "\n",
    "\n",
    "Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\n",
    "\n",
    "\n",
    "Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable.\n",
    "\n",
    "\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"\n",
    "Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\n",
    "Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Re-train and plot the decision tree with the hyperparameters you have chosen\n",
    "Re-train model with the hyperparameters you have chosen \n",
    "Plot the tree you have trained\n",
    "Hint: You can import the **plot_tree** function from the sklearn library.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Test your classifier on the test set\n",
    "Predict the labels of testing data using the tree you have trained\n",
    "Report the classification accuracy.\n",
    "Plot & investigate the confusion matrix. Fill the following blanks. \n",
    "> The model most frequently mistakes class(es) _________ for class(es) _________.\n",
    "Hint: You can use the confusion_matrix function from sklearn.metrics\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Find the information gain on the first split\"\"\",\n",
    "#####################\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATING SIMILARITY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_similarity(prompt, questions):\n",
    "\n",
    "    # Encode prompt and questions\n",
    "    prompt_embedding = model.encode(prompt, convert_to_tensor=True)\n",
    "    question_embeddings = model.encode(questions, convert_to_tensor=True)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_scores = util.pytorch_cos_sim(prompt_embedding, question_embeddings)\n",
    "\n",
    "    # Convert the tensor to a list of similarity scores\n",
    "    similarity_scores = cosine_scores.tolist()[0]\n",
    "\n",
    "    return similarity_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING BASE DICTIONARY IN THE SPECIFIED FORMAT\n",
    "\n",
    "#### Result dict contains {\"htmlfilename\": [ [sim1,sim2,....sim9],[sim1,sim2,....sim9],[sim1,sim2,....sim9] .... ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result dict contains {\"htmlfilename\": [ [sim1,sim2,....sim9],[sim1,sim2,....sim9],[sim1,sim2,....sim9] .... ]\n",
    "\n",
    "result_dict = {}\n",
    "\n",
    "html_file_names = list(code2prompts.keys())\n",
    "\n",
    "for html_file in html_file_names:\n",
    "    prompts = code2prompts[html_file]\n",
    "    prompt_similarities = []\n",
    "\n",
    "    # Calculate similarity for each prompt and each question\n",
    "    for prompt in prompts:\n",
    "        similarity_scores = calculate_similarity(prompt, questions)\n",
    "        prompt_similarities.append(similarity_scores)\n",
    "\n",
    "    result_dict[html_file] = prompt_similarities\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW FILES ARE BROKEN. THEY GIVE 404 ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139235c7-736c-4237-92f0-92e8c116832c\n",
      "668ad17e-0240-49f7-b5a7-d22e502554c6\n",
      "b0640e51-6879-40cb-a4f5-329f952ef99d\n",
      "da6b70d5-29f6-491a-ad46-037c77067128\n"
     ]
    }
   ],
   "source": [
    "# BELOW FILES ARE CORRUPTED\n",
    "problems = []\n",
    "for key,value in code2prompts.items():\n",
    "    if len(code2prompts[key])==0:\n",
    "        print(key)\n",
    "        problems.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAKING MAXIMUM SIMILARITY FOR EACH QUESTION AMONG ALL PROMPTS FOR A SINGLE FILE\n",
    "\n",
    "#### IF FILE IS BROKEN, WE GIVE ALL 0 TO SIMILARITIES BETWEEN QUESTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML_File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Q0        Q1        Q2        Q3   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.242323  0.650830  0.639897  0.790342  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.412892  0.822821  0.696175  0.909993   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.173714  0.217742  0.274107  0.284707   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.285609  0.548311  0.439191  0.645035   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.444721  0.758592  0.872447  0.712806   \n",
       "\n",
       "                                            Q4        Q5        Q6        Q7   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.690072  0.788218  0.428342  0.461473  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.766648  0.987573  0.684214  0.729532   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.487476  0.249203  0.297617  0.538953   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.770841  0.659323  0.553139  0.538424   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.821277  0.916046  0.555504  0.945931   \n",
       "\n",
       "                                            Q8  \n",
       "HTML_File                                       \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.285456  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.491343  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.142434  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.426416  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.590542  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#TAKING MAXIMUM SIMILARITY FOR EACH QUESTION AMONG ALL PROMPTS FOR A SINGLE FILE\n",
    "\n",
    "#test_dict = {\"html_file_1\": [[0.1,0.2,0.1,0.1,0.1,0.1,0.1,0.1,0.1],[0.4,0.9,0.3,0.1,0.1,0.1,0.1,0.1,0.1]],\n",
    " #              \"html_file_2\": []}\n",
    "\n",
    "new_result_dict = {}\n",
    "\n",
    "for html_file, prompt_list in result_dict.items():\n",
    "    if not prompt_list:\n",
    "        continue\n",
    "        # If the prompt list is empty, WE ARE NOT ADDING ITS SIMILARITY\n",
    "        #new_result_dict[html_file] = [0.0] * 9\n",
    "    else:\n",
    "        # Pad the prompt_list with zeros if the number of questions is less than 9\n",
    "        prompt_list += [[0.0] * 9] * (9 - len(prompt_list))\n",
    "        # Calculate the maximum similarity for each question across all prompts\n",
    "        max_sims = [max(prompt_list[i][j] for i in range(len(prompt_list))) for j in range(9)]\n",
    "        new_result_dict[html_file] = max_sims\n",
    "        \n",
    "        \n",
    "        \n",
    "# Convert the related_questions_dict to a DataFrame\n",
    "df_prompt_matching = pd.DataFrame.from_dict(new_result_dict, orient='index')\n",
    "\n",
    "# Set column names as 'Q0', 'Q1', ..., 'Q8'\n",
    "df_prompt_matching.columns = [f'Q{i}' for i in range(df_prompt_matching.shape[1])]\n",
    "\n",
    "# Reset the index to make 'HTML_File' a column\n",
    "df_prompt_matching.reset_index(inplace=True)\n",
    "df_prompt_matching.rename(columns={'index': 'HTML_File'}, inplace=True)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df_prompt_matching.set_index('HTML_File', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_prompt_matching.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO HAVE AVERAGE SIMILARITY VALUES \n",
    "\n",
    "### i.e we are taking average between all sim1's sim2's among all prompts for a single prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML_File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>0.131876</td>\n",
       "      <td>0.285558</td>\n",
       "      <td>0.380305</td>\n",
       "      <td>0.294066</td>\n",
       "      <td>0.365903</td>\n",
       "      <td>0.294589</td>\n",
       "      <td>0.238968</td>\n",
       "      <td>0.332627</td>\n",
       "      <td>0.124415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>0.122576</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.337141</td>\n",
       "      <td>0.305693</td>\n",
       "      <td>0.296665</td>\n",
       "      <td>0.323831</td>\n",
       "      <td>0.312685</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.209524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>0.010530</td>\n",
       "      <td>0.111217</td>\n",
       "      <td>0.168907</td>\n",
       "      <td>0.115451</td>\n",
       "      <td>0.081844</td>\n",
       "      <td>0.124755</td>\n",
       "      <td>0.130175</td>\n",
       "      <td>0.235636</td>\n",
       "      <td>0.061148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>0.075920</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>0.277807</td>\n",
       "      <td>0.223789</td>\n",
       "      <td>0.240406</td>\n",
       "      <td>0.197946</td>\n",
       "      <td>0.239033</td>\n",
       "      <td>0.298362</td>\n",
       "      <td>0.167645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.156857</td>\n",
       "      <td>0.249157</td>\n",
       "      <td>0.239491</td>\n",
       "      <td>0.215537</td>\n",
       "      <td>0.198821</td>\n",
       "      <td>0.210744</td>\n",
       "      <td>0.289835</td>\n",
       "      <td>0.165927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Q0        Q1        Q2        Q3   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.131876  0.285558  0.380305  0.294066  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.122576  0.273231  0.337141  0.305693   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.010530  0.111217  0.168907  0.115451   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.075920  0.184396  0.277807  0.223789   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.069941  0.156857  0.249157  0.239491   \n",
       "\n",
       "                                            Q4        Q5        Q6        Q7   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.365903  0.294589  0.238968  0.332627  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.296665  0.323831  0.312685  0.376181   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.081844  0.124755  0.130175  0.235636   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.240406  0.197946  0.239033  0.298362   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.215537  0.198821  0.210744  0.289835   \n",
       "\n",
       "                                            Q8  \n",
       "HTML_File                                       \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.124415  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.209524  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.061148  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.167645  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.165927  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TO HAVE AVERAGE SIMILARITY VALUES \n",
    "\n",
    "avg_result_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the average similarity for each question across all prompts\n",
    "for html_file, similarities_list in result_dict.items():\n",
    "    num_prompts = len(similarities_list)\n",
    "    num_questions = len(similarities_list[0]) if num_prompts > 0 else 0\n",
    "\n",
    "    if num_prompts > 0:\n",
    "        avg_similarities = [sum(similarities_list[j][i] for j in range(num_prompts)) / num_prompts for i in range(num_questions)]\n",
    "    else:\n",
    "        avg_similarities = [0] * num_questions\n",
    "\n",
    "    avg_result_dict[html_file] = avg_similarities\n",
    "    \n",
    "\n",
    "    \n",
    "# Convert the dictionary to a DataFrame if needed\n",
    "df_avg_matching = pd.DataFrame.from_dict(avg_result_dict, orient='index', columns=[f'Q{i}' for i in range(len(avg_similarities))])\n",
    "\n",
    "# Reset the index to make 'HTML_File' a column\n",
    "df_avg_matching.reset_index(inplace=True)\n",
    "df_avg_matching.rename(columns={'index': 'HTML_File'}, inplace=True)\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df_avg_matching.set_index('HTML_File', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_avg_matching.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO HAVE YES OR NO TYPE OF MODEL\n",
    "\n",
    "### FOR A SINGLE FILE WE LOOK AT ALL sim1's among all the prompts, we identify the highest one and put a yes for corresponding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML_File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Q0   Q1   Q2   Q3   Q4   Q5   Q6   Q7   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883   No  Yes  Yes  Yes  Yes  Yes   No  Yes  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b   No  Yes  Yes  Yes  Yes  Yes  Yes  Yes   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b   No  Yes   No   No  Yes   No  Yes  Yes   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc   No  Yes  Yes  Yes  Yes  Yes  Yes  Yes   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  Yes  Yes  Yes  Yes  Yes  Yes  Yes  Yes   \n",
       "\n",
       "                                       Q8  \n",
       "HTML_File                                  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883   No  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  Yes  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b   No  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  Yes  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  Yes  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TO HAVE YES OR NO TYPE OF MODEL\n",
    "\n",
    "\n",
    "\n",
    "# Function to get the index of the maximum value in a list\n",
    "def get_max_index(lst):\n",
    "    return max(range(len(lst)), key=lst.__getitem__, default=None)\n",
    "\n",
    "# Create a new dictionary to store related questions for each HTML file\n",
    "yes_no_dict = {}\n",
    "\n",
    "for html_file, similarities_list in result_dict.items():\n",
    "    \n",
    "    # Get the index of the question with the highest similarity for each prompt\n",
    "    related_questions = [get_max_index(prompt) for prompt in similarities_list]\n",
    "\n",
    "    # Create a list indicating whether each question is related (Yes) or not (No)\n",
    "    is_related = ['Yes' if i in related_questions else 'No' for i in range(len(similarities_list[0]))] if similarities_list else ['No'] * 9\n",
    "\n",
    "    yes_no_dict[html_file] = is_related\n",
    "\n",
    "# Convert the related_questions_dict to a DataFrame\n",
    "df_yes_no = pd.DataFrame.from_dict(yes_no_dict, orient='index')\n",
    "\n",
    "# Set column names as 'Q0', 'Q1', ..., 'Q8'\n",
    "df_yes_no.columns = [f'Q{i}' for i in range(df_yes_no.shape[1])]\n",
    "\n",
    "# Reset the index to make 'HTML_File' a column\n",
    "df_yes_no.reset_index(inplace=True)\n",
    "df_yes_no.rename(columns={'index': 'HTML_File'}, inplace=True)\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df_yes_no.set_index('HTML_File', inplace=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_yes_no.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- Number of prompts that a uers asked\n",
    "- Number of complaints that a user makes e.g \"the code gives this error!\"\n",
    "- User prompts average number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def calculate_discomfort_count(text):\n",
    "    # Discomfort indicators\n",
    "    discomfort_keywords = [\"no\", \"not really\", \"confused\", \"error\",\"not correct\"\n",
    "                       \"disappointed\", \"frustrated\", \"annoyed\", \"doesn't work\", \"apologize\", \"does not work\",\n",
    "                       \"didn't work\", \"did not work\", \"wrong\",\"didnt work\",\"doesnt work\",\"didnt understand\",\n",
    "                           \"did not understand\", \"didn't understand\"\n",
    "                       \"assertionerror\", \"attributeerror\", \"eoferror\", \"floatingpointerror\",\n",
    "                       \"generatorexit\", \"importerror\", \"indexerror\", \"keyerror\", \"keyboardinterrupt\",\n",
    "                       \"memoryerror\", \"nameerror\", \"notimplementederror\", \"oserror\", \"overflowerror\",\n",
    "                       \"referenceerror\", \"runtimeerror\", \"stopiteration\", \"syntaxerror\",\n",
    "                       \"indentationerror\", \"taberror\", \"systemerror\", \"systemexit\", \"typeerror\",\n",
    "                       \"unboundlocalerror\", \"unicodeerror\", \"unicodeencodeerror\", \"unicodedecodeerror\",\n",
    "                       \"unicodetranslateerror\", \"valueerror\", \"zerodivisionerror\"]\n",
    "\n",
    "\n",
    "    # Count the number of discomfort indicators in the text\n",
    "    discomfort_count = sum(1 for keyword in discomfort_keywords if re.search(rf'\\b{re.escape(keyword)}\\b', text.lower(), flags=re.IGNORECASE))\n",
    "\n",
    "\n",
    "    return discomfort_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comfort_count(text):\n",
    "    # Comfort indicators\n",
    "    comfort_keywords = [\"good\", \"great\", \"awesome\", \"satisfied\", \"happy\", \"well done\", \"thank you\", \"excellent\",\"thanks\",\"worked\",\n",
    "                       \"works\",\"well\"]\n",
    "\n",
    "    # Count the number of comfort indicators in the text\n",
    "    comfort_count = sum(1 for keyword in comfort_keywords if re.search(rf'\\b{re.escape(keyword)}\\b', text.lower(), flags=re.IGNORECASE))\n",
    "\n",
    "    return comfort_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gpt_confusion(text):\n",
    "    confusion_keywords=[\"apologize\",\"confusion\",\"misunderstanding\",\"misunderstood\",\"apologies\",\"oversight\"]\n",
    "    confusion_count = sum(1 for keyword in confusion_keywords if re.search(rf'\\b{re.escape(keyword)}\\b', text.lower(), flags=re.IGNORECASE))\n",
    "\n",
    "    return confusion_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def sim_between_prompt_and_commentcode(user_message,gpt_code_comment):\n",
    "\n",
    "    message_embedding = model.encode(user_message, convert_to_tensor=True)\n",
    "    gpt_commentcode_embedding = model.encode(gpt_code_comment, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_scores = util.pytorch_cos_sim(message_embedding, gpt_commentcode_embedding)\n",
    "\n",
    "    # Convert the tensor to a list of similarity scores\n",
    "    similarity_scores = cosine_scores.tolist()[0]\n",
    "\n",
    "    return similarity_scores[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW FUNCTION USES WORD2VEC MODEL AND CALCULATES THE SIMILARITY AMONG ALL PROMPTS\n",
    "\n",
    "### used for identifying how similar the prompts are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "# Load the GloVe model\n",
    "model_name = \"glove-wiki-gigaword-100\"\n",
    "word_to_vec = gensim.downloader.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_cosine_similarity(user_prompts, word_to_vec):\n",
    "    if len(user_prompts) < 2:\n",
    "        # if there is only one user prompt then there is not one more prompt to compare with\n",
    "        return 0.0\n",
    "\n",
    "    # Vectorize each user prompt\n",
    "    prompt_vectors = [vectorize(prompt) for prompt in user_prompts]\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(prompt_vectors)\n",
    "\n",
    "    # Exclude the diagonal elements (self-similarity)\n",
    "    similarity_matrix_no_diagonal = similarity_matrix - np.eye(len(similarity_matrix))\n",
    "\n",
    "    # Calculate the average similarity\n",
    "    average_similarity = similarity_matrix_no_diagonal.sum() / (len(user_prompts) * (len(user_prompts) - 1))\n",
    "\n",
    "    return average_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize(prompt):\n",
    "    words = prompt.lower().split()  # tokenizing\n",
    "    \n",
    "    # put zero vector if there is no representation in word_to_vec.\n",
    "    word_vectors = [word_to_vec[word] if word in word_to_vec else np.zeros_like(word_to_vec['word'])\n",
    "                    for word in words]  \n",
    "    # take average of all. \n",
    "    # by averaging the size is fixed for all reviews,\n",
    "    # the size is equal to the size of an encoding of a single word in word_to_vec\n",
    "    average_vector = np.mean(word_vectors, axis=0)\n",
    "    return average_vector\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_count(text):\n",
    "    # Split the text into words using a regular expression\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    return len(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BY USING THE ABOVE FUNCTIONS AND MODELS, WE ARE STARTING TO CREATE OUR DATAFRAME WITH IDENTIFIED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139235c7-736c-4237-92f0-92e8c116832c\n",
      "668ad17e-0240-49f7-b5a7-d22e502554c6\n",
      "b0640e51-6879-40cb-a4f5-329f952ef99d\n",
      "da6b70d5-29f6-491a-ad46-037c77067128\n"
     ]
    }
   ],
   "source": [
    "code2features = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "\n",
    "for code, convs in code2convos.items():\n",
    "    if len(convs) == 0:\n",
    "        print(code)\n",
    "        continue\n",
    "    user_prompts = []\n",
    "    similarities_prompt_commentCode=[]\n",
    "    for c in convs:\n",
    "        # iterating over each dictionary\n",
    "        # {\"role\": \"user\", \"text\": }, {\"role\": \"assistant\", \"text\":, \"code\":, \"commentCode\": }\n",
    "        \n",
    "        lastCommentCode=\"\"\n",
    "        if c[\"role\"]==\"assistant\":\n",
    "            \n",
    "            lastCommentCode=c[\"commentCode\"]\n",
    "                \n",
    "                \n",
    "        text = c[\"text\"].lower()\n",
    "        if c[\"role\"] == \"user\":\n",
    "            # User Prompts\n",
    "            user_prompts.append(text)\n",
    "\n",
    "            # count the user prompts\n",
    "            code2features[code][\"#user_prompts\"] += 1\n",
    "\n",
    "            code2features[code][\"total_discomfort_count\"] += calculate_discomfort_count(text)\n",
    "            code2features[code][\"total_comfort_count\"] += calculate_comfort_count(text)\n",
    "            code2features[code][\"prompt_avg_words\"] += calculate_word_count(text)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            # ChatGPT Responses\n",
    "            code2features[code][\"response_avg_words\"] += calculate_word_count(text)\n",
    "            #Response confusion metric\n",
    "            code2features[code][\"response_confusion_total_count\"]+=calculate_gpt_confusion(text)\n",
    "            if lastCommentCode!=\"\":\n",
    "                \n",
    "                similarities_prompt_commentCode.append(sim_between_prompt_and_commentcode(prevText,lastCommentCode))   \n",
    "            \n",
    "        prevText=text\n",
    "\n",
    "    code2features[code][\"prompt_avg_words\"] /= code2features[code][\"#user_prompts\"]\n",
    "    code2features[code][\"response_avg_words\"] /= code2features[code][\"#user_prompts\"]\n",
    "    average_similarity = calculate_average_cosine_similarity(user_prompts, word_to_vec)\n",
    "    code2features[code][\"similarity_between_prompts\"] = average_similarity\n",
    "    \n",
    "    if len(similarities_prompt_commentCode) > 0:\n",
    "        code2features[code][\"avg_sim_between_prompt_codeComment\"] = sum(similarities_prompt_commentCode) / len(similarities_prompt_commentCode)\n",
    "    else:\n",
    "        code2features[code][\"avg_sim_between_prompt_codeComment\"] = 0  \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(code2features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24219d6-07f0-4baf-80ac-18475dc5b66f</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.380952</td>\n",
       "      <td>202.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>0.377319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2f18684-4a16-4c05-a2d1-c0f96d1de869</th>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.211268</td>\n",
       "      <td>200.408451</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.884943</td>\n",
       "      <td>0.482037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f852596d-fdca-45aa-9050-d4f76ce6a53c</th>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.766667</td>\n",
       "      <td>116.266667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.919986</td>\n",
       "      <td>0.492801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8ec3336-fd48-4654-ad98-62ccfb96d096</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>272.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.398174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8de815-224c-4d06-9fd4-7156d1a9920d</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  total_discomfort_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883           14.0                     8.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b           18.0                     0.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b            9.0                     8.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc           20.0                     3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0                    16.0   \n",
       "...                                             ...                     ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f           21.0                     1.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869           71.0                     3.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c           30.0                     6.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096           14.0                     0.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d           31.0                    16.0   \n",
       "\n",
       "                                      total_comfort_count  prompt_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  0.0         63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  0.0         39.666667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  1.0         99.111111   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  0.0         17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                  1.0         30.697674   \n",
       "...                                                   ...               ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                  0.0         31.380952   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                  2.0         48.211268   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                  1.0         93.766667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                  1.0         77.000000   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                  2.0         50.806452   \n",
       "\n",
       "                                      response_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883          160.642857  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b          169.166667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b          160.444444   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc          148.500000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34          123.000000   \n",
       "...                                                  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f          202.666667   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869          200.408451   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c          116.266667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096          272.142857   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d          114.548387   \n",
       "\n",
       "                                      response_confusion_total_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                             2.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                             1.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            12.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                             3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            19.0   \n",
       "...                                                              ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                             5.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            17.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                             4.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                             1.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                             3.0   \n",
       "\n",
       "                                      similarity_between_prompts   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0.959773  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0.913921   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0.802151   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0.904731   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    0.889234   \n",
       "...                                                          ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                    0.883792   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                    0.884943   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                    0.919986   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                    0.903643   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    0.902465   \n",
       "\n",
       "                                      avg_sim_between_prompt_codeComment  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                            0.558252  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                            0.556858  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            0.331554  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                            0.419597  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            0.470122  \n",
       "...                                                                  ...  \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                            0.377319  \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            0.482037  \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                            0.492801  \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                            0.398174  \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                            0.427945  \n",
       "\n",
       "[123 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING 1 MORE FEATURE --- CREATING AVERAGE VECTOR OF THE ONES WHO GET 100, AND PUTTING SIMILARITY FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmls_100_scores = [\"ba18e4e8-2c26-46d4-ba31-cc21947aabd5\",\n",
    "\"58bee29c-a749-463e-8d56-c4edf0815b3f\",\n",
    "\"51f35201-da77-4b6d-a455-99cc84195c5c\",\n",
    "\"223ae726-cb25-49df-a125-c4af3519c8e8\",\n",
    "\"e264c424-a241-43f7-acca-9fbbf21dc1c6\",\n",
    "\"f2f18684-4a16-4c05-a2d1-c0f96d1de869\",\n",
    "\"c21be348-17bd-4fdd-88f5-137f6a13cdee\",\n",
    "\"c91d6fef-baf5-4e77-8bfc-b14fb7fc770d\",\n",
    "\"58fcd378-aa29-4067-813c-bb4de525428e\",\n",
    "\"5a62a8ee-c67c-475e-bd85-cf6d83c90ea9\",\n",
    "\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\",\n",
    "\"f8ec3336-fd48-4654-ad98-62ccfb96d096\",\n",
    "\"36bab6e3-0d16-4626-846b-33c0384f0c79\",\n",
    "\"5541316f-6fbd-4441-b513-ac252e6355ec\",\n",
    "\"97f57cf9-4f02-4f8c-b65c-8ea0009a82a2\",\n",
    "\"7b0ecddc-caa5-4b81-88ea-cd65a7270900\",\n",
    "\"17bd62e7-6792-4399-a573-07456a73901b\",\n",
    "\"26d95379-e2f1-454c-a9d2-60cd80bc06a5\",\n",
    "\"745bb746-6467-4146-8ef5-55f3ee3f589e\",\n",
    "\"1b54e38b-3b1d-425e-835a-d1e0fb2694fc\",\n",
    "\"27de4332-d81f-47a2-b2a9-c0b023a30919\",\n",
    "\"1038cb22-8ad2-4030-b44a-59f10352e91c\",\n",
    "]\n",
    "\n",
    "# Initialize an empty dictionary to aggregate the features\n",
    "aggregated_features_100 = defaultdict(float)\n",
    "\n",
    "# Initialize a counter for the number of files that scored 100\n",
    "count_files_score_100 = 0\n",
    "\n",
    "# Iterate through each HTML file that scored 100 and aggregate their features\n",
    "for code in htmls_100_scores:\n",
    "    if code in code2features:\n",
    "        count_files_score_100 += 1\n",
    "        for feature in df.columns.tolist():\n",
    "            aggregated_features_100[feature] += code2features[code].get(feature, 0)\n",
    "\n",
    "average_features_100 = {feature: total / count_files_score_100 for feature, total in aggregated_features_100.items()}\n",
    "\n",
    "vector_list = list(average_features_100.values())\n",
    "\n",
    "\n",
    "def calculate_similarity(row):\n",
    "    row_values = row.values.tolist()\n",
    "    similarity = cosine_similarity([vector_list], [row_values])\n",
    "    return similarity[0][0]\n",
    "\n",
    "\n",
    "df['similarity_between_fullpoints'] = df.apply(calculate_similarity, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  total_discomfort_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883           14.0                     8.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b           18.0                     0.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b            9.0                     8.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc           20.0                     3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0                    16.0   \n",
       "\n",
       "                                      total_comfort_count  prompt_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  0.0         63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  0.0         39.666667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  1.0         99.111111   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  0.0         17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                  1.0         30.697674   \n",
       "\n",
       "                                      response_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883          160.642857  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b          169.166667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b          160.444444   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc          148.500000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34          123.000000   \n",
       "\n",
       "                                      response_confusion_total_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                             2.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                             1.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            12.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                             3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            19.0   \n",
       "\n",
       "                                      similarity_between_prompts   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0.959773  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0.913921   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0.802151   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0.904731   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    0.889234   \n",
       "\n",
       "                                      avg_sim_between_prompt_codeComment   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                            0.558252  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                            0.556858   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            0.331554   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                            0.419597   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            0.470122   \n",
       "\n",
       "                                      similarity_between_fullpoints  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       0.984955  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       0.988546  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                       0.950704  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       0.980123  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                       0.928597  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING NEW FEATURES. LET'S ADD METRICS THAT MEASURE HOW DETAİLED THE PROMPTS ARE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiz Sonuçları - 0031c86e-81f4-4eef-9e0e-28037abf9883:\n",
      "{'total_message_length': 5701, 'average_word_count_per_sentence': 63.07142857142857, 'average_word_length': 5.438278595696489, 'english_conjunctions_count': 32, 'example_words_count': 2, 'total_parentheses_count': 14}\n",
      "==============================\n",
      "Analiz Sonuçları - 0225686d-b825-4cac-8691-3a3a5343df2b:\n",
      "{'total_message_length': 4700, 'average_word_count_per_sentence': 39.388888888888886, 'average_word_length': 5.423131170662906, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 65}\n",
      "==============================\n",
      "Analiz Sonuçları - 041f950b-c013-409a-a642-cffff60b9d4b:\n",
      "{'total_message_length': 5967, 'average_word_count_per_sentence': 97.55555555555556, 'average_word_length': 5.619589977220957, 'english_conjunctions_count': 13, 'example_words_count': 0, 'total_parentheses_count': 100}\n",
      "==============================\n",
      "Analiz Sonuçları - 04f91058-d0f8-4324-83b2-19c671f433dc:\n",
      "{'total_message_length': 2282, 'average_word_count_per_sentence': 17.75, 'average_word_length': 5.087323943661972, 'english_conjunctions_count': 6, 'example_words_count': 0, 'total_parentheses_count': 12}\n",
      "==============================\n",
      "Analiz Sonuçları - 089eb66d-4c3a-4f58-b98f-a3774a2efb34:\n",
      "{'total_message_length': 18669, 'average_word_count_per_sentence': 28.767441860465116, 'average_word_length': 6.212206952303961, 'english_conjunctions_count': 59, 'example_words_count': 2, 'total_parentheses_count': 271}\n",
      "==============================\n",
      "Analiz Sonuçları - 090d6217-5d69-4929-a342-19abab78324f:\n",
      "{'total_message_length': 21914, 'average_word_count_per_sentence': 33.02739726027397, 'average_word_length': 7.566569888013272, 'english_conjunctions_count': 20, 'example_words_count': 1, 'total_parentheses_count': 297}\n",
      "==============================\n",
      "Analiz Sonuçları - 0c95c563-f1e1-4a35-844c-2e8ccdd1b161:\n",
      "{'total_message_length': 5107, 'average_word_count_per_sentence': 46.86666666666667, 'average_word_length': 5.97724039829303, 'english_conjunctions_count': 9, 'example_words_count': 0, 'total_parentheses_count': 64}\n",
      "==============================\n",
      "Analiz Sonuçları - 0ddfae9c-0dbd-4fbe-9e68-c3e0cb73b8fc:\n",
      "{'total_message_length': 2008, 'average_word_count_per_sentence': 29.454545454545453, 'average_word_length': 5.160493827160494, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 12}\n",
      "==============================\n",
      "Analiz Sonuçları - 0e466794-f7f8-4cc2-b07e-070b13a0b5e1:\n",
      "{'total_message_length': 27590, 'average_word_count_per_sentence': 67.97826086956522, 'average_word_length': 7.228333866325552, 'english_conjunctions_count': 38, 'example_words_count': 0, 'total_parentheses_count': 473}\n",
      "==============================\n",
      "Analiz Sonuçları - 0f0c953a-a472-47c1-809b-9fc14dba9091:\n",
      "{'total_message_length': 3961, 'average_word_count_per_sentence': 34.11764705882353, 'average_word_length': 5.451724137931034, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 38}\n",
      "==============================\n",
      "Analiz Sonuçları - 1029802d-1057-4e3e-b827-e8a9c2ded3b9:\n",
      "{'total_message_length': 14119, 'average_word_count_per_sentence': 35.53846153846154, 'average_word_length': 6.270562770562771, 'english_conjunctions_count': 23, 'example_words_count': 0, 'total_parentheses_count': 193}\n",
      "==============================\n",
      "Analiz Sonuçları - 1038cb22-8ad2-4030-b44a-59f10352e91c:\n",
      "{'total_message_length': 21081, 'average_word_count_per_sentence': 36.08064516129032, 'average_word_length': 7.94456861868574, 'english_conjunctions_count': 21, 'example_words_count': 0, 'total_parentheses_count': 339}\n",
      "==============================\n",
      "Analiz Sonuçları - 106ffe99-c787-4d09-9076-4ba411eb68b1:\n",
      "{'total_message_length': 5643, 'average_word_count_per_sentence': 35.8, 'average_word_length': 5.298324022346368, 'english_conjunctions_count': 15, 'example_words_count': 0, 'total_parentheses_count': 75}\n",
      "==============================\n",
      "Analiz Sonuçları - 139235c7-736c-4237-92f0-92e8c116832c:\n",
      "{'total_message_length': 0, 'average_word_count_per_sentence': 0, 'average_word_length': 0, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 14ce054d-4619-4685-ba9b-4b5cd6f81b2d:\n",
      "{'total_message_length': 6648, 'average_word_count_per_sentence': 78.5, 'average_word_length': 7.002547770700637, 'english_conjunctions_count': 7, 'example_words_count': 0, 'total_parentheses_count': 155}\n",
      "==============================\n",
      "Analiz Sonuçları - 152a7787-ecd1-448f-a98e-8af0826d8215:\n",
      "{'total_message_length': 5768, 'average_word_count_per_sentence': 25.933333333333334, 'average_word_length': 6.0347043701799485, 'english_conjunctions_count': 6, 'example_words_count': 0, 'total_parentheses_count': 63}\n",
      "==============================\n",
      "Analiz Sonuçları - 17bd62e7-6792-4399-a573-07456a73901b:\n",
      "{'total_message_length': 7435, 'average_word_count_per_sentence': 30.10810810810811, 'average_word_length': 5.466786355475763, 'english_conjunctions_count': 25, 'example_words_count': 0, 'total_parentheses_count': 99}\n",
      "==============================\n",
      "Analiz Sonuçları - 1b54e38b-3b1d-425e-835a-d1e0fb2694fc:\n",
      "{'total_message_length': 8446, 'average_word_count_per_sentence': 58.44444444444444, 'average_word_length': 6.701520912547529, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 155}\n",
      "==============================\n",
      "Analiz Sonuçları - 223ae726-cb25-49df-a125-c4af3519c8e8:\n",
      "{'total_message_length': 2463, 'average_word_count_per_sentence': 22.875, 'average_word_length': 5.426229508196721, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 14}\n",
      "==============================\n",
      "Analiz Sonuçları - 22bb7162-3399-464a-b30b-cf1fc3210b4e:\n",
      "{'total_message_length': 7852, 'average_word_count_per_sentence': 55.285714285714285, 'average_word_length': 5.359173126614987, 'english_conjunctions_count': 25, 'example_words_count': 0, 'total_parentheses_count': 77}\n",
      "==============================\n",
      "Analiz Sonuçları - 2446216c-c557-4ee8-b470-7e2ae3c88968:\n",
      "{'total_message_length': 4738, 'average_word_count_per_sentence': 115.8, 'average_word_length': 6.853195164075993, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 108}\n",
      "==============================\n",
      "Analiz Sonuçları - 24f01035-0717-4256-9952-c415aa8ecd10:\n",
      "{'total_message_length': 47716, 'average_word_count_per_sentence': 75.13636363636364, 'average_word_length': 7.765073603549102, 'english_conjunctions_count': 51, 'example_words_count': 0, 'total_parentheses_count': 687}\n",
      "==============================\n",
      "Analiz Sonuçları - 26d95379-e2f1-454c-a9d2-60cd80bc06a5:\n",
      "{'total_message_length': 4238, 'average_word_count_per_sentence': 20.3, 'average_word_length': 5.752052545155993, 'english_conjunctions_count': 13, 'example_words_count': 0, 'total_parentheses_count': 70}\n",
      "==============================\n",
      "Analiz Sonuçları - 271b130d-50bd-436e-add6-38d9c618be8a:\n",
      "{'total_message_length': 3672, 'average_word_count_per_sentence': 31.833333333333332, 'average_word_length': 5.209424083769633, 'english_conjunctions_count': 19, 'example_words_count': 0, 'total_parentheses_count': 10}\n",
      "==============================\n",
      "Analiz Sonuçları - 27de4332-d81f-47a2-b2a9-c0b023a30919:\n",
      "{'total_message_length': 6513, 'average_word_count_per_sentence': 37.857142857142854, 'average_word_length': 6.628930817610063, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 84}\n",
      "==============================\n",
      "Analiz Sonuçları - 2b9cf078-c56b-4020-9197-cd9f7d4f909c:\n",
      "{'total_message_length': 9555, 'average_word_count_per_sentence': 69.26666666666667, 'average_word_length': 7.422521655437921, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 153}\n",
      "==============================\n",
      "Analiz Sonuçları - 30283b91-7fc3-4125-985b-b441f0f489d6:\n",
      "{'total_message_length': 8349, 'average_word_count_per_sentence': 77.14285714285714, 'average_word_length': 6.125925925925926, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 114}\n",
      "==============================\n",
      "Analiz Sonuçları - 3104d903-6012-484c-bd00-b93594b289ea:\n",
      "{'total_message_length': 7395, 'average_word_count_per_sentence': 58.4375, 'average_word_length': 6.5037433155080215, 'english_conjunctions_count': 11, 'example_words_count': 0, 'total_parentheses_count': 115}\n",
      "==============================\n",
      "Analiz Sonuçları - 331a45a0-341c-4faf-97de-75c82b31b61f:\n",
      "{'total_message_length': 2055, 'average_word_count_per_sentence': 14.681818181818182, 'average_word_length': 5.021671826625387, 'english_conjunctions_count': 7, 'example_words_count': 0, 'total_parentheses_count': 8}\n",
      "==============================\n",
      "Analiz Sonuçları - 36bab6e3-0d16-4626-846b-33c0384f0c79:\n",
      "{'total_message_length': 18632, 'average_word_count_per_sentence': 42.824561403508774, 'average_word_length': 5.571487095452683, 'english_conjunctions_count': 39, 'example_words_count': 2, 'total_parentheses_count': 210}\n",
      "==============================\n",
      "Analiz Sonuçları - 38296004-7336-4797-9db4-662a48309a1c:\n",
      "{'total_message_length': 921, 'average_word_count_per_sentence': 36.75, 'average_word_length': 5.217687074829932, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 22}\n",
      "==============================\n",
      "Analiz Sonuçları - 410d88de-2489-4a83-8dae-6bc01e8e9f78:\n",
      "{'total_message_length': 227, 'average_word_count_per_sentence': 8.4, 'average_word_length': 4.5, 'english_conjunctions_count': 1, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 41b82427-7ae2-4c55-b8a3-310bb4abada0:\n",
      "{'total_message_length': 10121, 'average_word_count_per_sentence': 46.61538461538461, 'average_word_length': 7.031353135313531, 'english_conjunctions_count': 13, 'example_words_count': 0, 'total_parentheses_count': 141}\n",
      "==============================\n",
      "Analiz Sonuçları - 42980d53-7bcd-4a36-bf3a-aa43f7417ac5:\n",
      "{'total_message_length': 5984, 'average_word_count_per_sentence': 59.15384615384615, 'average_word_length': 6.218465539661898, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 84}\n",
      "==============================\n",
      "Analiz Sonuçları - 43ff9786-2b47-425b-8bad-e274d9988a0e:\n",
      "{'total_message_length': 23750, 'average_word_count_per_sentence': 55.41818181818182, 'average_word_length': 6.466535433070866, 'english_conjunctions_count': 44, 'example_words_count': 0, 'total_parentheses_count': 285}\n",
      "==============================\n",
      "Analiz Sonuçları - 450550b4-3bb9-4b12-a7fd-121ac4a36ea9:\n",
      "{'total_message_length': 4093, 'average_word_count_per_sentence': 51.5, 'average_word_length': 5.383495145631068, 'english_conjunctions_count': 7, 'example_words_count': 0, 'total_parentheses_count': 54}\n",
      "==============================\n",
      "Analiz Sonuçları - 45d2c21a-828e-46d9-8fcd-a4a39888773c:\n",
      "{'total_message_length': 3592, 'average_word_count_per_sentence': 27.11111111111111, 'average_word_length': 5.987704918032787, 'english_conjunctions_count': 9, 'example_words_count': 0, 'total_parentheses_count': 42}\n",
      "==============================\n",
      "Analiz Sonuçları - 4e6fdf20-96fa-4f62-bf55-5c4c695afebe:\n",
      "{'total_message_length': 7605, 'average_word_count_per_sentence': 55.2, 'average_word_length': 5.509963768115942, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 126}\n",
      "==============================\n",
      "Analiz Sonuçları - 4fb21782-81f0-47c1-8831-58a748904a2c:\n",
      "{'total_message_length': 3349, 'average_word_count_per_sentence': 38.714285714285715, 'average_word_length': 5.186346863468635, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 53}\n",
      "==============================\n",
      "Analiz Sonuçları - 50a71154-2269-460c-9341-291221c6ef02:\n",
      "{'total_message_length': 65180, 'average_word_count_per_sentence': 99.38571428571429, 'average_word_length': 7.466724162713813, 'english_conjunctions_count': 84, 'example_words_count': 0, 'total_parentheses_count': 939}\n",
      "==============================\n",
      "Analiz Sonuçları - 51f35201-da77-4b6d-a455-99cc84195c5c:\n",
      "{'total_message_length': 4891, 'average_word_count_per_sentence': 54.38461538461539, 'average_word_length': 5.718528995756719, 'english_conjunctions_count': 15, 'example_words_count': 0, 'total_parentheses_count': 28}\n",
      "==============================\n",
      "Analiz Sonuçları - 530b4e58-756d-4627-ad08-65ba0457ad42:\n",
      "{'total_message_length': 5501, 'average_word_count_per_sentence': 50.8125, 'average_word_length': 5.479704797047971, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 45}\n",
      "==============================\n",
      "Analiz Sonuçları - 53ad17d1-5eb2-4af6-9c38-3c90c05ee695:\n",
      "{'total_message_length': 19642, 'average_word_count_per_sentence': 36.39344262295082, 'average_word_length': 7.313063063063063, 'english_conjunctions_count': 18, 'example_words_count': 0, 'total_parentheses_count': 328}\n",
      "==============================\n",
      "Analiz Sonuçları - 5541316f-6fbd-4441-b513-ac252e6355ec:\n",
      "{'total_message_length': 7602, 'average_word_count_per_sentence': 55.4, 'average_word_length': 5.7048736462093865, 'english_conjunctions_count': 19, 'example_words_count': 0, 'total_parentheses_count': 65}\n",
      "==============================\n",
      "Analiz Sonuçları - 56c6f8dd-f37c-44d2-9820-9459aa34c8af:\n",
      "{'total_message_length': 2273, 'average_word_count_per_sentence': 13.25925925925926, 'average_word_length': 5.337988826815643, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 22}\n",
      "==============================\n",
      "Analiz Sonuçları - 58bee29c-a749-463e-8d56-c4edf0815b3f:\n",
      "{'total_message_length': 9679, 'average_word_count_per_sentence': 33.80952380952381, 'average_word_length': 5.5, 'english_conjunctions_count': 20, 'example_words_count': 0, 'total_parentheses_count': 116}\n",
      "==============================\n",
      "Analiz Sonuçları - 58fcd378-aa29-4067-813c-bb4de525428e:\n",
      "{'total_message_length': 16746, 'average_word_count_per_sentence': 32.983870967741936, 'average_word_length': 6.796577017114914, 'english_conjunctions_count': 35, 'example_words_count': 0, 'total_parentheses_count': 269}\n",
      "==============================\n",
      "Analiz Sonuçları - 597c7a93-6b16-4af9-9846-154599f596e1:\n",
      "{'total_message_length': 927, 'average_word_count_per_sentence': 12.76923076923077, 'average_word_length': 4.650602409638554, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 2}\n",
      "==============================\n",
      "Analiz Sonuçları - 5a62a8ee-c67c-475e-bd85-cf6d83c90ea9:\n",
      "{'total_message_length': 64231, 'average_word_count_per_sentence': 96.05333333333333, 'average_word_length': 7.181704608550805, 'english_conjunctions_count': 72, 'example_words_count': 0, 'total_parentheses_count': 1233}\n",
      "==============================\n",
      "Analiz Sonuçları - 5dbf76be-6634-4d42-a87f-b62b7fa6ceae:\n",
      "{'total_message_length': 15607, 'average_word_count_per_sentence': 41.58695652173913, 'average_word_length': 6.880292733925771, 'english_conjunctions_count': 20, 'example_words_count': 0, 'total_parentheses_count': 230}\n",
      "==============================\n",
      "Analiz Sonuçları - 5e481e20-f714-4f11-b941-0ef2fd5976d3:\n",
      "{'total_message_length': 1694, 'average_word_count_per_sentence': 210.0, 'average_word_length': 6.109523809523809, 'english_conjunctions_count': 2, 'example_words_count': 0, 'total_parentheses_count': 17}\n",
      "==============================\n",
      "Analiz Sonuçları - 6312a21b-c6be-44f9-ad81-46307b339fb6:\n",
      "{'total_message_length': 666, 'average_word_count_per_sentence': 9.5, 'average_word_length': 4.947368421052632, 'english_conjunctions_count': 2, 'example_words_count': 1, 'total_parentheses_count': 2}\n",
      "==============================\n",
      "Analiz Sonuçları - 63216e9b-5d0b-4047-97ee-302495d61640:\n",
      "{'total_message_length': 5154, 'average_word_count_per_sentence': 36.473684210526315, 'average_word_length': 5.8311688311688314, 'english_conjunctions_count': 16, 'example_words_count': 0, 'total_parentheses_count': 80}\n",
      "==============================\n",
      "Analiz Sonuçları - 65ea56c3-e205-4ed9-8b85-bd1876228cee:\n",
      "{'total_message_length': 3669, 'average_word_count_per_sentence': 44.9, 'average_word_length': 5.351893095768374, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 26}\n",
      "==============================\n",
      "Analiz Sonuçları - 663f8b4e-b683-4365-8316-b1dd1d325110:\n",
      "{'total_message_length': 8416, 'average_word_count_per_sentence': 30.25, 'average_word_length': 7.268595041322314, 'english_conjunctions_count': 16, 'example_words_count': 0, 'total_parentheses_count': 90}\n",
      "==============================\n",
      "Analiz Sonuçları - 668ad17e-0240-49f7-b5a7-d22e502554c6:\n",
      "{'total_message_length': 0, 'average_word_count_per_sentence': 0, 'average_word_length': 0, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 67c4a788-ec23-48c4-b6db-d76be6e118d6:\n",
      "{'total_message_length': 13447, 'average_word_count_per_sentence': 46.125, 'average_word_length': 5.930623306233063, 'english_conjunctions_count': 35, 'example_words_count': 0, 'total_parentheses_count': 151}\n",
      "==============================\n",
      "Analiz Sonuçları - 69426dc0-b745-4f89-9c9a-943828d19db9:\n",
      "{'total_message_length': 23658, 'average_word_count_per_sentence': 70.02702702702703, 'average_word_length': 7.503280586646083, 'english_conjunctions_count': 33, 'example_words_count': 0, 'total_parentheses_count': 294}\n",
      "==============================\n",
      "Analiz Sonuçları - 6a2003ad-a05a-41c9-9d48-e98491a90499:\n",
      "{'total_message_length': 92, 'average_word_count_per_sentence': 8.0, 'average_word_length': 4.875, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 6a903495-c5be-4263-b4dd-75e2bbc30434:\n",
      "{'total_message_length': 3259, 'average_word_count_per_sentence': 29.823529411764707, 'average_word_length': 5.455621301775148, 'english_conjunctions_count': 7, 'example_words_count': 0, 'total_parentheses_count': 45}\n",
      "==============================\n",
      "Analiz Sonuçları - 6b4e988c-eead-46ff-a35b-b2fd325b2698:\n",
      "{'total_message_length': 302, 'average_word_count_per_sentence': 5.363636363636363, 'average_word_length': 4.288135593220339, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 6c37a2d7-f786-4fc2-ba7a-04c3f961a365:\n",
      "{'total_message_length': 18026, 'average_word_count_per_sentence': 71.96296296296296, 'average_word_length': 7.504374678332476, 'english_conjunctions_count': 15, 'example_words_count': 0, 'total_parentheses_count': 291}\n",
      "==============================\n",
      "Analiz Sonuçları - 6d5742c1-77c4-429c-8f6e-ef1262ca5557:\n",
      "{'total_message_length': 17422, 'average_word_count_per_sentence': 39.15151515151515, 'average_word_length': 5.59094427244582, 'english_conjunctions_count': 50, 'example_words_count': 0, 'total_parentheses_count': 178}\n",
      "==============================\n",
      "Analiz Sonuçları - 6de08d44-bb5b-491d-a11e-51caa1eccd0c:\n",
      "{'total_message_length': 972, 'average_word_count_per_sentence': 14.8, 'average_word_length': 5.635135135135135, 'english_conjunctions_count': 1, 'example_words_count': 0, 'total_parentheses_count': 4}\n",
      "==============================\n",
      "Analiz Sonuçları - 7421916d-a0b5-4f0b-ad47-25a0cbf1b239:\n",
      "{'total_message_length': 4238, 'average_word_count_per_sentence': 42.333333333333336, 'average_word_length': 5.437795275590551, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 73}\n",
      "==============================\n",
      "Analiz Sonuçları - 745bb746-6467-4146-8ef5-55f3ee3f589e:\n",
      "{'total_message_length': 4872, 'average_word_count_per_sentence': 30.464285714285715, 'average_word_length': 4.731535756154748, 'english_conjunctions_count': 24, 'example_words_count': 0, 'total_parentheses_count': 16}\n",
      "==============================\n",
      "Analiz Sonuçları - 745ffa9e-f540-488a-b752-a3add11cb30b:\n",
      "{'total_message_length': 772, 'average_word_count_per_sentence': 9.384615384615385, 'average_word_length': 5.434426229508197, 'english_conjunctions_count': 1, 'example_words_count': 0, 'total_parentheses_count': 2}\n",
      "==============================\n",
      "Analiz Sonuçları - 746b8f06-1e89-43b8-b73c-1121eecfc854:\n",
      "{'total_message_length': 103, 'average_word_count_per_sentence': 21.0, 'average_word_length': 3.9523809523809526, 'english_conjunctions_count': 1, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - 76a73730-6432-4f30-bb59-7a609bc9ba43:\n",
      "{'total_message_length': 4306, 'average_word_count_per_sentence': 37.88235294117647, 'average_word_length': 5.458074534161491, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 46}\n",
      "==============================\n",
      "Analiz Sonuçları - 79cf72c1-d3aa-4e09-8ff2-6a8ad51b22ef:\n",
      "{'total_message_length': 2500, 'average_word_count_per_sentence': 38.2, 'average_word_length': 5.4319371727748695, 'english_conjunctions_count': 7, 'example_words_count': 0, 'total_parentheses_count': 30}\n",
      "==============================\n",
      "Analiz Sonuçları - 7ac3f7a5-bdbb-470c-a1b3-03da5887a408:\n",
      "{'total_message_length': 8665, 'average_word_count_per_sentence': 19.265625, 'average_word_length': 5.855636658556366, 'english_conjunctions_count': 21, 'example_words_count': 0, 'total_parentheses_count': 42}\n",
      "==============================\n",
      "Analiz Sonuçları - 7af13aaa-dd6a-4850-856d-73ea55d0c2ff:\n",
      "{'total_message_length': 4584, 'average_word_count_per_sentence': 29.5, 'average_word_length': 10.024213075060533, 'english_conjunctions_count': 8, 'example_words_count': 2, 'total_parentheses_count': 30}\n",
      "==============================\n",
      "Analiz Sonuçları - 7b0ecddc-caa5-4b81-88ea-cd65a7270900:\n",
      "{'total_message_length': 2569, 'average_word_count_per_sentence': 19.954545454545453, 'average_word_length': 4.876993166287016, 'english_conjunctions_count': 19, 'example_words_count': 0, 'total_parentheses_count': 24}\n",
      "==============================\n",
      "Analiz Sonuçları - 7c734c12-e18b-4de8-9004-c2523878db31:\n",
      "{'total_message_length': 1899, 'average_word_count_per_sentence': 35.875, 'average_word_length': 5.585365853658536, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 31}\n",
      "==============================\n",
      "Analiz Sonuçları - 8121427e-e5b1-400b-8342-d5d1c865f1d7:\n",
      "{'total_message_length': 4693, 'average_word_count_per_sentence': 18.822222222222223, 'average_word_length': 4.442739079102715, 'english_conjunctions_count': 31, 'example_words_count': 0, 'total_parentheses_count': 4}\n",
      "==============================\n",
      "Analiz Sonuçları - 81fdeb2a-e7e5-4a05-8058-d31ea579b0d9:\n",
      "{'total_message_length': 4061, 'average_word_count_per_sentence': 28.05, 'average_word_length': 5.83065953654189, 'english_conjunctions_count': 10, 'example_words_count': 1, 'total_parentheses_count': 12}\n",
      "==============================\n",
      "Analiz Sonuçları - 8505dcd7-9a9e-4ac3-b708-d3ffea7e6bb8:\n",
      "{'total_message_length': 2287, 'average_word_count_per_sentence': 25.928571428571427, 'average_word_length': 5.289256198347108, 'english_conjunctions_count': 6, 'example_words_count': 0, 'total_parentheses_count': 14}\n",
      "==============================\n",
      "Analiz Sonuçları - 854397cb-a264-4bad-b30f-a9c1ba012511:\n",
      "{'total_message_length': 35602, 'average_word_count_per_sentence': 55.6, 'average_word_length': 7.861095738793581, 'english_conjunctions_count': 49, 'example_words_count': 0, 'total_parentheses_count': 553}\n",
      "==============================\n",
      "Analiz Sonuçları - 8a84e6e5-d200-4cc2-a288-5c81201100c7:\n",
      "{'total_message_length': 7400, 'average_word_count_per_sentence': 13.225, 'average_word_length': 6.034026465028355, 'english_conjunctions_count': 17, 'example_words_count': 2, 'total_parentheses_count': 57}\n",
      "==============================\n",
      "Analiz Sonuçları - 8be8e839-6dd0-44e0-b039-170b5b77cf2a:\n",
      "{'total_message_length': 5351, 'average_word_count_per_sentence': 29.25, 'average_word_length': 10.188034188034187, 'english_conjunctions_count': 2, 'example_words_count': 0, 'total_parentheses_count': 26}\n",
      "==============================\n",
      "Analiz Sonuçları - 918f3066-0b5a-46dc-92b8-b4279f0cb26e:\n",
      "{'total_message_length': 67379, 'average_word_count_per_sentence': 100.09859154929578, 'average_word_length': 7.458984100182918, 'english_conjunctions_count': 63, 'example_words_count': 0, 'total_parentheses_count': 601}\n",
      "==============================\n",
      "Analiz Sonuçları - 941a3ef2-7559-430c-8682-830a04a6864c:\n",
      "{'total_message_length': 10328, 'average_word_count_per_sentence': 29.48780487804878, 'average_word_length': 6.795698924731183, 'english_conjunctions_count': 14, 'example_words_count': 0, 'total_parentheses_count': 100}\n",
      "==============================\n",
      "Analiz Sonuçları - 97f57cf9-4f02-4f8c-b65c-8ea0009a82a2:\n",
      "{'total_message_length': 1688, 'average_word_count_per_sentence': 26.3, 'average_word_length': 5.452471482889734, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 4}\n",
      "==============================\n",
      "Analiz Sonuçları - a0132e5d-4e16-4600-b2a7-5b6cd68a8b6a:\n",
      "{'total_message_length': 7748, 'average_word_count_per_sentence': 61.473684210526315, 'average_word_length': 5.302226027397261, 'english_conjunctions_count': 25, 'example_words_count': 0, 'total_parentheses_count': 69}\n",
      "==============================\n",
      "Analiz Sonuçları - a014d72a-81ad-43a4-8a2c-8046b7666320:\n",
      "{'total_message_length': 5776, 'average_word_count_per_sentence': 21.64516129032258, 'average_word_length': 7.5201192250372575, 'english_conjunctions_count': 6, 'example_words_count': 0, 'total_parentheses_count': 55}\n",
      "==============================\n",
      "Analiz Sonuçları - a1e834df-f4f6-4962-bcda-17f8aefc7f86:\n",
      "{'total_message_length': 5240, 'average_word_count_per_sentence': 26.5, 'average_word_length': 4.898584905660377, 'english_conjunctions_count': 28, 'example_words_count': 1, 'total_parentheses_count': 20}\n",
      "==============================\n",
      "Analiz Sonuçları - a70ebc32-7ee1-456f-9fa1-bef302fb0e78:\n",
      "{'total_message_length': 1128, 'average_word_count_per_sentence': 14.692307692307692, 'average_word_length': 4.81151832460733, 'english_conjunctions_count': 3, 'example_words_count': 0, 'total_parentheses_count': 2}\n",
      "==============================\n",
      "Analiz Sonuçları - a8270e39-5d70-4f1a-b031-6b4fcc55de01:\n",
      "{'total_message_length': 5769, 'average_word_count_per_sentence': 34.523809523809526, 'average_word_length': 6.5296551724137935, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 59}\n",
      "==============================\n",
      "Analiz Sonuçları - a948a3e5-70e5-447a-b3b4-baf3661f7b7e:\n",
      "{'total_message_length': 15864, 'average_word_count_per_sentence': 89.41666666666667, 'average_word_length': 6.166821994408202, 'english_conjunctions_count': 38, 'example_words_count': 0, 'total_parentheses_count': 127}\n",
      "==============================\n",
      "Analiz Sonuçları - aa15f751-f65f-4397-b138-df7b8301a12f:\n",
      "{'total_message_length': 10719, 'average_word_count_per_sentence': 70.75, 'average_word_length': 5.2249705535924615, 'english_conjunctions_count': 27, 'example_words_count': 0, 'total_parentheses_count': 107}\n",
      "==============================\n",
      "Analiz Sonuçları - ab775974-7ddb-4a60-aef2-4655d7bb746d:\n",
      "{'total_message_length': 8888, 'average_word_count_per_sentence': 20.76923076923077, 'average_word_length': 5.497037037037037, 'english_conjunctions_count': 18, 'example_words_count': 0, 'total_parentheses_count': 108}\n",
      "==============================\n",
      "Analiz Sonuçları - adb31914-fa31-471d-b476-6111c393ec42:\n",
      "{'total_message_length': 5377, 'average_word_count_per_sentence': 15.586206896551724, 'average_word_length': 4.772123893805309, 'english_conjunctions_count': 14, 'example_words_count': 6, 'total_parentheses_count': 71}\n",
      "==============================\n",
      "Analiz Sonuçları - b0640e51-6879-40cb-a4f5-329f952ef99d:\n",
      "{'total_message_length': 0, 'average_word_count_per_sentence': 0, 'average_word_length': 0, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - b13a2e11-1f0a-4f1e-9735-5f0674713593:\n",
      "{'total_message_length': 27730, 'average_word_count_per_sentence': 114.70833333333333, 'average_word_length': 8.56738103886669, 'english_conjunctions_count': 38, 'example_words_count': 4, 'total_parentheses_count': 369}\n",
      "==============================\n",
      "Analiz Sonuçları - b24c3a33-2952-4ae4-9f2d-643d8fdbc600:\n",
      "{'total_message_length': 44974, 'average_word_count_per_sentence': 84.16949152542372, 'average_word_length': 7.386830447039871, 'english_conjunctions_count': 61, 'example_words_count': 0, 'total_parentheses_count': 595}\n",
      "==============================\n",
      "Analiz Sonuçları - b47559b3-3b5f-4958-bfa5-ec9f7a36aec0:\n",
      "{'total_message_length': 7411, 'average_word_count_per_sentence': 38.34615384615385, 'average_word_length': 5.936810431293882, 'english_conjunctions_count': 26, 'example_words_count': 0, 'total_parentheses_count': 54}\n",
      "==============================\n",
      "Analiz Sonuçları - b57fe283-97a4-457f-a5d0-ef441650c968:\n",
      "{'total_message_length': 1477, 'average_word_count_per_sentence': 19.75, 'average_word_length': 5.206751054852321, 'english_conjunctions_count': 4, 'example_words_count': 0, 'total_parentheses_count': 16}\n",
      "==============================\n",
      "Analiz Sonuçları - b5fe7d4d-e4a5-4ebd-8058-069d6505eb01:\n",
      "{'total_message_length': 5727, 'average_word_count_per_sentence': 39.89473684210526, 'average_word_length': 6.014511873350924, 'english_conjunctions_count': 7, 'example_words_count': 1, 'total_parentheses_count': 78}\n",
      "==============================\n",
      "Analiz Sonuçları - b61f3f4c-785e-4d7c-b963-4480ece4656f:\n",
      "{'total_message_length': 13801, 'average_word_count_per_sentence': 53.407407407407405, 'average_word_length': 7.6900138696255205, 'english_conjunctions_count': 16, 'example_words_count': 0, 'total_parentheses_count': 241}\n",
      "==============================\n",
      "Analiz Sonuçları - b73f91f8-732f-4a48-bcbd-eadbbb457a94:\n",
      "{'total_message_length': 9189, 'average_word_count_per_sentence': 67.47058823529412, 'average_word_length': 6.446381865736704, 'english_conjunctions_count': 19, 'example_words_count': 0, 'total_parentheses_count': 133}\n",
      "==============================\n",
      "Analiz Sonuçları - ba18e4e8-2c26-46d4-ba31-cc21947aabd5:\n",
      "{'total_message_length': 7229, 'average_word_count_per_sentence': 36.96296296296296, 'average_word_length': 6.057114228456914, 'english_conjunctions_count': 10, 'example_words_count': 2, 'total_parentheses_count': 62}\n",
      "==============================\n",
      "Analiz Sonuçları - c0f51763-0c69-45fb-a4d7-6906d53db43d:\n",
      "{'total_message_length': 208, 'average_word_count_per_sentence': 12.333333333333334, 'average_word_length': 4.675675675675675, 'english_conjunctions_count': 1, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - c21be348-17bd-4fdd-88f5-137f6a13cdee:\n",
      "{'total_message_length': 3464, 'average_word_count_per_sentence': 28.5, 'average_word_length': 5.502923976608187, 'english_conjunctions_count': 9, 'example_words_count': 0, 'total_parentheses_count': 31}\n",
      "==============================\n",
      "Analiz Sonuçları - c65a33f5-6acf-4ff1-86fe-6003f165d44e:\n",
      "{'total_message_length': 2810, 'average_word_count_per_sentence': 21.6, 'average_word_length': 7.037037037037037, 'english_conjunctions_count': 5, 'example_words_count': 0, 'total_parentheses_count': 32}\n",
      "==============================\n",
      "Analiz Sonuçları - c91d6fef-baf5-4e77-8bfc-b14fb7fc770d:\n",
      "{'total_message_length': 9473, 'average_word_count_per_sentence': 30.085714285714285, 'average_word_length': 7.027540360873695, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 121}\n",
      "==============================\n",
      "Analiz Sonuçları - cc9ecae2-a3bf-43df-9628-56f587f400be:\n",
      "{'total_message_length': 8042, 'average_word_count_per_sentence': 63.5, 'average_word_length': 5.396325459317585, 'english_conjunctions_count': 21, 'example_words_count': 0, 'total_parentheses_count': 83}\n",
      "==============================\n",
      "Analiz Sonuçları - d4ab3f85-fdfb-434b-9774-96d94fd15d69:\n",
      "{'total_message_length': 7574, 'average_word_count_per_sentence': 59.21052631578947, 'average_word_length': 5.578666666666667, 'english_conjunctions_count': 18, 'example_words_count': 0, 'total_parentheses_count': 62}\n",
      "==============================\n",
      "Analiz Sonuçları - d61b757d-88bc-4a33-a620-0d76712207c3:\n",
      "{'total_message_length': 11711, 'average_word_count_per_sentence': 35.68, 'average_word_length': 5.378363228699552, 'english_conjunctions_count': 29, 'example_words_count': 0, 'total_parentheses_count': 160}\n",
      "==============================\n",
      "Analiz Sonuçları - d846484d-9257-40b4-98b9-6854288e8add:\n",
      "{'total_message_length': 10021, 'average_word_count_per_sentence': 52.30769230769231, 'average_word_length': 6.10514705882353, 'english_conjunctions_count': 24, 'example_words_count': 0, 'total_parentheses_count': 158}\n",
      "==============================\n",
      "Analiz Sonuçları - da219169-aacb-48b8-abdc-e25f08ad029e:\n",
      "{'total_message_length': 1838, 'average_word_count_per_sentence': 19.533333333333335, 'average_word_length': 5.296928327645051, 'english_conjunctions_count': 8, 'example_words_count': 0, 'total_parentheses_count': 8}\n",
      "==============================\n",
      "Analiz Sonuçları - da6b70d5-29f6-491a-ad46-037c77067128:\n",
      "{'total_message_length': 0, 'average_word_count_per_sentence': 0, 'average_word_length': 0, 'english_conjunctions_count': 0, 'example_words_count': 0, 'total_parentheses_count': 0}\n",
      "==============================\n",
      "Analiz Sonuçları - db921a07-c234-41c6-8891-ef1b8a22a2f5:\n",
      "{'total_message_length': 4254, 'average_word_count_per_sentence': 25.344827586206897, 'average_word_length': 4.650340136054422, 'english_conjunctions_count': 19, 'example_words_count': 0, 'total_parentheses_count': 11}\n",
      "==============================\n",
      "Analiz Sonuçları - dc9d3dc4-de7d-44e0-916c-04c85f94012a:\n",
      "{'total_message_length': 20846, 'average_word_count_per_sentence': 56.47727272727273, 'average_word_length': 6.622132796780684, 'english_conjunctions_count': 40, 'example_words_count': 0, 'total_parentheses_count': 272}\n",
      "==============================\n",
      "Analiz Sonuçları - dd898b12-b04b-404e-9b59-f846a162c177:\n",
      "{'total_message_length': 9388, 'average_word_count_per_sentence': 24.97872340425532, 'average_word_length': 6.680579216354344, 'english_conjunctions_count': 22, 'example_words_count': 0, 'total_parentheses_count': 110}\n",
      "==============================\n",
      "Analiz Sonuçları - dfe46143-c07c-4bb6-bddc-7458995dba2f:\n",
      "{'total_message_length': 15052, 'average_word_count_per_sentence': 41.11363636363637, 'average_word_length': 6.911553344389166, 'english_conjunctions_count': 29, 'example_words_count': 0, 'total_parentheses_count': 215}\n",
      "==============================\n",
      "Analiz Sonuçları - e264c424-a241-43f7-acca-9fbbf21dc1c6:\n",
      "{'total_message_length': 18764, 'average_word_count_per_sentence': 70.42857142857143, 'average_word_length': 6.440162271805274, 'english_conjunctions_count': 47, 'example_words_count': 0, 'total_parentheses_count': 232}\n",
      "==============================\n",
      "Analiz Sonuçları - e469cc3a-40fc-44e1-a7b7-3b2fbe621a8b:\n",
      "{'total_message_length': 1533, 'average_word_count_per_sentence': 39.0, 'average_word_length': 6.364102564102564, 'english_conjunctions_count': 3, 'example_words_count': 0, 'total_parentheses_count': 6}\n",
      "==============================\n",
      "Analiz Sonuçları - e76b910b-3156-4801-a73e-ddb16c763d43:\n",
      "{'total_message_length': 11137, 'average_word_count_per_sentence': 44.21212121212121, 'average_word_length': 6.4084989718985605, 'english_conjunctions_count': 24, 'example_words_count': 0, 'total_parentheses_count': 161}\n",
      "==============================\n",
      "Analiz Sonuçları - e779a2d6-6e4e-4ade-8a30-d624166c2ab3:\n",
      "{'total_message_length': 2901, 'average_word_count_per_sentence': 31.0, 'average_word_length': 5.3986175115207375, 'english_conjunctions_count': 4, 'example_words_count': 0, 'total_parentheses_count': 10}\n",
      "==============================\n",
      "Analiz Sonuçları - e8fd2278-1620-432d-81cb-02cac8543456:\n",
      "{'total_message_length': 6991, 'average_word_count_per_sentence': 79.0, 'average_word_length': 5.189873417721519, 'english_conjunctions_count': 16, 'example_words_count': 0, 'total_parentheses_count': 102}\n",
      "==============================\n",
      "Analiz Sonuçları - ebe86296-3cae-429a-9a7c-aa8f21cfd7cb:\n",
      "{'total_message_length': 2581, 'average_word_count_per_sentence': 18.761904761904763, 'average_word_length': 5.401015228426396, 'english_conjunctions_count': 12, 'example_words_count': 0, 'total_parentheses_count': 2}\n",
      "==============================\n",
      "Analiz Sonuçları - ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9:\n",
      "{'total_message_length': 18712, 'average_word_count_per_sentence': 23.73, 'average_word_length': 6.321533923303835, 'english_conjunctions_count': 28, 'example_words_count': 0, 'total_parentheses_count': 228}\n",
      "==============================\n",
      "Analiz Sonuçları - f24219d6-07f0-4baf-80ac-18475dc5b66f:\n",
      "{'total_message_length': 4035, 'average_word_count_per_sentence': 30.857142857142858, 'average_word_length': 5.219135802469136, 'english_conjunctions_count': 9, 'example_words_count': 1, 'total_parentheses_count': 69}\n",
      "==============================\n",
      "Analiz Sonuçları - f2f18684-4a16-4c05-a2d1-c0f96d1de869:\n",
      "{'total_message_length': 23006, 'average_word_count_per_sentence': 41.76056338028169, 'average_word_length': 6.075210792580101, 'english_conjunctions_count': 34, 'example_words_count': 1, 'total_parentheses_count': 192}\n",
      "==============================\n",
      "Analiz Sonuçları - f852596d-fdca-45aa-9050-d4f76ce6a53c:\n",
      "{'total_message_length': 21776, 'average_word_count_per_sentence': 84.43333333333334, 'average_word_length': 7.281879194630872, 'english_conjunctions_count': 31, 'example_words_count': 0, 'total_parentheses_count': 307}\n",
      "==============================\n",
      "Analiz Sonuçları - f8ec3336-fd48-4654-ad98-62ccfb96d096:\n",
      "{'total_message_length': 7143, 'average_word_count_per_sentence': 69.85714285714286, 'average_word_length': 5.768916155419223, 'english_conjunctions_count': 10, 'example_words_count': 0, 'total_parentheses_count': 78}\n",
      "==============================\n",
      "Analiz Sonuçları - fb8de815-224c-4d06-9fd4-7156d1a9920d:\n",
      "{'total_message_length': 11417, 'average_word_count_per_sentence': 46.61290322580645, 'average_word_length': 6.3695501730103805, 'english_conjunctions_count': 13, 'example_words_count': 0, 'total_parentheses_count': 199}\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def analyze_messages(user_id, messages):\n",
    "    total_message_length = sum(len(message) for message in messages)\n",
    "    average_message_length = total_message_length / len(messages) if len(messages) > 0 else 0\n",
    "\n",
    "    all_text = \" \".join(messages)\n",
    "    words = all_text.split()\n",
    "\n",
    "    total_word_count = len(words)\n",
    "    average_word_count_per_sentence = total_word_count / len(messages) if len(messages) > 0 else 0\n",
    "\n",
    "    average_word_length = sum(len(word) for word in words) / total_word_count if total_word_count > 0 else 0\n",
    "\n",
    "    english_conjunctions_count = sum(1 for word in words if word.lower() in {\"and\", \"or\", \"but\", \"so\", \"yet\"})\n",
    "\n",
    "    example_words_count = sum(1 for word in words if word.lower() in {\"example\", \"illustrate\", \"demonstrate\"})\n",
    "\n",
    "    total_parentheses_count = sum(message.count('(') + message.count(')') for message in messages)\n",
    "\n",
    "    prompt_num = len(messages)\n",
    "\n",
    "    return {\n",
    "        \"total_message_length\": total_message_length, #EKLE\n",
    "        \n",
    "        \"average_word_count_per_sentence\": average_word_count_per_sentence, #EKLE\n",
    "        \"average_word_length\": average_word_length, #EKLE\n",
    "        \"english_conjunctions_count\": english_conjunctions_count, #EKLE\n",
    "        \"example_words_count\": example_words_count, #EKLE\n",
    "        \"total_parentheses_count\": total_parentheses_count #EKLE\n",
    "    }\n",
    "\n",
    "user_analyses = {user_id: analyze_messages(user_id, messages) for user_id, messages in code2prompts.items()}\n",
    "\n",
    "# Sonuçları yazdırma\n",
    "for user_id, analysis in user_analyses.items():\n",
    "    print(f\"Analiz Sonuçları - {user_id}:\\n{analysis}\\n{'='*30}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0031c86e-81f4-4eef-9e0e-28037abf9883': {'total_message_length': 5701,\n",
       "  'average_word_count_per_sentence': 63.07142857142857,\n",
       "  'average_word_length': 5.438278595696489,\n",
       "  'english_conjunctions_count': 32,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 14},\n",
       " '0225686d-b825-4cac-8691-3a3a5343df2b': {'total_message_length': 4700,\n",
       "  'average_word_count_per_sentence': 39.388888888888886,\n",
       "  'average_word_length': 5.423131170662906,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 65},\n",
       " '041f950b-c013-409a-a642-cffff60b9d4b': {'total_message_length': 5967,\n",
       "  'average_word_count_per_sentence': 97.55555555555556,\n",
       "  'average_word_length': 5.619589977220957,\n",
       "  'english_conjunctions_count': 13,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 100},\n",
       " '04f91058-d0f8-4324-83b2-19c671f433dc': {'total_message_length': 2282,\n",
       "  'average_word_count_per_sentence': 17.75,\n",
       "  'average_word_length': 5.087323943661972,\n",
       "  'english_conjunctions_count': 6,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 12},\n",
       " '089eb66d-4c3a-4f58-b98f-a3774a2efb34': {'total_message_length': 18669,\n",
       "  'average_word_count_per_sentence': 28.767441860465116,\n",
       "  'average_word_length': 6.212206952303961,\n",
       "  'english_conjunctions_count': 59,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 271},\n",
       " '090d6217-5d69-4929-a342-19abab78324f': {'total_message_length': 21914,\n",
       "  'average_word_count_per_sentence': 33.02739726027397,\n",
       "  'average_word_length': 7.566569888013272,\n",
       "  'english_conjunctions_count': 20,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 297},\n",
       " '0c95c563-f1e1-4a35-844c-2e8ccdd1b161': {'total_message_length': 5107,\n",
       "  'average_word_count_per_sentence': 46.86666666666667,\n",
       "  'average_word_length': 5.97724039829303,\n",
       "  'english_conjunctions_count': 9,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 64},\n",
       " '0ddfae9c-0dbd-4fbe-9e68-c3e0cb73b8fc': {'total_message_length': 2008,\n",
       "  'average_word_count_per_sentence': 29.454545454545453,\n",
       "  'average_word_length': 5.160493827160494,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 12},\n",
       " '0e466794-f7f8-4cc2-b07e-070b13a0b5e1': {'total_message_length': 27590,\n",
       "  'average_word_count_per_sentence': 67.97826086956522,\n",
       "  'average_word_length': 7.228333866325552,\n",
       "  'english_conjunctions_count': 38,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 473},\n",
       " '0f0c953a-a472-47c1-809b-9fc14dba9091': {'total_message_length': 3961,\n",
       "  'average_word_count_per_sentence': 34.11764705882353,\n",
       "  'average_word_length': 5.451724137931034,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 38},\n",
       " '1029802d-1057-4e3e-b827-e8a9c2ded3b9': {'total_message_length': 14119,\n",
       "  'average_word_count_per_sentence': 35.53846153846154,\n",
       "  'average_word_length': 6.270562770562771,\n",
       "  'english_conjunctions_count': 23,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 193},\n",
       " '1038cb22-8ad2-4030-b44a-59f10352e91c': {'total_message_length': 21081,\n",
       "  'average_word_count_per_sentence': 36.08064516129032,\n",
       "  'average_word_length': 7.94456861868574,\n",
       "  'english_conjunctions_count': 21,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 339},\n",
       " '106ffe99-c787-4d09-9076-4ba411eb68b1': {'total_message_length': 5643,\n",
       "  'average_word_count_per_sentence': 35.8,\n",
       "  'average_word_length': 5.298324022346368,\n",
       "  'english_conjunctions_count': 15,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 75},\n",
       " '139235c7-736c-4237-92f0-92e8c116832c': {'total_message_length': 0,\n",
       "  'average_word_count_per_sentence': 0,\n",
       "  'average_word_length': 0,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '14ce054d-4619-4685-ba9b-4b5cd6f81b2d': {'total_message_length': 6648,\n",
       "  'average_word_count_per_sentence': 78.5,\n",
       "  'average_word_length': 7.002547770700637,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 155},\n",
       " '152a7787-ecd1-448f-a98e-8af0826d8215': {'total_message_length': 5768,\n",
       "  'average_word_count_per_sentence': 25.933333333333334,\n",
       "  'average_word_length': 6.0347043701799485,\n",
       "  'english_conjunctions_count': 6,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 63},\n",
       " '17bd62e7-6792-4399-a573-07456a73901b': {'total_message_length': 7435,\n",
       "  'average_word_count_per_sentence': 30.10810810810811,\n",
       "  'average_word_length': 5.466786355475763,\n",
       "  'english_conjunctions_count': 25,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 99},\n",
       " '1b54e38b-3b1d-425e-835a-d1e0fb2694fc': {'total_message_length': 8446,\n",
       "  'average_word_count_per_sentence': 58.44444444444444,\n",
       "  'average_word_length': 6.701520912547529,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 155},\n",
       " '223ae726-cb25-49df-a125-c4af3519c8e8': {'total_message_length': 2463,\n",
       "  'average_word_count_per_sentence': 22.875,\n",
       "  'average_word_length': 5.426229508196721,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 14},\n",
       " '22bb7162-3399-464a-b30b-cf1fc3210b4e': {'total_message_length': 7852,\n",
       "  'average_word_count_per_sentence': 55.285714285714285,\n",
       "  'average_word_length': 5.359173126614987,\n",
       "  'english_conjunctions_count': 25,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 77},\n",
       " '2446216c-c557-4ee8-b470-7e2ae3c88968': {'total_message_length': 4738,\n",
       "  'average_word_count_per_sentence': 115.8,\n",
       "  'average_word_length': 6.853195164075993,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 108},\n",
       " '24f01035-0717-4256-9952-c415aa8ecd10': {'total_message_length': 47716,\n",
       "  'average_word_count_per_sentence': 75.13636363636364,\n",
       "  'average_word_length': 7.765073603549102,\n",
       "  'english_conjunctions_count': 51,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 687},\n",
       " '26d95379-e2f1-454c-a9d2-60cd80bc06a5': {'total_message_length': 4238,\n",
       "  'average_word_count_per_sentence': 20.3,\n",
       "  'average_word_length': 5.752052545155993,\n",
       "  'english_conjunctions_count': 13,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 70},\n",
       " '271b130d-50bd-436e-add6-38d9c618be8a': {'total_message_length': 3672,\n",
       "  'average_word_count_per_sentence': 31.833333333333332,\n",
       "  'average_word_length': 5.209424083769633,\n",
       "  'english_conjunctions_count': 19,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 10},\n",
       " '27de4332-d81f-47a2-b2a9-c0b023a30919': {'total_message_length': 6513,\n",
       "  'average_word_count_per_sentence': 37.857142857142854,\n",
       "  'average_word_length': 6.628930817610063,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 84},\n",
       " '2b9cf078-c56b-4020-9197-cd9f7d4f909c': {'total_message_length': 9555,\n",
       "  'average_word_count_per_sentence': 69.26666666666667,\n",
       "  'average_word_length': 7.422521655437921,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 153},\n",
       " '30283b91-7fc3-4125-985b-b441f0f489d6': {'total_message_length': 8349,\n",
       "  'average_word_count_per_sentence': 77.14285714285714,\n",
       "  'average_word_length': 6.125925925925926,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 114},\n",
       " '3104d903-6012-484c-bd00-b93594b289ea': {'total_message_length': 7395,\n",
       "  'average_word_count_per_sentence': 58.4375,\n",
       "  'average_word_length': 6.5037433155080215,\n",
       "  'english_conjunctions_count': 11,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 115},\n",
       " '331a45a0-341c-4faf-97de-75c82b31b61f': {'total_message_length': 2055,\n",
       "  'average_word_count_per_sentence': 14.681818181818182,\n",
       "  'average_word_length': 5.021671826625387,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 8},\n",
       " '36bab6e3-0d16-4626-846b-33c0384f0c79': {'total_message_length': 18632,\n",
       "  'average_word_count_per_sentence': 42.824561403508774,\n",
       "  'average_word_length': 5.571487095452683,\n",
       "  'english_conjunctions_count': 39,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 210},\n",
       " '38296004-7336-4797-9db4-662a48309a1c': {'total_message_length': 921,\n",
       "  'average_word_count_per_sentence': 36.75,\n",
       "  'average_word_length': 5.217687074829932,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 22},\n",
       " '410d88de-2489-4a83-8dae-6bc01e8e9f78': {'total_message_length': 227,\n",
       "  'average_word_count_per_sentence': 8.4,\n",
       "  'average_word_length': 4.5,\n",
       "  'english_conjunctions_count': 1,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '41b82427-7ae2-4c55-b8a3-310bb4abada0': {'total_message_length': 10121,\n",
       "  'average_word_count_per_sentence': 46.61538461538461,\n",
       "  'average_word_length': 7.031353135313531,\n",
       "  'english_conjunctions_count': 13,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 141},\n",
       " '42980d53-7bcd-4a36-bf3a-aa43f7417ac5': {'total_message_length': 5984,\n",
       "  'average_word_count_per_sentence': 59.15384615384615,\n",
       "  'average_word_length': 6.218465539661898,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 84},\n",
       " '43ff9786-2b47-425b-8bad-e274d9988a0e': {'total_message_length': 23750,\n",
       "  'average_word_count_per_sentence': 55.41818181818182,\n",
       "  'average_word_length': 6.466535433070866,\n",
       "  'english_conjunctions_count': 44,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 285},\n",
       " '450550b4-3bb9-4b12-a7fd-121ac4a36ea9': {'total_message_length': 4093,\n",
       "  'average_word_count_per_sentence': 51.5,\n",
       "  'average_word_length': 5.383495145631068,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 54},\n",
       " '45d2c21a-828e-46d9-8fcd-a4a39888773c': {'total_message_length': 3592,\n",
       "  'average_word_count_per_sentence': 27.11111111111111,\n",
       "  'average_word_length': 5.987704918032787,\n",
       "  'english_conjunctions_count': 9,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 42},\n",
       " '4e6fdf20-96fa-4f62-bf55-5c4c695afebe': {'total_message_length': 7605,\n",
       "  'average_word_count_per_sentence': 55.2,\n",
       "  'average_word_length': 5.509963768115942,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 126},\n",
       " '4fb21782-81f0-47c1-8831-58a748904a2c': {'total_message_length': 3349,\n",
       "  'average_word_count_per_sentence': 38.714285714285715,\n",
       "  'average_word_length': 5.186346863468635,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 53},\n",
       " '50a71154-2269-460c-9341-291221c6ef02': {'total_message_length': 65180,\n",
       "  'average_word_count_per_sentence': 99.38571428571429,\n",
       "  'average_word_length': 7.466724162713813,\n",
       "  'english_conjunctions_count': 84,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 939},\n",
       " '51f35201-da77-4b6d-a455-99cc84195c5c': {'total_message_length': 4891,\n",
       "  'average_word_count_per_sentence': 54.38461538461539,\n",
       "  'average_word_length': 5.718528995756719,\n",
       "  'english_conjunctions_count': 15,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 28},\n",
       " '530b4e58-756d-4627-ad08-65ba0457ad42': {'total_message_length': 5501,\n",
       "  'average_word_count_per_sentence': 50.8125,\n",
       "  'average_word_length': 5.479704797047971,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 45},\n",
       " '53ad17d1-5eb2-4af6-9c38-3c90c05ee695': {'total_message_length': 19642,\n",
       "  'average_word_count_per_sentence': 36.39344262295082,\n",
       "  'average_word_length': 7.313063063063063,\n",
       "  'english_conjunctions_count': 18,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 328},\n",
       " '5541316f-6fbd-4441-b513-ac252e6355ec': {'total_message_length': 7602,\n",
       "  'average_word_count_per_sentence': 55.4,\n",
       "  'average_word_length': 5.7048736462093865,\n",
       "  'english_conjunctions_count': 19,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 65},\n",
       " '56c6f8dd-f37c-44d2-9820-9459aa34c8af': {'total_message_length': 2273,\n",
       "  'average_word_count_per_sentence': 13.25925925925926,\n",
       "  'average_word_length': 5.337988826815643,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 22},\n",
       " '58bee29c-a749-463e-8d56-c4edf0815b3f': {'total_message_length': 9679,\n",
       "  'average_word_count_per_sentence': 33.80952380952381,\n",
       "  'average_word_length': 5.5,\n",
       "  'english_conjunctions_count': 20,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 116},\n",
       " '58fcd378-aa29-4067-813c-bb4de525428e': {'total_message_length': 16746,\n",
       "  'average_word_count_per_sentence': 32.983870967741936,\n",
       "  'average_word_length': 6.796577017114914,\n",
       "  'english_conjunctions_count': 35,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 269},\n",
       " '597c7a93-6b16-4af9-9846-154599f596e1': {'total_message_length': 927,\n",
       "  'average_word_count_per_sentence': 12.76923076923077,\n",
       "  'average_word_length': 4.650602409638554,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 2},\n",
       " '5a62a8ee-c67c-475e-bd85-cf6d83c90ea9': {'total_message_length': 64231,\n",
       "  'average_word_count_per_sentence': 96.05333333333333,\n",
       "  'average_word_length': 7.181704608550805,\n",
       "  'english_conjunctions_count': 72,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 1233},\n",
       " '5dbf76be-6634-4d42-a87f-b62b7fa6ceae': {'total_message_length': 15607,\n",
       "  'average_word_count_per_sentence': 41.58695652173913,\n",
       "  'average_word_length': 6.880292733925771,\n",
       "  'english_conjunctions_count': 20,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 230},\n",
       " '5e481e20-f714-4f11-b941-0ef2fd5976d3': {'total_message_length': 1694,\n",
       "  'average_word_count_per_sentence': 210.0,\n",
       "  'average_word_length': 6.109523809523809,\n",
       "  'english_conjunctions_count': 2,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 17},\n",
       " '6312a21b-c6be-44f9-ad81-46307b339fb6': {'total_message_length': 666,\n",
       "  'average_word_count_per_sentence': 9.5,\n",
       "  'average_word_length': 4.947368421052632,\n",
       "  'english_conjunctions_count': 2,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 2},\n",
       " '63216e9b-5d0b-4047-97ee-302495d61640': {'total_message_length': 5154,\n",
       "  'average_word_count_per_sentence': 36.473684210526315,\n",
       "  'average_word_length': 5.8311688311688314,\n",
       "  'english_conjunctions_count': 16,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 80},\n",
       " '65ea56c3-e205-4ed9-8b85-bd1876228cee': {'total_message_length': 3669,\n",
       "  'average_word_count_per_sentence': 44.9,\n",
       "  'average_word_length': 5.351893095768374,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 26},\n",
       " '663f8b4e-b683-4365-8316-b1dd1d325110': {'total_message_length': 8416,\n",
       "  'average_word_count_per_sentence': 30.25,\n",
       "  'average_word_length': 7.268595041322314,\n",
       "  'english_conjunctions_count': 16,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 90},\n",
       " '668ad17e-0240-49f7-b5a7-d22e502554c6': {'total_message_length': 0,\n",
       "  'average_word_count_per_sentence': 0,\n",
       "  'average_word_length': 0,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '67c4a788-ec23-48c4-b6db-d76be6e118d6': {'total_message_length': 13447,\n",
       "  'average_word_count_per_sentence': 46.125,\n",
       "  'average_word_length': 5.930623306233063,\n",
       "  'english_conjunctions_count': 35,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 151},\n",
       " '69426dc0-b745-4f89-9c9a-943828d19db9': {'total_message_length': 23658,\n",
       "  'average_word_count_per_sentence': 70.02702702702703,\n",
       "  'average_word_length': 7.503280586646083,\n",
       "  'english_conjunctions_count': 33,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 294},\n",
       " '6a2003ad-a05a-41c9-9d48-e98491a90499': {'total_message_length': 92,\n",
       "  'average_word_count_per_sentence': 8.0,\n",
       "  'average_word_length': 4.875,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '6a903495-c5be-4263-b4dd-75e2bbc30434': {'total_message_length': 3259,\n",
       "  'average_word_count_per_sentence': 29.823529411764707,\n",
       "  'average_word_length': 5.455621301775148,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 45},\n",
       " '6b4e988c-eead-46ff-a35b-b2fd325b2698': {'total_message_length': 302,\n",
       "  'average_word_count_per_sentence': 5.363636363636363,\n",
       "  'average_word_length': 4.288135593220339,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '6c37a2d7-f786-4fc2-ba7a-04c3f961a365': {'total_message_length': 18026,\n",
       "  'average_word_count_per_sentence': 71.96296296296296,\n",
       "  'average_word_length': 7.504374678332476,\n",
       "  'english_conjunctions_count': 15,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 291},\n",
       " '6d5742c1-77c4-429c-8f6e-ef1262ca5557': {'total_message_length': 17422,\n",
       "  'average_word_count_per_sentence': 39.15151515151515,\n",
       "  'average_word_length': 5.59094427244582,\n",
       "  'english_conjunctions_count': 50,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 178},\n",
       " '6de08d44-bb5b-491d-a11e-51caa1eccd0c': {'total_message_length': 972,\n",
       "  'average_word_count_per_sentence': 14.8,\n",
       "  'average_word_length': 5.635135135135135,\n",
       "  'english_conjunctions_count': 1,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 4},\n",
       " '7421916d-a0b5-4f0b-ad47-25a0cbf1b239': {'total_message_length': 4238,\n",
       "  'average_word_count_per_sentence': 42.333333333333336,\n",
       "  'average_word_length': 5.437795275590551,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 73},\n",
       " '745bb746-6467-4146-8ef5-55f3ee3f589e': {'total_message_length': 4872,\n",
       "  'average_word_count_per_sentence': 30.464285714285715,\n",
       "  'average_word_length': 4.731535756154748,\n",
       "  'english_conjunctions_count': 24,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 16},\n",
       " '745ffa9e-f540-488a-b752-a3add11cb30b': {'total_message_length': 772,\n",
       "  'average_word_count_per_sentence': 9.384615384615385,\n",
       "  'average_word_length': 5.434426229508197,\n",
       "  'english_conjunctions_count': 1,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 2},\n",
       " '746b8f06-1e89-43b8-b73c-1121eecfc854': {'total_message_length': 103,\n",
       "  'average_word_count_per_sentence': 21.0,\n",
       "  'average_word_length': 3.9523809523809526,\n",
       "  'english_conjunctions_count': 1,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " '76a73730-6432-4f30-bb59-7a609bc9ba43': {'total_message_length': 4306,\n",
       "  'average_word_count_per_sentence': 37.88235294117647,\n",
       "  'average_word_length': 5.458074534161491,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 46},\n",
       " '79cf72c1-d3aa-4e09-8ff2-6a8ad51b22ef': {'total_message_length': 2500,\n",
       "  'average_word_count_per_sentence': 38.2,\n",
       "  'average_word_length': 5.4319371727748695,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 30},\n",
       " '7ac3f7a5-bdbb-470c-a1b3-03da5887a408': {'total_message_length': 8665,\n",
       "  'average_word_count_per_sentence': 19.265625,\n",
       "  'average_word_length': 5.855636658556366,\n",
       "  'english_conjunctions_count': 21,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 42},\n",
       " '7af13aaa-dd6a-4850-856d-73ea55d0c2ff': {'total_message_length': 4584,\n",
       "  'average_word_count_per_sentence': 29.5,\n",
       "  'average_word_length': 10.024213075060533,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 30},\n",
       " '7b0ecddc-caa5-4b81-88ea-cd65a7270900': {'total_message_length': 2569,\n",
       "  'average_word_count_per_sentence': 19.954545454545453,\n",
       "  'average_word_length': 4.876993166287016,\n",
       "  'english_conjunctions_count': 19,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 24},\n",
       " '7c734c12-e18b-4de8-9004-c2523878db31': {'total_message_length': 1899,\n",
       "  'average_word_count_per_sentence': 35.875,\n",
       "  'average_word_length': 5.585365853658536,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 31},\n",
       " '8121427e-e5b1-400b-8342-d5d1c865f1d7': {'total_message_length': 4693,\n",
       "  'average_word_count_per_sentence': 18.822222222222223,\n",
       "  'average_word_length': 4.442739079102715,\n",
       "  'english_conjunctions_count': 31,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 4},\n",
       " '81fdeb2a-e7e5-4a05-8058-d31ea579b0d9': {'total_message_length': 4061,\n",
       "  'average_word_count_per_sentence': 28.05,\n",
       "  'average_word_length': 5.83065953654189,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 12},\n",
       " '8505dcd7-9a9e-4ac3-b708-d3ffea7e6bb8': {'total_message_length': 2287,\n",
       "  'average_word_count_per_sentence': 25.928571428571427,\n",
       "  'average_word_length': 5.289256198347108,\n",
       "  'english_conjunctions_count': 6,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 14},\n",
       " '854397cb-a264-4bad-b30f-a9c1ba012511': {'total_message_length': 35602,\n",
       "  'average_word_count_per_sentence': 55.6,\n",
       "  'average_word_length': 7.861095738793581,\n",
       "  'english_conjunctions_count': 49,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 553},\n",
       " '8a84e6e5-d200-4cc2-a288-5c81201100c7': {'total_message_length': 7400,\n",
       "  'average_word_count_per_sentence': 13.225,\n",
       "  'average_word_length': 6.034026465028355,\n",
       "  'english_conjunctions_count': 17,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 57},\n",
       " '8be8e839-6dd0-44e0-b039-170b5b77cf2a': {'total_message_length': 5351,\n",
       "  'average_word_count_per_sentence': 29.25,\n",
       "  'average_word_length': 10.188034188034187,\n",
       "  'english_conjunctions_count': 2,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 26},\n",
       " '918f3066-0b5a-46dc-92b8-b4279f0cb26e': {'total_message_length': 67379,\n",
       "  'average_word_count_per_sentence': 100.09859154929578,\n",
       "  'average_word_length': 7.458984100182918,\n",
       "  'english_conjunctions_count': 63,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 601},\n",
       " '941a3ef2-7559-430c-8682-830a04a6864c': {'total_message_length': 10328,\n",
       "  'average_word_count_per_sentence': 29.48780487804878,\n",
       "  'average_word_length': 6.795698924731183,\n",
       "  'english_conjunctions_count': 14,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 100},\n",
       " '97f57cf9-4f02-4f8c-b65c-8ea0009a82a2': {'total_message_length': 1688,\n",
       "  'average_word_count_per_sentence': 26.3,\n",
       "  'average_word_length': 5.452471482889734,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 4},\n",
       " 'a0132e5d-4e16-4600-b2a7-5b6cd68a8b6a': {'total_message_length': 7748,\n",
       "  'average_word_count_per_sentence': 61.473684210526315,\n",
       "  'average_word_length': 5.302226027397261,\n",
       "  'english_conjunctions_count': 25,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 69},\n",
       " 'a014d72a-81ad-43a4-8a2c-8046b7666320': {'total_message_length': 5776,\n",
       "  'average_word_count_per_sentence': 21.64516129032258,\n",
       "  'average_word_length': 7.5201192250372575,\n",
       "  'english_conjunctions_count': 6,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 55},\n",
       " 'a1e834df-f4f6-4962-bcda-17f8aefc7f86': {'total_message_length': 5240,\n",
       "  'average_word_count_per_sentence': 26.5,\n",
       "  'average_word_length': 4.898584905660377,\n",
       "  'english_conjunctions_count': 28,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 20},\n",
       " 'a70ebc32-7ee1-456f-9fa1-bef302fb0e78': {'total_message_length': 1128,\n",
       "  'average_word_count_per_sentence': 14.692307692307692,\n",
       "  'average_word_length': 4.81151832460733,\n",
       "  'english_conjunctions_count': 3,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 2},\n",
       " 'a8270e39-5d70-4f1a-b031-6b4fcc55de01': {'total_message_length': 5769,\n",
       "  'average_word_count_per_sentence': 34.523809523809526,\n",
       "  'average_word_length': 6.5296551724137935,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 59},\n",
       " 'a948a3e5-70e5-447a-b3b4-baf3661f7b7e': {'total_message_length': 15864,\n",
       "  'average_word_count_per_sentence': 89.41666666666667,\n",
       "  'average_word_length': 6.166821994408202,\n",
       "  'english_conjunctions_count': 38,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 127},\n",
       " 'aa15f751-f65f-4397-b138-df7b8301a12f': {'total_message_length': 10719,\n",
       "  'average_word_count_per_sentence': 70.75,\n",
       "  'average_word_length': 5.2249705535924615,\n",
       "  'english_conjunctions_count': 27,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 107},\n",
       " 'ab775974-7ddb-4a60-aef2-4655d7bb746d': {'total_message_length': 8888,\n",
       "  'average_word_count_per_sentence': 20.76923076923077,\n",
       "  'average_word_length': 5.497037037037037,\n",
       "  'english_conjunctions_count': 18,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 108},\n",
       " 'adb31914-fa31-471d-b476-6111c393ec42': {'total_message_length': 5377,\n",
       "  'average_word_count_per_sentence': 15.586206896551724,\n",
       "  'average_word_length': 4.772123893805309,\n",
       "  'english_conjunctions_count': 14,\n",
       "  'example_words_count': 6,\n",
       "  'total_parentheses_count': 71},\n",
       " 'b0640e51-6879-40cb-a4f5-329f952ef99d': {'total_message_length': 0,\n",
       "  'average_word_count_per_sentence': 0,\n",
       "  'average_word_length': 0,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " 'b13a2e11-1f0a-4f1e-9735-5f0674713593': {'total_message_length': 27730,\n",
       "  'average_word_count_per_sentence': 114.70833333333333,\n",
       "  'average_word_length': 8.56738103886669,\n",
       "  'english_conjunctions_count': 38,\n",
       "  'example_words_count': 4,\n",
       "  'total_parentheses_count': 369},\n",
       " 'b24c3a33-2952-4ae4-9f2d-643d8fdbc600': {'total_message_length': 44974,\n",
       "  'average_word_count_per_sentence': 84.16949152542372,\n",
       "  'average_word_length': 7.386830447039871,\n",
       "  'english_conjunctions_count': 61,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 595},\n",
       " 'b47559b3-3b5f-4958-bfa5-ec9f7a36aec0': {'total_message_length': 7411,\n",
       "  'average_word_count_per_sentence': 38.34615384615385,\n",
       "  'average_word_length': 5.936810431293882,\n",
       "  'english_conjunctions_count': 26,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 54},\n",
       " 'b57fe283-97a4-457f-a5d0-ef441650c968': {'total_message_length': 1477,\n",
       "  'average_word_count_per_sentence': 19.75,\n",
       "  'average_word_length': 5.206751054852321,\n",
       "  'english_conjunctions_count': 4,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 16},\n",
       " 'b5fe7d4d-e4a5-4ebd-8058-069d6505eb01': {'total_message_length': 5727,\n",
       "  'average_word_count_per_sentence': 39.89473684210526,\n",
       "  'average_word_length': 6.014511873350924,\n",
       "  'english_conjunctions_count': 7,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 78},\n",
       " 'b61f3f4c-785e-4d7c-b963-4480ece4656f': {'total_message_length': 13801,\n",
       "  'average_word_count_per_sentence': 53.407407407407405,\n",
       "  'average_word_length': 7.6900138696255205,\n",
       "  'english_conjunctions_count': 16,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 241},\n",
       " 'b73f91f8-732f-4a48-bcbd-eadbbb457a94': {'total_message_length': 9189,\n",
       "  'average_word_count_per_sentence': 67.47058823529412,\n",
       "  'average_word_length': 6.446381865736704,\n",
       "  'english_conjunctions_count': 19,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 133},\n",
       " 'ba18e4e8-2c26-46d4-ba31-cc21947aabd5': {'total_message_length': 7229,\n",
       "  'average_word_count_per_sentence': 36.96296296296296,\n",
       "  'average_word_length': 6.057114228456914,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 2,\n",
       "  'total_parentheses_count': 62},\n",
       " 'c0f51763-0c69-45fb-a4d7-6906d53db43d': {'total_message_length': 208,\n",
       "  'average_word_count_per_sentence': 12.333333333333334,\n",
       "  'average_word_length': 4.675675675675675,\n",
       "  'english_conjunctions_count': 1,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " 'c21be348-17bd-4fdd-88f5-137f6a13cdee': {'total_message_length': 3464,\n",
       "  'average_word_count_per_sentence': 28.5,\n",
       "  'average_word_length': 5.502923976608187,\n",
       "  'english_conjunctions_count': 9,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 31},\n",
       " 'c65a33f5-6acf-4ff1-86fe-6003f165d44e': {'total_message_length': 2810,\n",
       "  'average_word_count_per_sentence': 21.6,\n",
       "  'average_word_length': 7.037037037037037,\n",
       "  'english_conjunctions_count': 5,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 32},\n",
       " 'c91d6fef-baf5-4e77-8bfc-b14fb7fc770d': {'total_message_length': 9473,\n",
       "  'average_word_count_per_sentence': 30.085714285714285,\n",
       "  'average_word_length': 7.027540360873695,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 121},\n",
       " 'cc9ecae2-a3bf-43df-9628-56f587f400be': {'total_message_length': 8042,\n",
       "  'average_word_count_per_sentence': 63.5,\n",
       "  'average_word_length': 5.396325459317585,\n",
       "  'english_conjunctions_count': 21,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 83},\n",
       " 'd4ab3f85-fdfb-434b-9774-96d94fd15d69': {'total_message_length': 7574,\n",
       "  'average_word_count_per_sentence': 59.21052631578947,\n",
       "  'average_word_length': 5.578666666666667,\n",
       "  'english_conjunctions_count': 18,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 62},\n",
       " 'd61b757d-88bc-4a33-a620-0d76712207c3': {'total_message_length': 11711,\n",
       "  'average_word_count_per_sentence': 35.68,\n",
       "  'average_word_length': 5.378363228699552,\n",
       "  'english_conjunctions_count': 29,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 160},\n",
       " 'd846484d-9257-40b4-98b9-6854288e8add': {'total_message_length': 10021,\n",
       "  'average_word_count_per_sentence': 52.30769230769231,\n",
       "  'average_word_length': 6.10514705882353,\n",
       "  'english_conjunctions_count': 24,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 158},\n",
       " 'da219169-aacb-48b8-abdc-e25f08ad029e': {'total_message_length': 1838,\n",
       "  'average_word_count_per_sentence': 19.533333333333335,\n",
       "  'average_word_length': 5.296928327645051,\n",
       "  'english_conjunctions_count': 8,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 8},\n",
       " 'da6b70d5-29f6-491a-ad46-037c77067128': {'total_message_length': 0,\n",
       "  'average_word_count_per_sentence': 0,\n",
       "  'average_word_length': 0,\n",
       "  'english_conjunctions_count': 0,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 0},\n",
       " 'db921a07-c234-41c6-8891-ef1b8a22a2f5': {'total_message_length': 4254,\n",
       "  'average_word_count_per_sentence': 25.344827586206897,\n",
       "  'average_word_length': 4.650340136054422,\n",
       "  'english_conjunctions_count': 19,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 11},\n",
       " 'dc9d3dc4-de7d-44e0-916c-04c85f94012a': {'total_message_length': 20846,\n",
       "  'average_word_count_per_sentence': 56.47727272727273,\n",
       "  'average_word_length': 6.622132796780684,\n",
       "  'english_conjunctions_count': 40,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 272},\n",
       " 'dd898b12-b04b-404e-9b59-f846a162c177': {'total_message_length': 9388,\n",
       "  'average_word_count_per_sentence': 24.97872340425532,\n",
       "  'average_word_length': 6.680579216354344,\n",
       "  'english_conjunctions_count': 22,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 110},\n",
       " 'dfe46143-c07c-4bb6-bddc-7458995dba2f': {'total_message_length': 15052,\n",
       "  'average_word_count_per_sentence': 41.11363636363637,\n",
       "  'average_word_length': 6.911553344389166,\n",
       "  'english_conjunctions_count': 29,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 215},\n",
       " 'e264c424-a241-43f7-acca-9fbbf21dc1c6': {'total_message_length': 18764,\n",
       "  'average_word_count_per_sentence': 70.42857142857143,\n",
       "  'average_word_length': 6.440162271805274,\n",
       "  'english_conjunctions_count': 47,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 232},\n",
       " 'e469cc3a-40fc-44e1-a7b7-3b2fbe621a8b': {'total_message_length': 1533,\n",
       "  'average_word_count_per_sentence': 39.0,\n",
       "  'average_word_length': 6.364102564102564,\n",
       "  'english_conjunctions_count': 3,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 6},\n",
       " 'e76b910b-3156-4801-a73e-ddb16c763d43': {'total_message_length': 11137,\n",
       "  'average_word_count_per_sentence': 44.21212121212121,\n",
       "  'average_word_length': 6.4084989718985605,\n",
       "  'english_conjunctions_count': 24,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 161},\n",
       " 'e779a2d6-6e4e-4ade-8a30-d624166c2ab3': {'total_message_length': 2901,\n",
       "  'average_word_count_per_sentence': 31.0,\n",
       "  'average_word_length': 5.3986175115207375,\n",
       "  'english_conjunctions_count': 4,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 10},\n",
       " 'e8fd2278-1620-432d-81cb-02cac8543456': {'total_message_length': 6991,\n",
       "  'average_word_count_per_sentence': 79.0,\n",
       "  'average_word_length': 5.189873417721519,\n",
       "  'english_conjunctions_count': 16,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 102},\n",
       " 'ebe86296-3cae-429a-9a7c-aa8f21cfd7cb': {'total_message_length': 2581,\n",
       "  'average_word_count_per_sentence': 18.761904761904763,\n",
       "  'average_word_length': 5.401015228426396,\n",
       "  'english_conjunctions_count': 12,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 2},\n",
       " 'ef5b3fbc-f5d2-4446-bb4f-7d8b2a3026e9': {'total_message_length': 18712,\n",
       "  'average_word_count_per_sentence': 23.73,\n",
       "  'average_word_length': 6.321533923303835,\n",
       "  'english_conjunctions_count': 28,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 228},\n",
       " 'f24219d6-07f0-4baf-80ac-18475dc5b66f': {'total_message_length': 4035,\n",
       "  'average_word_count_per_sentence': 30.857142857142858,\n",
       "  'average_word_length': 5.219135802469136,\n",
       "  'english_conjunctions_count': 9,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 69},\n",
       " 'f2f18684-4a16-4c05-a2d1-c0f96d1de869': {'total_message_length': 23006,\n",
       "  'average_word_count_per_sentence': 41.76056338028169,\n",
       "  'average_word_length': 6.075210792580101,\n",
       "  'english_conjunctions_count': 34,\n",
       "  'example_words_count': 1,\n",
       "  'total_parentheses_count': 192},\n",
       " 'f852596d-fdca-45aa-9050-d4f76ce6a53c': {'total_message_length': 21776,\n",
       "  'average_word_count_per_sentence': 84.43333333333334,\n",
       "  'average_word_length': 7.281879194630872,\n",
       "  'english_conjunctions_count': 31,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 307},\n",
       " 'f8ec3336-fd48-4654-ad98-62ccfb96d096': {'total_message_length': 7143,\n",
       "  'average_word_count_per_sentence': 69.85714285714286,\n",
       "  'average_word_length': 5.768916155419223,\n",
       "  'english_conjunctions_count': 10,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 78},\n",
       " 'fb8de815-224c-4d06-9fd4-7156d1a9920d': {'total_message_length': 11417,\n",
       "  'average_word_count_per_sentence': 46.61290322580645,\n",
       "  'average_word_length': 6.3695501730103805,\n",
       "  'english_conjunctions_count': 13,\n",
       "  'example_words_count': 0,\n",
       "  'total_parentheses_count': 199}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df = pd.DataFrame.from_dict(user_analyses, orient='index')\n",
    "\n",
    "# Step 2: Merge the two DataFrames based on the index (html file codes)\n",
    "df = df.merge(new_features_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIGHT NOW THIS DF DOES NOT INCLUDE THE BROKEN FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>total_message_length</th>\n",
       "      <th>average_word_count_per_sentence</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>english_conjunctions_count</th>\n",
       "      <th>example_words_count</th>\n",
       "      <th>total_parentheses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>5701</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>5.438279</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>4700</td>\n",
       "      <td>39.388889</td>\n",
       "      <td>5.423131</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>5967</td>\n",
       "      <td>97.555556</td>\n",
       "      <td>5.619590</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>2282</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>5.087324</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>18669</td>\n",
       "      <td>28.767442</td>\n",
       "      <td>6.212207</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24219d6-07f0-4baf-80ac-18475dc5b66f</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.380952</td>\n",
       "      <td>202.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>0.377319</td>\n",
       "      <td>0.981626</td>\n",
       "      <td>4035</td>\n",
       "      <td>30.857143</td>\n",
       "      <td>5.219136</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2f18684-4a16-4c05-a2d1-c0f96d1de869</th>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.211268</td>\n",
       "      <td>200.408451</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.884943</td>\n",
       "      <td>0.482037</td>\n",
       "      <td>0.992739</td>\n",
       "      <td>23006</td>\n",
       "      <td>41.760563</td>\n",
       "      <td>6.075211</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f852596d-fdca-45aa-9050-d4f76ce6a53c</th>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.766667</td>\n",
       "      <td>116.266667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.919986</td>\n",
       "      <td>0.492801</td>\n",
       "      <td>0.929497</td>\n",
       "      <td>21776</td>\n",
       "      <td>84.433333</td>\n",
       "      <td>7.281879</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8ec3336-fd48-4654-ad98-62ccfb96d096</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>272.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.398174</td>\n",
       "      <td>0.982006</td>\n",
       "      <td>7143</td>\n",
       "      <td>69.857143</td>\n",
       "      <td>5.768916</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8de815-224c-4d06-9fd4-7156d1a9920d</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>11417</td>\n",
       "      <td>46.612903</td>\n",
       "      <td>6.369550</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  total_discomfort_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883           14.0                     8.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b           18.0                     0.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b            9.0                     8.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc           20.0                     3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0                    16.0   \n",
       "...                                             ...                     ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f           21.0                     1.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869           71.0                     3.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c           30.0                     6.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096           14.0                     0.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d           31.0                    16.0   \n",
       "\n",
       "                                      total_comfort_count  prompt_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  0.0         63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  0.0         39.666667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  1.0         99.111111   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  0.0         17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                  1.0         30.697674   \n",
       "...                                                   ...               ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                  0.0         31.380952   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                  2.0         48.211268   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                  1.0         93.766667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                  1.0         77.000000   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                  2.0         50.806452   \n",
       "\n",
       "                                      response_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883          160.642857  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b          169.166667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b          160.444444   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc          148.500000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34          123.000000   \n",
       "...                                                  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f          202.666667   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869          200.408451   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c          116.266667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096          272.142857   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d          114.548387   \n",
       "\n",
       "                                      response_confusion_total_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                             2.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                             1.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            12.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                             3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            19.0   \n",
       "...                                                              ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                             5.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            17.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                             4.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                             1.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                             3.0   \n",
       "\n",
       "                                      similarity_between_prompts   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0.959773  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0.913921   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0.802151   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0.904731   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    0.889234   \n",
       "...                                                          ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                    0.883792   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                    0.884943   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                    0.919986   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                    0.903643   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    0.902465   \n",
       "\n",
       "                                      avg_sim_between_prompt_codeComment   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                            0.558252  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                            0.556858   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            0.331554   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                            0.419597   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            0.470122   \n",
       "...                                                                  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                            0.377319   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            0.482037   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                            0.492801   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                            0.398174   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                            0.427945   \n",
       "\n",
       "                                      similarity_between_fullpoints   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       0.984955  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       0.988546   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                       0.950704   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       0.980123   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                       0.928597   \n",
       "...                                                             ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                       0.981626   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                       0.992739   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                       0.929497   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                       0.982006   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                       0.988390   \n",
       "\n",
       "                                      total_message_length   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  5701  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  4700   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  5967   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  2282   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                 18669   \n",
       "...                                                    ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                  4035   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                 23006   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                 21776   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                  7143   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                 11417   \n",
       "\n",
       "                                      average_word_count_per_sentence   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                        63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                        39.388889   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                        97.555556   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                        17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                        28.767442   \n",
       "...                                                               ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                        30.857143   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                        41.760563   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                        84.433333   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                        69.857143   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                        46.612903   \n",
       "\n",
       "                                      average_word_length   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883             5.438279  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b             5.423131   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b             5.619590   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc             5.087324   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34             6.212207   \n",
       "...                                                   ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f             5.219136   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869             6.075211   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c             7.281879   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096             5.768916   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d             6.369550   \n",
       "\n",
       "                                      english_conjunctions_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                          32  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                          10   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                          13   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                           6   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                          59   \n",
       "...                                                          ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                           9   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                          34   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                          31   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                          10   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                          13   \n",
       "\n",
       "                                      example_words_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    2  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    2   \n",
       "...                                                   ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                    1   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                    1   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                    0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                    0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    0   \n",
       "\n",
       "                                      total_parentheses_count  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       14  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       65  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                      100  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       12  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                      271  \n",
       "...                                                       ...  \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                       69  \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                      192  \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                      307  \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                       78  \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                      199  \n",
       "\n",
       "[123 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINALIZE YOUR DATAFRAME AND CONCATANATE WITH SCORES\n",
    "\n",
    "### AFTER THAT START CREATING YOUR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUR SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a2003ad-a05a-41c9-9d48-e98491a90499</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81fdeb2a-e7e5-4a05-8058-d31ea579b0d9</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6a903495-c5be-4263-b4dd-75e2bbc30434</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6d5742c1-77c4-429c-8f6e-ef1262ca5557</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code  grade\n",
       "0  6a2003ad-a05a-41c9-9d48-e98491a90499   90.0\n",
       "1  04f91058-d0f8-4324-83b2-19c671f433dc   97.0\n",
       "2  81fdeb2a-e7e5-4a05-8058-d31ea579b0d9   94.0\n",
       "3  6a903495-c5be-4263-b4dd-75e2bbc30434   97.0\n",
       "4  6d5742c1-77c4-429c-8f6e-ef1262ca5557   93.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the scores\n",
    "scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "# selecting the columns we need and we care\n",
    "scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "# show some examples\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUR PROMPT MATCHING\n",
    "\n",
    "### OUR PROMPT MATCHING DOES NOT INCLUDE THE BROKEN FILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTML_File</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24219d6-07f0-4baf-80ac-18475dc5b66f</th>\n",
       "      <td>0.302987</td>\n",
       "      <td>0.418350</td>\n",
       "      <td>0.546734</td>\n",
       "      <td>0.490407</td>\n",
       "      <td>0.466607</td>\n",
       "      <td>0.502019</td>\n",
       "      <td>0.941213</td>\n",
       "      <td>0.928735</td>\n",
       "      <td>0.771037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2f18684-4a16-4c05-a2d1-c0f96d1de869</th>\n",
       "      <td>0.311383</td>\n",
       "      <td>0.368891</td>\n",
       "      <td>0.549631</td>\n",
       "      <td>0.966176</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>0.945437</td>\n",
       "      <td>0.608420</td>\n",
       "      <td>0.934719</td>\n",
       "      <td>0.769781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f852596d-fdca-45aa-9050-d4f76ce6a53c</th>\n",
       "      <td>0.435314</td>\n",
       "      <td>0.975701</td>\n",
       "      <td>0.889675</td>\n",
       "      <td>0.977834</td>\n",
       "      <td>0.903663</td>\n",
       "      <td>0.947942</td>\n",
       "      <td>0.807891</td>\n",
       "      <td>0.956091</td>\n",
       "      <td>0.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8ec3336-fd48-4654-ad98-62ccfb96d096</th>\n",
       "      <td>0.431564</td>\n",
       "      <td>0.993305</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.678769</td>\n",
       "      <td>0.851377</td>\n",
       "      <td>0.906791</td>\n",
       "      <td>0.930365</td>\n",
       "      <td>0.918092</td>\n",
       "      <td>0.630520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8de815-224c-4d06-9fd4-7156d1a9920d</th>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Q0        Q1        Q2        Q3   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.242323  0.650830  0.639897  0.790342  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.412892  0.822821  0.696175  0.909993   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.173714  0.217742  0.274107  0.284707   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.285609  0.548311  0.439191  0.645035   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.444721  0.758592  0.872447  0.712806   \n",
       "...                                        ...       ...       ...       ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f  0.302987  0.418350  0.546734  0.490407   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.311383  0.368891  0.549631  0.966176   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c  0.435314  0.975701  0.889675  0.977834   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096  0.431564  0.993305  0.853336  0.678769   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.449902  0.904886  0.830096  0.879708   \n",
       "\n",
       "                                            Q4        Q5        Q6        Q7   \n",
       "HTML_File                                                                      \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.690072  0.788218  0.428342  0.461473  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.766648  0.987573  0.684214  0.729532   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.487476  0.249203  0.297617  0.538953   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.770841  0.659323  0.553139  0.538424   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.821277  0.916046  0.555504  0.945931   \n",
       "...                                        ...       ...       ...       ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f  0.466607  0.502019  0.941213  0.928735   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.655741  0.945437  0.608420  0.934719   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c  0.903663  0.947942  0.807891  0.956091   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096  0.851377  0.906791  0.930365  0.918092   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.849048  0.970448  0.930143  0.919492   \n",
       "\n",
       "                                            Q8  \n",
       "HTML_File                                       \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.285456  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.491343  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.142434  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.426416  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.590542  \n",
       "...                                        ...  \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f  0.771037  \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.769781  \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c  0.427795  \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096  0.630520  \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.619326  \n",
       "\n",
       "[123 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prompt_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE BETWEEN\n",
    "## DATAFRAME WITH FEATURES & DATAFRAME WITH PROMPT MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_prompt_matching, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>total_message_length</th>\n",
       "      <th>...</th>\n",
       "      <th>total_parentheses_count</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>5701</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>4700</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>5967</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>2282</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>18669</td>\n",
       "      <td>...</td>\n",
       "      <td>271</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f24219d6-07f0-4baf-80ac-18475dc5b66f</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.380952</td>\n",
       "      <td>202.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>0.377319</td>\n",
       "      <td>0.981626</td>\n",
       "      <td>4035</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>0.302987</td>\n",
       "      <td>0.418350</td>\n",
       "      <td>0.546734</td>\n",
       "      <td>0.490407</td>\n",
       "      <td>0.466607</td>\n",
       "      <td>0.502019</td>\n",
       "      <td>0.941213</td>\n",
       "      <td>0.928735</td>\n",
       "      <td>0.771037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2f18684-4a16-4c05-a2d1-c0f96d1de869</th>\n",
       "      <td>71.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.211268</td>\n",
       "      <td>200.408451</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.884943</td>\n",
       "      <td>0.482037</td>\n",
       "      <td>0.992739</td>\n",
       "      <td>23006</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>0.311383</td>\n",
       "      <td>0.368891</td>\n",
       "      <td>0.549631</td>\n",
       "      <td>0.966176</td>\n",
       "      <td>0.655741</td>\n",
       "      <td>0.945437</td>\n",
       "      <td>0.608420</td>\n",
       "      <td>0.934719</td>\n",
       "      <td>0.769781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f852596d-fdca-45aa-9050-d4f76ce6a53c</th>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.766667</td>\n",
       "      <td>116.266667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.919986</td>\n",
       "      <td>0.492801</td>\n",
       "      <td>0.929497</td>\n",
       "      <td>21776</td>\n",
       "      <td>...</td>\n",
       "      <td>307</td>\n",
       "      <td>0.435314</td>\n",
       "      <td>0.975701</td>\n",
       "      <td>0.889675</td>\n",
       "      <td>0.977834</td>\n",
       "      <td>0.903663</td>\n",
       "      <td>0.947942</td>\n",
       "      <td>0.807891</td>\n",
       "      <td>0.956091</td>\n",
       "      <td>0.427795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f8ec3336-fd48-4654-ad98-62ccfb96d096</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>272.142857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.398174</td>\n",
       "      <td>0.982006</td>\n",
       "      <td>7143</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>0.431564</td>\n",
       "      <td>0.993305</td>\n",
       "      <td>0.853336</td>\n",
       "      <td>0.678769</td>\n",
       "      <td>0.851377</td>\n",
       "      <td>0.906791</td>\n",
       "      <td>0.930365</td>\n",
       "      <td>0.918092</td>\n",
       "      <td>0.630520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8de815-224c-4d06-9fd4-7156d1a9920d</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>11417</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  total_discomfort_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883           14.0                     8.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b           18.0                     0.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b            9.0                     8.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc           20.0                     3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0                    16.0   \n",
       "...                                             ...                     ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f           21.0                     1.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869           71.0                     3.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c           30.0                     6.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096           14.0                     0.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d           31.0                    16.0   \n",
       "\n",
       "                                      total_comfort_count  prompt_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  0.0         63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  0.0         39.666667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  1.0         99.111111   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  0.0         17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                  1.0         30.697674   \n",
       "...                                                   ...               ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                  0.0         31.380952   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                  2.0         48.211268   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                  1.0         93.766667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                  1.0         77.000000   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                  2.0         50.806452   \n",
       "\n",
       "                                      response_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883          160.642857  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b          169.166667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b          160.444444   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc          148.500000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34          123.000000   \n",
       "...                                                  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f          202.666667   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869          200.408451   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c          116.266667   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096          272.142857   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d          114.548387   \n",
       "\n",
       "                                      response_confusion_total_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                             2.0  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                             1.0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            12.0   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                             3.0   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            19.0   \n",
       "...                                                              ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                             5.0   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            17.0   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                             4.0   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                             1.0   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                             3.0   \n",
       "\n",
       "                                      similarity_between_prompts   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0.959773  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0.913921   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0.802151   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0.904731   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    0.889234   \n",
       "...                                                          ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                    0.883792   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                    0.884943   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                    0.919986   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                    0.903643   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    0.902465   \n",
       "\n",
       "                                      avg_sim_between_prompt_codeComment   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                            0.558252  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                            0.556858   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            0.331554   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                            0.419597   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            0.470122   \n",
       "...                                                                  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                            0.377319   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                            0.482037   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                            0.492801   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                            0.398174   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                            0.427945   \n",
       "\n",
       "                                      similarity_between_fullpoints   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       0.984955  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       0.988546   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                       0.950704   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       0.980123   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                       0.928597   \n",
       "...                                                             ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                       0.981626   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                       0.992739   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                       0.929497   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                       0.982006   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                       0.988390   \n",
       "\n",
       "                                      total_message_length  ...   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  5701  ...  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  4700  ...   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  5967  ...   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  2282  ...   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                 18669  ...   \n",
       "...                                                    ...  ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                  4035  ...   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                 23006  ...   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                 21776  ...   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                  7143  ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                 11417  ...   \n",
       "\n",
       "                                      total_parentheses_count        Q0   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       14  0.242323  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       65  0.412892   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                      100  0.173714   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       12  0.285609   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                      271  0.444721   \n",
       "...                                                       ...       ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f                       69  0.302987   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869                      192  0.311383   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c                      307  0.435314   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096                       78  0.431564   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                      199  0.449902   \n",
       "\n",
       "                                            Q1        Q2        Q3        Q4   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.650830  0.639897  0.790342  0.690072  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.822821  0.696175  0.909993  0.766648   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.217742  0.274107  0.284707  0.487476   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.548311  0.439191  0.645035  0.770841   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.758592  0.872447  0.712806  0.821277   \n",
       "...                                        ...       ...       ...       ...   \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f  0.418350  0.546734  0.490407  0.466607   \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.368891  0.549631  0.966176  0.655741   \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c  0.975701  0.889675  0.977834  0.903663   \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096  0.993305  0.853336  0.678769  0.851377   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.904886  0.830096  0.879708  0.849048   \n",
       "\n",
       "                                            Q5        Q6        Q7        Q8  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.788218  0.428342  0.461473  0.285456  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.987573  0.684214  0.729532  0.491343  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.249203  0.297617  0.538953  0.142434  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.659323  0.553139  0.538424  0.426416  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.916046  0.555504  0.945931  0.590542  \n",
       "...                                        ...       ...       ...       ...  \n",
       "f24219d6-07f0-4baf-80ac-18475dc5b66f  0.502019  0.941213  0.928735  0.771037  \n",
       "f2f18684-4a16-4c05-a2d1-c0f96d1de869  0.945437  0.608420  0.934719  0.769781  \n",
       "f852596d-fdca-45aa-9050-d4f76ce6a53c  0.947942  0.807891  0.956091  0.427795  \n",
       "f8ec3336-fd48-4654-ad98-62ccfb96d096  0.906791  0.930365  0.918092  0.630520  \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.970448  0.930143  0.919492  0.619326  \n",
       "\n",
       "[123 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDING BROKEN FILE'S INDEXES, WE USE THE AVERAGE VALUE IN THE DATAFRAME IN ORDER TO PERFORM DATA IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New indexes\n",
    "new_indexes = ['139235c7-736c-4237-92f0-92e8c116832c',\n",
    "               '668ad17e-0240-49f7-b5a7-d22e502554c6',\n",
    "               'b0640e51-6879-40cb-a4f5-329f952ef99d',\n",
    "               'da6b70d5-29f6-491a-ad46-037c77067128']\n",
    "\n",
    "# Create a new DataFrame with the new indexes\n",
    "new_rows_df = pd.DataFrame(index=new_indexes, columns=df.columns)\n",
    "\n",
    "# Calculate averages for each column and set them for the new indexes\n",
    "for column in df.columns:\n",
    "    avg_value = df[column].mean()\n",
    "    new_rows_df[column] = avg_value\n",
    "\n",
    "# Concatenate the original DataFrame with the new rows DataFrame\n",
    "df = pd.concat([df, new_rows_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['#user_prompts'] = df['#user_prompts'].astype(int)\n",
    "df['total_discomfort_count'] = df['total_discomfort_count'].astype(int)\n",
    "df['total_comfort_count'] = df['total_comfort_count'].astype(int)\n",
    "df['response_confusion_total_count'] = df['response_confusion_total_count'].astype(int)\n",
    "df['total_message_length'] = df['total_message_length'].astype(int)\n",
    "df['total_parentheses_count'] = df['total_parentheses_count'].astype(int)\n",
    "df['english_conjunctions_count'] = df['english_conjunctions_count'].astype(int)\n",
    "df['example_words_count'] = df['example_words_count'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE DATAFRAME TO ADD THE SCORE INFO LATER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>total_message_length</th>\n",
       "      <th>...</th>\n",
       "      <th>total_parentheses_count</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0031c86e-81f4-4eef-9e0e-28037abf9883</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>5701</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0225686d-b825-4cac-8691-3a3a5343df2b</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>4700</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>041f950b-c013-409a-a642-cffff60b9d4b</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>5967</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04f91058-d0f8-4324-83b2-19c671f433dc</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>2282</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>089eb66d-4c3a-4f58-b98f-a3774a2efb34</th>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>18669</td>\n",
       "      <td>...</td>\n",
       "      <td>271</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fb8de815-224c-4d06-9fd4-7156d1a9920d</th>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>11417</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139235c7-736c-4237-92f0-92e8c116832c</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>10170</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668ad17e-0240-49f7-b5a7-d22e502554c6</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>10170</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b0640e51-6879-40cb-a4f5-329f952ef99d</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>10170</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da6b70d5-29f6-491a-ad46-037c77067128</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>10170</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      #user_prompts  total_discomfort_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883             14                       8  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b             18                       0   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b              9                       8   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc             20                       3   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34             86                      16   \n",
       "...                                             ...                     ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d             31                      16   \n",
       "139235c7-736c-4237-92f0-92e8c116832c             28                       4   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6             28                       4   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d             28                       4   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128             28                       4   \n",
       "\n",
       "                                      total_comfort_count  prompt_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0         63.071429  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0         39.666667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    1         99.111111   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0         17.750000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    1         30.697674   \n",
       "...                                                   ...               ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    2         50.806452   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                    0         48.153147   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                    0         48.153147   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                    0         48.153147   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                    0         48.153147   \n",
       "\n",
       "                                      response_avg_words   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883          160.642857  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b          169.166667   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b          160.444444   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc          148.500000   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34          123.000000   \n",
       "...                                                  ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d          114.548387   \n",
       "139235c7-736c-4237-92f0-92e8c116832c          150.265901   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6          150.265901   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d          150.265901   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128          150.265901   \n",
       "\n",
       "                                      response_confusion_total_count   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                               2  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                               1   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                              12   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                               3   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                              19   \n",
       "...                                                              ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                               3   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                               6   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                               6   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                               6   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                               6   \n",
       "\n",
       "                                      similarity_between_prompts   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                    0.959773  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                    0.913921   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                    0.802151   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                    0.904731   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                    0.889234   \n",
       "...                                                          ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                    0.902465   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                    0.862682   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                    0.862682   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                    0.862682   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                    0.862682   \n",
       "\n",
       "                                      avg_sim_between_prompt_codeComment   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                            0.558252  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                            0.556858   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                            0.331554   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                            0.419597   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                            0.470122   \n",
       "...                                                                  ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                            0.427945   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                            0.449188   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                            0.449188   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                            0.449188   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                            0.449188   \n",
       "\n",
       "                                      similarity_between_fullpoints   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       0.984955  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       0.988546   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                       0.950704   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       0.980123   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                       0.928597   \n",
       "...                                                             ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                       0.988390   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                       0.969126   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                       0.969126   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                       0.969126   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                       0.969126   \n",
       "\n",
       "                                      total_message_length  ...   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                  5701  ...  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                  4700  ...   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                  5967  ...   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                  2282  ...   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                 18669  ...   \n",
       "...                                                    ...  ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                 11417  ...   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                 10170  ...   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                 10170  ...   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                 10170  ...   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                 10170  ...   \n",
       "\n",
       "                                      total_parentheses_count        Q0   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883                       14  0.242323  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b                       65  0.412892   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b                      100  0.173714   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc                       12  0.285609   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34                      271  0.444721   \n",
       "...                                                       ...       ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d                      199  0.449902   \n",
       "139235c7-736c-4237-92f0-92e8c116832c                      130  0.338774   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6                      130  0.338774   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d                      130  0.338774   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128                      130  0.338774   \n",
       "\n",
       "                                            Q1        Q2        Q3        Q4   \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.650830  0.639897  0.790342  0.690072  \\\n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.822821  0.696175  0.909993  0.766648   \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.217742  0.274107  0.284707  0.487476   \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.548311  0.439191  0.645035  0.770841   \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.758592  0.872447  0.712806  0.821277   \n",
       "...                                        ...       ...       ...       ...   \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.904886  0.830096  0.879708  0.849048   \n",
       "139235c7-736c-4237-92f0-92e8c116832c  0.568363  0.637507  0.717978  0.749788   \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6  0.568363  0.637507  0.717978  0.749788   \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d  0.568363  0.637507  0.717978  0.749788   \n",
       "da6b70d5-29f6-491a-ad46-037c77067128  0.568363  0.637507  0.717978  0.749788   \n",
       "\n",
       "                                            Q5        Q6        Q7        Q8  \n",
       "0031c86e-81f4-4eef-9e0e-28037abf9883  0.788218  0.428342  0.461473  0.285456  \n",
       "0225686d-b825-4cac-8691-3a3a5343df2b  0.987573  0.684214  0.729532  0.491343  \n",
       "041f950b-c013-409a-a642-cffff60b9d4b  0.249203  0.297617  0.538953  0.142434  \n",
       "04f91058-d0f8-4324-83b2-19c671f433dc  0.659323  0.553139  0.538424  0.426416  \n",
       "089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.916046  0.555504  0.945931  0.590542  \n",
       "...                                        ...       ...       ...       ...  \n",
       "fb8de815-224c-4d06-9fd4-7156d1a9920d  0.970448  0.930143  0.919492  0.619326  \n",
       "139235c7-736c-4237-92f0-92e8c116832c  0.760652  0.672611  0.723560  0.533915  \n",
       "668ad17e-0240-49f7-b5a7-d22e502554c6  0.760652  0.672611  0.723560  0.533915  \n",
       "b0640e51-6879-40cb-a4f5-329f952ef99d  0.760652  0.672611  0.723560  0.533915  \n",
       "da6b70d5-29f6-491a-ad46-037c77067128  0.760652  0.672611  0.723560  0.533915  \n",
       "\n",
       "[127 rows x 24 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADE DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check grades distribution\n",
    "\n",
    "plt.title('Histogram Grades')\n",
    "plt.hist(scores[\"grade\"], rwidth=.8, bins=np.arange(min(scores[\"grade\"]), max(scores[\"grade\"])+2) - 0.5)\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNSETTING THE INDEXES AS HTML FILE NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>...</th>\n",
       "      <th>total_parentheses_count</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>...</td>\n",
       "      <td>271</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>139235c7-736c-4237-92f0-92e8c116832c</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>668ad17e-0240-49f7-b5a7-d22e502554c6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>b0640e51-6879-40cb-a4f5-329f952ef99d</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>da6b70d5-29f6-491a-ad46-037c77067128</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts   \n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883             14  \\\n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b             18   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b              9   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc             20   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34             86   \n",
       "..                                    ...            ...   \n",
       "122  fb8de815-224c-4d06-9fd4-7156d1a9920d             31   \n",
       "123  139235c7-736c-4237-92f0-92e8c116832c             28   \n",
       "124  668ad17e-0240-49f7-b5a7-d22e502554c6             28   \n",
       "125  b0640e51-6879-40cb-a4f5-329f952ef99d             28   \n",
       "126  da6b70d5-29f6-491a-ad46-037c77067128             28   \n",
       "\n",
       "     total_discomfort_count  total_comfort_count  prompt_avg_words   \n",
       "0                         8                    0         63.071429  \\\n",
       "1                         0                    0         39.666667   \n",
       "2                         8                    1         99.111111   \n",
       "3                         3                    0         17.750000   \n",
       "4                        16                    1         30.697674   \n",
       "..                      ...                  ...               ...   \n",
       "122                      16                    2         50.806452   \n",
       "123                       4                    0         48.153147   \n",
       "124                       4                    0         48.153147   \n",
       "125                       4                    0         48.153147   \n",
       "126                       4                    0         48.153147   \n",
       "\n",
       "     response_avg_words  response_confusion_total_count   \n",
       "0            160.642857                               2  \\\n",
       "1            169.166667                               1   \n",
       "2            160.444444                              12   \n",
       "3            148.500000                               3   \n",
       "4            123.000000                              19   \n",
       "..                  ...                             ...   \n",
       "122          114.548387                               3   \n",
       "123          150.265901                               6   \n",
       "124          150.265901                               6   \n",
       "125          150.265901                               6   \n",
       "126          150.265901                               6   \n",
       "\n",
       "     similarity_between_prompts  avg_sim_between_prompt_codeComment   \n",
       "0                      0.959773                            0.558252  \\\n",
       "1                      0.913921                            0.556858   \n",
       "2                      0.802151                            0.331554   \n",
       "3                      0.904731                            0.419597   \n",
       "4                      0.889234                            0.470122   \n",
       "..                          ...                                 ...   \n",
       "122                    0.902465                            0.427945   \n",
       "123                    0.862682                            0.449188   \n",
       "124                    0.862682                            0.449188   \n",
       "125                    0.862682                            0.449188   \n",
       "126                    0.862682                            0.449188   \n",
       "\n",
       "     similarity_between_fullpoints  ...  total_parentheses_count        Q0   \n",
       "0                         0.984955  ...                       14  0.242323  \\\n",
       "1                         0.988546  ...                       65  0.412892   \n",
       "2                         0.950704  ...                      100  0.173714   \n",
       "3                         0.980123  ...                       12  0.285609   \n",
       "4                         0.928597  ...                      271  0.444721   \n",
       "..                             ...  ...                      ...       ...   \n",
       "122                       0.988390  ...                      199  0.449902   \n",
       "123                       0.969126  ...                      130  0.338774   \n",
       "124                       0.969126  ...                      130  0.338774   \n",
       "125                       0.969126  ...                      130  0.338774   \n",
       "126                       0.969126  ...                      130  0.338774   \n",
       "\n",
       "           Q1        Q2        Q3        Q4        Q5        Q6        Q7   \n",
       "0    0.650830  0.639897  0.790342  0.690072  0.788218  0.428342  0.461473  \\\n",
       "1    0.822821  0.696175  0.909993  0.766648  0.987573  0.684214  0.729532   \n",
       "2    0.217742  0.274107  0.284707  0.487476  0.249203  0.297617  0.538953   \n",
       "3    0.548311  0.439191  0.645035  0.770841  0.659323  0.553139  0.538424   \n",
       "4    0.758592  0.872447  0.712806  0.821277  0.916046  0.555504  0.945931   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "122  0.904886  0.830096  0.879708  0.849048  0.970448  0.930143  0.919492   \n",
       "123  0.568363  0.637507  0.717978  0.749788  0.760652  0.672611  0.723560   \n",
       "124  0.568363  0.637507  0.717978  0.749788  0.760652  0.672611  0.723560   \n",
       "125  0.568363  0.637507  0.717978  0.749788  0.760652  0.672611  0.723560   \n",
       "126  0.568363  0.637507  0.717978  0.749788  0.760652  0.672611  0.723560   \n",
       "\n",
       "           Q8  \n",
       "0    0.285456  \n",
       "1    0.491343  \n",
       "2    0.142434  \n",
       "3    0.426416  \n",
       "4    0.590542  \n",
       "..        ...  \n",
       "122  0.619326  \n",
       "123  0.533915  \n",
       "124  0.533915  \n",
       "125  0.533915  \n",
       "126  0.533915  \n",
       "\n",
       "[127 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True, drop=False)\n",
    "df.rename(columns={\"index\": \"code\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging scores with features\n",
    "\n",
    "# IT IS THE FINAL DATAFRAME WE HAVE IN ORDER TO START ANALYZING OUR DATA, MODIFYING SOME COLUMNS, DEVELOPING OUR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df = pd.merge(df, scores, on='code', how=\"left\")\n",
    "# Merge with 'left' method\n",
    "final_df = pd.merge(df, scores.drop_duplicates(subset=['code']), on='code', how='left')\n",
    "\n",
    "# Drop duplicate columns (if any)\n",
    "final_df = final_df.loc[:,~final_df.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>...</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>139235c7-736c-4237-92f0-92e8c116832c</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>668ad17e-0240-49f7-b5a7-d22e502554c6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>b0640e51-6879-40cb-a4f5-329f952ef99d</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>da6b70d5-29f6-491a-ad46-037c77067128</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts   \n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883             14  \\\n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b             18   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b              9   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc             20   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34             86   \n",
       "..                                    ...            ...   \n",
       "122  fb8de815-224c-4d06-9fd4-7156d1a9920d             31   \n",
       "123  139235c7-736c-4237-92f0-92e8c116832c             28   \n",
       "124  668ad17e-0240-49f7-b5a7-d22e502554c6             28   \n",
       "125  b0640e51-6879-40cb-a4f5-329f952ef99d             28   \n",
       "126  da6b70d5-29f6-491a-ad46-037c77067128             28   \n",
       "\n",
       "     total_discomfort_count  total_comfort_count  prompt_avg_words   \n",
       "0                         8                    0         63.071429  \\\n",
       "1                         0                    0         39.666667   \n",
       "2                         8                    1         99.111111   \n",
       "3                         3                    0         17.750000   \n",
       "4                        16                    1         30.697674   \n",
       "..                      ...                  ...               ...   \n",
       "122                      16                    2         50.806452   \n",
       "123                       4                    0         48.153147   \n",
       "124                       4                    0         48.153147   \n",
       "125                       4                    0         48.153147   \n",
       "126                       4                    0         48.153147   \n",
       "\n",
       "     response_avg_words  response_confusion_total_count   \n",
       "0            160.642857                               2  \\\n",
       "1            169.166667                               1   \n",
       "2            160.444444                              12   \n",
       "3            148.500000                               3   \n",
       "4            123.000000                              19   \n",
       "..                  ...                             ...   \n",
       "122          114.548387                               3   \n",
       "123          150.265901                               6   \n",
       "124          150.265901                               6   \n",
       "125          150.265901                               6   \n",
       "126          150.265901                               6   \n",
       "\n",
       "     similarity_between_prompts  avg_sim_between_prompt_codeComment   \n",
       "0                      0.959773                            0.558252  \\\n",
       "1                      0.913921                            0.556858   \n",
       "2                      0.802151                            0.331554   \n",
       "3                      0.904731                            0.419597   \n",
       "4                      0.889234                            0.470122   \n",
       "..                          ...                                 ...   \n",
       "122                    0.902465                            0.427945   \n",
       "123                    0.862682                            0.449188   \n",
       "124                    0.862682                            0.449188   \n",
       "125                    0.862682                            0.449188   \n",
       "126                    0.862682                            0.449188   \n",
       "\n",
       "     similarity_between_fullpoints  ...        Q0        Q1        Q2   \n",
       "0                         0.984955  ...  0.242323  0.650830  0.639897  \\\n",
       "1                         0.988546  ...  0.412892  0.822821  0.696175   \n",
       "2                         0.950704  ...  0.173714  0.217742  0.274107   \n",
       "3                         0.980123  ...  0.285609  0.548311  0.439191   \n",
       "4                         0.928597  ...  0.444721  0.758592  0.872447   \n",
       "..                             ...  ...       ...       ...       ...   \n",
       "122                       0.988390  ...  0.449902  0.904886  0.830096   \n",
       "123                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "124                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "125                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "126                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "\n",
       "           Q3        Q4        Q5        Q6        Q7        Q8  grade  \n",
       "0    0.790342  0.690072  0.788218  0.428342  0.461473  0.285456   48.0  \n",
       "1    0.909993  0.766648  0.987573  0.684214  0.729532  0.491343   99.0  \n",
       "2    0.284707  0.487476  0.249203  0.297617  0.538953  0.142434   90.0  \n",
       "3    0.645035  0.770841  0.659323  0.553139  0.538424  0.426416   97.0  \n",
       "4    0.712806  0.821277  0.916046  0.555504  0.945931  0.590542  100.0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "122  0.879708  0.849048  0.970448  0.930143  0.919492  0.619326   98.0  \n",
       "123  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   86.0  \n",
       "124  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   99.0  \n",
       "125  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   98.0  \n",
       "126  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   95.0  \n",
       "\n",
       "[127 rows x 26 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One data point is not having grade, so it is being dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in each column:\n",
      "code                                  0\n",
      "#user_prompts                         0\n",
      "total_discomfort_count                0\n",
      "total_comfort_count                   0\n",
      "prompt_avg_words                      0\n",
      "response_avg_words                    0\n",
      "response_confusion_total_count        0\n",
      "similarity_between_prompts            0\n",
      "avg_sim_between_prompt_codeComment    0\n",
      "similarity_between_fullpoints         0\n",
      "total_message_length                  0\n",
      "average_word_count_per_sentence       0\n",
      "average_word_length                   0\n",
      "english_conjunctions_count            0\n",
      "example_words_count                   0\n",
      "total_parentheses_count               0\n",
      "Q0                                    0\n",
      "Q1                                    0\n",
      "Q2                                    0\n",
      "Q3                                    0\n",
      "Q4                                    0\n",
      "Q5                                    0\n",
      "Q6                                    0\n",
      "Q7                                    0\n",
      "Q8                                    0\n",
      "grade                                 1\n",
      "dtype: int64\n",
      "NaN values in each column AFTER DROP:\n",
      "code                                  0\n",
      "#user_prompts                         0\n",
      "total_discomfort_count                0\n",
      "total_comfort_count                   0\n",
      "prompt_avg_words                      0\n",
      "response_avg_words                    0\n",
      "response_confusion_total_count        0\n",
      "similarity_between_prompts            0\n",
      "avg_sim_between_prompt_codeComment    0\n",
      "similarity_between_fullpoints         0\n",
      "total_message_length                  0\n",
      "average_word_count_per_sentence       0\n",
      "average_word_length                   0\n",
      "english_conjunctions_count            0\n",
      "example_words_count                   0\n",
      "total_parentheses_count               0\n",
      "Q0                                    0\n",
      "Q1                                    0\n",
      "Q2                                    0\n",
      "Q3                                    0\n",
      "Q4                                    0\n",
      "Q5                                    0\n",
      "Q6                                    0\n",
      "Q7                                    0\n",
      "Q8                                    0\n",
      "grade                                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_values = final_df.isna().sum()\n",
    "\n",
    "# Display the count of NaN values for each column\n",
    "print(\"NaN values in each column:\")\n",
    "print(nan_values)\n",
    "final_df = final_df.dropna(subset=['grade'])\n",
    "\n",
    "nan_values = final_df.isna().sum()\n",
    "\n",
    "# Display the count of NaN values for each column\n",
    "print(\"NaN values in each column AFTER DROP:\")\n",
    "print(nan_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>...</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>0.639897</td>\n",
       "      <td>0.790342</td>\n",
       "      <td>0.690072</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412892</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>0.696175</td>\n",
       "      <td>0.909993</td>\n",
       "      <td>0.766648</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173714</td>\n",
       "      <td>0.217742</td>\n",
       "      <td>0.274107</td>\n",
       "      <td>0.284707</td>\n",
       "      <td>0.487476</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285609</td>\n",
       "      <td>0.548311</td>\n",
       "      <td>0.439191</td>\n",
       "      <td>0.645035</td>\n",
       "      <td>0.770841</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444721</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.872447</td>\n",
       "      <td>0.712806</td>\n",
       "      <td>0.821277</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449902</td>\n",
       "      <td>0.904886</td>\n",
       "      <td>0.830096</td>\n",
       "      <td>0.879708</td>\n",
       "      <td>0.849048</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>139235c7-736c-4237-92f0-92e8c116832c</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>668ad17e-0240-49f7-b5a7-d22e502554c6</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>b0640e51-6879-40cb-a4f5-329f952ef99d</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>da6b70d5-29f6-491a-ad46-037c77067128</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>48.153147</td>\n",
       "      <td>150.265901</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862682</td>\n",
       "      <td>0.449188</td>\n",
       "      <td>0.969126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338774</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>0.637507</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.749788</td>\n",
       "      <td>0.760652</td>\n",
       "      <td>0.672611</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.533915</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts   \n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883             14  \\\n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b             18   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b              9   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc             20   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34             86   \n",
       "..                                    ...            ...   \n",
       "122  fb8de815-224c-4d06-9fd4-7156d1a9920d             31   \n",
       "123  139235c7-736c-4237-92f0-92e8c116832c             28   \n",
       "124  668ad17e-0240-49f7-b5a7-d22e502554c6             28   \n",
       "125  b0640e51-6879-40cb-a4f5-329f952ef99d             28   \n",
       "126  da6b70d5-29f6-491a-ad46-037c77067128             28   \n",
       "\n",
       "     total_discomfort_count  total_comfort_count  prompt_avg_words   \n",
       "0                         8                    0         63.071429  \\\n",
       "1                         0                    0         39.666667   \n",
       "2                         8                    1         99.111111   \n",
       "3                         3                    0         17.750000   \n",
       "4                        16                    1         30.697674   \n",
       "..                      ...                  ...               ...   \n",
       "122                      16                    2         50.806452   \n",
       "123                       4                    0         48.153147   \n",
       "124                       4                    0         48.153147   \n",
       "125                       4                    0         48.153147   \n",
       "126                       4                    0         48.153147   \n",
       "\n",
       "     response_avg_words  response_confusion_total_count   \n",
       "0            160.642857                               2  \\\n",
       "1            169.166667                               1   \n",
       "2            160.444444                              12   \n",
       "3            148.500000                               3   \n",
       "4            123.000000                              19   \n",
       "..                  ...                             ...   \n",
       "122          114.548387                               3   \n",
       "123          150.265901                               6   \n",
       "124          150.265901                               6   \n",
       "125          150.265901                               6   \n",
       "126          150.265901                               6   \n",
       "\n",
       "     similarity_between_prompts  avg_sim_between_prompt_codeComment   \n",
       "0                      0.959773                            0.558252  \\\n",
       "1                      0.913921                            0.556858   \n",
       "2                      0.802151                            0.331554   \n",
       "3                      0.904731                            0.419597   \n",
       "4                      0.889234                            0.470122   \n",
       "..                          ...                                 ...   \n",
       "122                    0.902465                            0.427945   \n",
       "123                    0.862682                            0.449188   \n",
       "124                    0.862682                            0.449188   \n",
       "125                    0.862682                            0.449188   \n",
       "126                    0.862682                            0.449188   \n",
       "\n",
       "     similarity_between_fullpoints  ...        Q0        Q1        Q2   \n",
       "0                         0.984955  ...  0.242323  0.650830  0.639897  \\\n",
       "1                         0.988546  ...  0.412892  0.822821  0.696175   \n",
       "2                         0.950704  ...  0.173714  0.217742  0.274107   \n",
       "3                         0.980123  ...  0.285609  0.548311  0.439191   \n",
       "4                         0.928597  ...  0.444721  0.758592  0.872447   \n",
       "..                             ...  ...       ...       ...       ...   \n",
       "122                       0.988390  ...  0.449902  0.904886  0.830096   \n",
       "123                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "124                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "125                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "126                       0.969126  ...  0.338774  0.568363  0.637507   \n",
       "\n",
       "           Q3        Q4        Q5        Q6        Q7        Q8  grade  \n",
       "0    0.790342  0.690072  0.788218  0.428342  0.461473  0.285456   48.0  \n",
       "1    0.909993  0.766648  0.987573  0.684214  0.729532  0.491343   99.0  \n",
       "2    0.284707  0.487476  0.249203  0.297617  0.538953  0.142434   90.0  \n",
       "3    0.645035  0.770841  0.659323  0.553139  0.538424  0.426416   97.0  \n",
       "4    0.712806  0.821277  0.916046  0.555504  0.945931  0.590542  100.0  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "122  0.879708  0.849048  0.970448  0.930143  0.919492  0.619326   98.0  \n",
       "123  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   86.0  \n",
       "124  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   99.0  \n",
       "125  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   98.0  \n",
       "126  0.717978  0.749788  0.760652  0.672611  0.723560  0.533915   95.0  \n",
       "\n",
       "[126 rows x 26 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAST CHAPTER- DO YOUR MODIFICATIONS ON THE DATASET, AND START DEVELOPING YOUR MODEL\n",
    "\n",
    "# YOUR DATAFRAME VARIABLE NAME IS -> final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanFıratYılmaz\\AppData\\Local\\Temp\\ipykernel_23460\\166021265.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"avg_discomfort_count_per_prompt\"]=final_df[\"total_discomfort_count\"]/final_df[\"#user_prompts\"]\n",
      "C:\\Users\\HasanFıratYılmaz\\AppData\\Local\\Temp\\ipykernel_23460\\166021265.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"avg_comfort_count_per_prompt\"]=final_df[\"total_comfort_count\"]/final_df[\"#user_prompts\"]\n",
      "C:\\Users\\HasanFıratYılmaz\\AppData\\Local\\Temp\\ipykernel_23460\\166021265.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"avg_example_words_count_per_prompt\"]=final_df[\"example_words_count\"]/final_df[\"#user_prompts\"]\n",
      "C:\\Users\\HasanFıratYılmaz\\AppData\\Local\\Temp\\ipykernel_23460\\166021265.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"avg_parentheses_count_per_prompt\"]=final_df[\"total_parentheses_count\"]/final_df[\"#user_prompts\"]\n",
      "C:\\Users\\HasanFıratYılmaz\\AppData\\Local\\Temp\\ipykernel_23460\\166021265.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"avg_english_conjunctions_count_per_prompts\"]=final_df[\"english_conjunctions_count\"]/final_df[\"#user_prompts\"]\n"
     ]
    }
   ],
   "source": [
    "final_df[\"avg_discomfort_count_per_prompt\"]=final_df[\"total_discomfort_count\"]/final_df[\"#user_prompts\"]\n",
    "final_df[\"avg_comfort_count_per_prompt\"]=final_df[\"total_comfort_count\"]/final_df[\"#user_prompts\"]\n",
    "final_df[\"avg_example_words_count_per_prompt\"]=final_df[\"example_words_count\"]/final_df[\"#user_prompts\"]\n",
    "final_df[\"avg_parentheses_count_per_prompt\"]=final_df[\"total_parentheses_count\"]/final_df[\"#user_prompts\"]\n",
    "final_df[\"avg_english_conjunctions_count_per_prompts\"]=final_df[\"english_conjunctions_count\"]/final_df[\"#user_prompts\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EKLENMEK ISTIYORSA BU NOKTADA FINAL_DF UZERINDE CALISILMALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 86 puan için 88 ve 84 aralığı\n",
    "# 99 puan için 98 ve 100 aralığı\n",
    "# 98 puan için 97 ve 99 aralığı\n",
    "# 95 puan için 94 ve 96 aralığı\n",
    "\n",
    "recive_86 = filtered_codes = final_df.loc[(final_df['grade'] >= 84) & (final_df['grade'] <= 88), 'code'].tolist()\n",
    "recive_99 = filtered_codes = final_df.loc[(final_df['grade'] >= 98) & (final_df['grade'] <= 100), 'code'].tolist()\n",
    "recive_98 = filtered_codes = final_df.loc[(final_df['grade'] >= 97) & (final_df['grade'] <= 99), 'code'].tolist()\n",
    "recive_95 = filtered_codes = final_df.loc[(final_df['grade'] >= 94) & (final_df['grade'] <= 95), 'code'].tolist()\n",
    "\n",
    "averages_dict86 = {}\n",
    "\n",
    "# Her bir kolon için ortalama değeri hesapla ve dictionary'e ekle\n",
    "for column in final_df.columns[1:]:  # İlk sütun user_id, onu hariç tutuyoruz\n",
    "    averages_dict86[column] = final_df[final_df['code'].isin(recive_86)][column].mean()\n",
    "\n",
    "averages_dict99 = {}\n",
    "\n",
    "# Her bir kolon için ortalama değeri hesapla ve dictionary'e ekle\n",
    "for column in final_df.columns[1:]:  # İlk sütun user_id, onu hariç tutuyoruz\n",
    "    averages_dict99[column] = final_df[final_df['code'].isin(recive_99)][column].mean()\n",
    "\n",
    "\n",
    "averages_dict98 = {}\n",
    "\n",
    "# Her bir kolon için ortalama değeri hesapla ve dictionary'e ekle\n",
    "for column in final_df.columns[1:]:  # İlk sütun user_id, onu hariç tutuyoruz\n",
    "    averages_dict98[column] = final_df[final_df['code'].isin(recive_98)][column].mean()\n",
    "\n",
    "averages_dict95 = {}\n",
    "\n",
    "# Her bir kolon için ortalama değeri hesapla ve dictionary'e ekle\n",
    "for column in final_df.columns[1:]:  # İlk sütun user_id, onu hariç tutuyoruz\n",
    "    averages_dict95[column] = final_df[final_df['code'].isin(recive_95)][column].mean()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_df = final_df.drop(final_df[final_df['code'] == '139235c7-736c-4237-92f0-92e8c116832c'].index) ##gets 86\n",
    "final_df = final_df.drop(final_df[final_df['code'] == '668ad17e-0240-49f7-b5a7-d22e502554c6'].index)##99\n",
    "final_df = final_df.drop(final_df[final_df['code'] == 'b0640e51-6879-40cb-a4f5-329f952ef99d'].index)##98\n",
    "final_df = final_df.drop(final_df[final_df['code'] == 'da6b70d5-29f6-491a-ad46-037c77067128'].index)##95\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictforfirst=averages_dict86.copy()\n",
    "dictforfirst[\"code\"]='139235c7-736c-4237-92f0-92e8c116832c'\n",
    "dictforsecond=averages_dict99.copy()\n",
    "dictforsecond[\"code\"]='668ad17e-0240-49f7-b5a7-d22e502554c6'\n",
    "dictforthird=averages_dict98.copy()\n",
    "dictforthird[\"code\"]=\"b0640e51-6879-40cb-a4f5-329f952ef99d\"\n",
    "dictforfourth=averages_dict95.copy()\n",
    "dictforfourth[\"code\"]=\"da6b70d5-29f6-491a-ad46-037c77067128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffirst = pd.DataFrame([dictforfirst])\n",
    "final_df = pd.concat([final_df, dffirst], ignore_index=True)\n",
    "\n",
    "dfsecond = pd.DataFrame([dictforsecond])\n",
    "final_df = pd.concat([final_df, dfsecond], ignore_index=True)\n",
    "\n",
    "dfthird = pd.DataFrame([dictforthird])\n",
    "final_df = pd.concat([final_df, dfthird], ignore_index=True)\n",
    "\n",
    "dffourth = pd.DataFrame([dictforfourth])\n",
    "final_df = pd.concat([final_df, dffourth], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>grade</th>\n",
       "      <th>avg_discomfort_count_per_prompt</th>\n",
       "      <th>avg_comfort_count_per_prompt</th>\n",
       "      <th>avg_example_words_count_per_prompt</th>\n",
       "      <th>avg_parentheses_count_per_prompt</th>\n",
       "      <th>avg_english_conjunctions_count_per_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>3.151163</td>\n",
       "      <td>0.686047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>fb8de815-224c-4d06-9fd4-7156d1a9920d</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>114.548387</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.902465</td>\n",
       "      <td>0.427945</td>\n",
       "      <td>0.988390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970448</td>\n",
       "      <td>0.930143</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.619326</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.419355</td>\n",
       "      <td>0.419355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>139235c7-736c-4237-92f0-92e8c116832c</td>\n",
       "      <td>33.294118</td>\n",
       "      <td>7.058824</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>50.394260</td>\n",
       "      <td>158.223472</td>\n",
       "      <td>7.705882</td>\n",
       "      <td>0.881627</td>\n",
       "      <td>0.482080</td>\n",
       "      <td>0.955429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761836</td>\n",
       "      <td>0.693153</td>\n",
       "      <td>0.763857</td>\n",
       "      <td>0.582420</td>\n",
       "      <td>85.529412</td>\n",
       "      <td>0.150003</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>4.471710</td>\n",
       "      <td>0.633518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>668ad17e-0240-49f7-b5a7-d22e502554c6</td>\n",
       "      <td>30.979167</td>\n",
       "      <td>4.708333</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>49.709487</td>\n",
       "      <td>144.946072</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>0.847030</td>\n",
       "      <td>0.452481</td>\n",
       "      <td>0.970987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782802</td>\n",
       "      <td>0.687767</td>\n",
       "      <td>0.729910</td>\n",
       "      <td>0.548092</td>\n",
       "      <td>99.229167</td>\n",
       "      <td>0.123922</td>\n",
       "      <td>0.032976</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>4.339349</td>\n",
       "      <td>0.683265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>b0640e51-6879-40cb-a4f5-329f952ef99d</td>\n",
       "      <td>26.636364</td>\n",
       "      <td>4.121212</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>51.102801</td>\n",
       "      <td>145.491561</td>\n",
       "      <td>3.787879</td>\n",
       "      <td>0.845609</td>\n",
       "      <td>0.442290</td>\n",
       "      <td>0.973879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773120</td>\n",
       "      <td>0.682941</td>\n",
       "      <td>0.712591</td>\n",
       "      <td>0.508677</td>\n",
       "      <td>98.242424</td>\n",
       "      <td>0.135210</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>4.602278</td>\n",
       "      <td>0.669044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>da6b70d5-29f6-491a-ad46-037c77067128</td>\n",
       "      <td>35.058824</td>\n",
       "      <td>6.235294</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>50.821913</td>\n",
       "      <td>138.043759</td>\n",
       "      <td>9.823529</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>0.418673</td>\n",
       "      <td>0.972504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852404</td>\n",
       "      <td>0.742359</td>\n",
       "      <td>0.812240</td>\n",
       "      <td>0.576388</td>\n",
       "      <td>94.529412</td>\n",
       "      <td>0.160903</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>4.939592</td>\n",
       "      <td>0.636159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     code  #user_prompts   \n",
       "0    0031c86e-81f4-4eef-9e0e-28037abf9883      14.000000  \\\n",
       "1    0225686d-b825-4cac-8691-3a3a5343df2b      18.000000   \n",
       "2    041f950b-c013-409a-a642-cffff60b9d4b       9.000000   \n",
       "3    04f91058-d0f8-4324-83b2-19c671f433dc      20.000000   \n",
       "4    089eb66d-4c3a-4f58-b98f-a3774a2efb34      86.000000   \n",
       "..                                    ...            ...   \n",
       "121  fb8de815-224c-4d06-9fd4-7156d1a9920d      31.000000   \n",
       "122  139235c7-736c-4237-92f0-92e8c116832c      33.294118   \n",
       "123  668ad17e-0240-49f7-b5a7-d22e502554c6      30.979167   \n",
       "124  b0640e51-6879-40cb-a4f5-329f952ef99d      26.636364   \n",
       "125  da6b70d5-29f6-491a-ad46-037c77067128      35.058824   \n",
       "\n",
       "     total_discomfort_count  total_comfort_count  prompt_avg_words   \n",
       "0                  8.000000             0.000000         63.071429  \\\n",
       "1                  0.000000             0.000000         39.666667   \n",
       "2                  8.000000             1.000000         99.111111   \n",
       "3                  3.000000             0.000000         17.750000   \n",
       "4                 16.000000             1.000000         30.697674   \n",
       "..                      ...                  ...               ...   \n",
       "121               16.000000             2.000000         50.806452   \n",
       "122                7.058824             0.529412         50.394260   \n",
       "123                4.708333             0.979167         49.709487   \n",
       "124                4.121212             0.393939         51.102801   \n",
       "125                6.235294             0.823529         50.821913   \n",
       "\n",
       "     response_avg_words  response_confusion_total_count   \n",
       "0            160.642857                        2.000000  \\\n",
       "1            169.166667                        1.000000   \n",
       "2            160.444444                       12.000000   \n",
       "3            148.500000                        3.000000   \n",
       "4            123.000000                       19.000000   \n",
       "..                  ...                             ...   \n",
       "121          114.548387                        3.000000   \n",
       "122          158.223472                        7.705882   \n",
       "123          144.946072                        5.375000   \n",
       "124          145.491561                        3.787879   \n",
       "125          138.043759                        9.823529   \n",
       "\n",
       "     similarity_between_prompts  avg_sim_between_prompt_codeComment   \n",
       "0                      0.959773                            0.558252  \\\n",
       "1                      0.913921                            0.556858   \n",
       "2                      0.802151                            0.331554   \n",
       "3                      0.904731                            0.419597   \n",
       "4                      0.889234                            0.470122   \n",
       "..                          ...                                 ...   \n",
       "121                    0.902465                            0.427945   \n",
       "122                    0.881627                            0.482080   \n",
       "123                    0.847030                            0.452481   \n",
       "124                    0.845609                            0.442290   \n",
       "125                    0.873391                            0.418673   \n",
       "\n",
       "     similarity_between_fullpoints  ...        Q5        Q6        Q7   \n",
       "0                         0.984955  ...  0.788218  0.428342  0.461473  \\\n",
       "1                         0.988546  ...  0.987573  0.684214  0.729532   \n",
       "2                         0.950704  ...  0.249203  0.297617  0.538953   \n",
       "3                         0.980123  ...  0.659323  0.553139  0.538424   \n",
       "4                         0.928597  ...  0.916046  0.555504  0.945931   \n",
       "..                             ...  ...       ...       ...       ...   \n",
       "121                       0.988390  ...  0.970448  0.930143  0.919492   \n",
       "122                       0.955429  ...  0.761836  0.693153  0.763857   \n",
       "123                       0.970987  ...  0.782802  0.687767  0.729910   \n",
       "124                       0.973879  ...  0.773120  0.682941  0.712591   \n",
       "125                       0.972504  ...  0.852404  0.742359  0.812240   \n",
       "\n",
       "           Q8       grade  avg_discomfort_count_per_prompt   \n",
       "0    0.285456   48.000000                         0.571429  \\\n",
       "1    0.491343   99.000000                         0.000000   \n",
       "2    0.142434   90.000000                         0.888889   \n",
       "3    0.426416   97.000000                         0.150000   \n",
       "4    0.590542  100.000000                         0.186047   \n",
       "..        ...         ...                              ...   \n",
       "121  0.619326   98.000000                         0.516129   \n",
       "122  0.582420   85.529412                         0.150003   \n",
       "123  0.548092   99.229167                         0.123922   \n",
       "124  0.508677   98.242424                         0.135210   \n",
       "125  0.576388   94.529412                         0.160903   \n",
       "\n",
       "     avg_comfort_count_per_prompt  avg_example_words_count_per_prompt   \n",
       "0                        0.000000                            0.142857  \\\n",
       "1                        0.000000                            0.000000   \n",
       "2                        0.111111                            0.000000   \n",
       "3                        0.000000                            0.000000   \n",
       "4                        0.011628                            0.023256   \n",
       "..                            ...                                 ...   \n",
       "121                      0.064516                            0.000000   \n",
       "122                      0.015350                            0.016695   \n",
       "123                      0.032976                            0.006679   \n",
       "124                      0.012707                            0.005276   \n",
       "125                      0.035991                            0.004412   \n",
       "\n",
       "     avg_parentheses_count_per_prompt   \n",
       "0                            1.000000  \\\n",
       "1                            3.611111   \n",
       "2                           11.111111   \n",
       "3                            0.600000   \n",
       "4                            3.151163   \n",
       "..                                ...   \n",
       "121                          6.419355   \n",
       "122                          4.471710   \n",
       "123                          4.339349   \n",
       "124                          4.602278   \n",
       "125                          4.939592   \n",
       "\n",
       "     avg_english_conjunctions_count_per_prompts  \n",
       "0                                      2.285714  \n",
       "1                                      0.555556  \n",
       "2                                      1.444444  \n",
       "3                                      0.300000  \n",
       "4                                      0.686047  \n",
       "..                                          ...  \n",
       "121                                    0.419355  \n",
       "122                                    0.633518  \n",
       "123                                    0.683265  \n",
       "124                                    0.669044  \n",
       "125                                    0.636159  \n",
       "\n",
       "[126 rows x 31 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE ARE DONE WITH FINAL_DF. CONTINUE WITH MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAPtCAYAAAB8WqVQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdZ3RUVf/28WvSCaRQQo+EhN4REAGRqgFUBJEmSsdKURCEW6VKURERLIgiTb3Bgt4gSpEuoHQQpLcgEqpJIMFAkv284Mn8GZJgkjmTMPD9rDVrMXvO/PY+YSaZa84++9iMMUYAAAAAAEt45PYAAAAAAOB2QsgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIA5IhZs2bJZrPp2LFjltU8duyYbDabZs2aZVlNV7PZbBo5cmSmt+3bt69rB5RDXPH/DwC3KkIWALixw4cP65lnnlF4eLj8/PwUGBioBg0a6L333tPly5dze3iW+fLLLzV58uTcHoZLbNiwQSNHjlRMTIxL6sfFxWns2LGqXbu2goKC5Ovrq1KlSqljx45avHixS/oEgDudV24PAACQPYsXL1b79u3l6+urrl27qkqVKrpy5Yp++eUXDR48WHv27NH06dNze5iW+PLLL7V79269+OKLDu2lSpXS5cuX5e3tnTsDy4bLly/Ly+v//vxu2LBBo0aNUvfu3RUcHGxpX4cOHVJkZKSOHz+utm3bqmvXrsqXL59OnDihH3/8UQ8//LDmzJmjp556ytJ+AeBOR8gCADd09OhRderUSaVKldLKlStVrFgx+2MvvPCCDh06ZMlRCmOM/vnnH+XJkyfNY//88498fHzk4ZF7kyJsNpv8/Pxyrf/syKnxJiUlqW3btjp9+rTWrFmjBg0aODw+YsQILVu2TMnJyTetEx8fr7x587pyqABw22G6IAC4obfeekuXLl3SjBkzHAJWqjJlymjAgAH2+0lJSRozZowiIiLk6+ursLAw/ec//1FiYqLD88LCwvTwww9r6dKlql27tvLkyaOPP/5Yq1evls1m07x58/Taa6+pRIkS8vf3V1xcnCTpt99+U4sWLRQUFCR/f381atRI69ev/9f9+N///qeHHnpIxYsXl6+vryIiIjRmzBiHD/6NGzfW4sWLdfz4cdlsNtlsNoWFhUnK+JyslStXqmHDhsqbN6+Cg4P16KOPau/evQ7bjBw5UjabTYcOHbIfRQoKClKPHj2UkJBw03FPmTJFnp6eDlP83nnnHdlsNg0cONDelpycrICAAL3yyiv2tuvPyRo5cqQGDx4sSSpdurR9/248b+n7779XlSpV5Ovrq8qVK2vJkiU3HZ8kff3119q9e7def/31NAEr1YMPPqiWLVva76eeN7VmzRo9//zzKly4sEqWLClJOn78uJ5//nmVL19eefLkUcGCBdW+fft0z7Has2ePmjZtqjx58qhkyZJ64403lJKSku4YfvrpJ/v/VUBAgB566CHt2bPnX/cPAG5lHMkCADe0aNEihYeHq379+pnavnfv3po9e7Yef/xxDRo0SL/99pvGjx+vvXv36rvvvnPYdv/+/ercubOeeeYZ9enTR+XLl7c/NmbMGPn4+Ojll19WYmKifHx8tHLlSrVs2VK1atXSiBEj5OHhoZkzZ6pp06Zat26d7rnnngzHNWvWLOXLl08DBw5Uvnz5tHLlSg0fPlxxcXF6++23JUmvvvqqYmNj9eeff+rdd9+VJOXLly/Dmj///LNatmyp8PBwjRw5UpcvX9bUqVPVoEEDbdu2zR7QUnXo0EGlS5fW+PHjtW3bNn366acqXLiw3nzzzQz7aNiwoVJSUvTLL7/o4YcfliStW7dOHh4eWrdunX277du369KlS7r//vvTrfPYY4/pwIED+u9//6t3331XhQoVkiSFhITYt/nll1+0YMECPf/88woICNCUKVPUrl07RUVFqWDBghmOcdGiRZKkJ598MsNtMvL8888rJCREw4cPV3x8vCRp8+bN2rBhgzp16qSSJUvq2LFj+uijj9S4cWP98ccf8vf3lyRFR0erSZMmSkpK0tChQ5U3b15Nnz493aOhc+fOVbdu3RQZGak333xTCQkJ+uijj3Tfffdp+/btaf6vAMBtGACAW4mNjTWSzKOPPpqp7Xfs2GEkmd69ezu0v/zyy0aSWblypb2tVKlSRpJZsmSJw7arVq0ykkx4eLhJSEiwt6ekpJiyZcuayMhIk5KSYm9PSEgwpUuXNg888IC9bebMmUaSOXr0qMN2N3rmmWeMv7+/+eeff+xtDz30kClVqlSabY8ePWokmZkzZ9rbatSoYQoXLmzOnz9vb9u5c6fx8PAwXbt2tbeNGDHCSDI9e/Z0qNm2bVtTsGDBNH1dLzk52QQGBpohQ4bYfw4FCxY07du3N56enubixYvGGGMmTZpkPDw8zN9//21/riQzYsQI+/233347zc/l+m19fHzMoUOHHPZFkpk6depNx1izZk0THBycpv3SpUvm7Nmz9ltsbKz9sdT/o/vuu88kJSU5PC+9/6uNGzcaSWbOnDn2thdffNFIMr/99pu97cyZMyYoKMhhPy9evGiCg4NNnz59HGpGR0eboKCgNO0A4E6YLggAbiZ1il5AQECmtv/xxx8lyWEamyQNGjRIktKcu1W6dGlFRkamW6tbt24ORyR27NihgwcP6oknntD58+d17tw5nTt3TvHx8WrWrJnWrl2b4TQxSQ61Ll68qHPnzqlhw4ZKSEjQvn37MrV/1zt16pR27Nih7t27q0CBAvb2atWq6YEHHrD/LK737LPPOtxv2LChzp8/b/85p8fDw0P169fX2rVrJUl79+7V+fPnNXToUBljtHHjRknXjm5VqVLFqQUtmjdvroiICId9CQwM1JEjR276vLi4uHSP+L366qsKCQmx35544ok02/Tp00eenp4Obdf/X129elXnz59XmTJlFBwcrG3bttkf+/HHH3Xvvfc6HMEMCQlRly5dHOotX75cMTEx6ty5s/11c+7cOXl6eqpu3bpatWrVTfcPAG5lTBcEADcTGBgo6VooyYzjx4/Lw8NDZcqUcWgvWrSogoODdfz4cYf20qVLZ1jrxscOHjwo6Vr4ykhsbKzy58+f7mN79uzRa6+9ppUrV6YJNbGxsRnWzEjqvlw/xTFVxYoVtXTp0jQLOdx1110O26WO9e+//7b/rNPTsGFD+3TEdevWqVixYrr77rtVvXp1rVu3Tg888IB++eUXdejQIcv7cb0bx5c6xr///vumzwsICND58+fTtD///PP2KY4ZTSVM7zVw+fJljR8/XjNnztTJkydljLE/dv3/1fHjx1W3bt00z7/x/yT1tdO0adN0x3Cznz0A3OoIWQDgZgIDA1W8eHHt3r07S8+z2WyZ2i69c2cyeiz1KNXbb7+tGjVqpPucjM6fiomJUaNGjRQYGKjRo0crIiJCfn5+2rZtm1555ZWbHgGz0o1HbFJdHyLSc9999+nq1avauHGj1q1bp4YNG0q6Fr7WrVunffv26ezZs/b2nB5fhQoVtGPHDp08eVIlSpSwt5crV07lypWTlPFKh+m9Bvr166eZM2fqxRdfVL169RQUFCSbzaZOnTpl6/8q9Tlz585V0aJF0zx+/TL3AOBu+A0GAG7o4Ycf1vTp07Vx40bVq1fvptuWKlVKKSkpOnjwoCpWrGhvP336tGJiYlSqVKlsjyN1GltgYKCaN2+epeeuXr1a58+f14IFCxwWhjh69GiabTMbEFP3Zf/+/Wke27dvnwoVKmTZcuT33HOPfHx8tG7dOq1bt86+SuD999+vTz75RCtWrLDfv5nM7ltWPfzww5o3b56++OILDRkyxOl633zzjbp166Z33nnH3vbPP/+kuYhyqVKl7Eeprnfj/0nqa6dw4cJZfu0AwK2Oc7IAwA0NGTJEefPmVe/evXX69Ok0jx8+fFjvvfeeJKlVq1aSpMmTJztsM2nSJEnSQw89lO1x1KpVSxEREZo4caIuXbqU5vGzZ89m+NzUIzTXH5G5cuWKPvzwwzTb5s2bN1PTB4sVK6YaNWpo9uzZDh/+d+/erWXLltl/Flbw8/NTnTp19N///ldRUVEOR7IuX76sKVOmKCIiIt0l9q+XGvpuDCvO6tChgypVqqQxY8bo119/TXebfzsadj1PT88020+dOjXNdbZatWqlX3/9VZs2bbK3nT17Vl988YXDdpGRkQoMDNS4ceN09erVNP3d7LUDALc6jmQBgBuKiIjQl19+qY4dO6pixYrq2rWrqlSpoitXrmjDhg36+uuv1b17d0lS9erV1a1bN02fPt0+RW/Tpk2aPXu22rRpoyZNmmR7HB4eHvr000/VsmVLVa5cWT169FCJEiV08uRJrVq1SoGBgfalxG9Uv3595c+fX926dVP//v1ls9k0d+7cdD/416pVS/Pnz9fAgQNVp04d5cuXT4888ki6dd9++221bNlS9erVU69evexLuAcFBdmvT2WVhg0basKECQoKClLVqlUlXTsyU758ee3fv9/+f3AztWrVknRtQYpOnTrJ29tbjzzyiNNH3Ly9vfXdd98pMjJS9913nx577DH79ahOnjyphQsXKioqKtMh++GHH9bcuXMVFBSkSpUqaePGjfr555/TLCM/ZMgQzZ07Vy1atNCAAQPsS7iXKlVKu3btsm8XGBiojz76SE899ZTuvvtuderUSSEhIYqKitLixYvVoEEDvf/++079DAAg1+TewoYAAGcdOHDA9OnTx4SFhRkfHx8TEBBgGjRoYKZOneqwBPrVq1fNqFGjTOnSpY23t7cJDQ01w4YNc9jGmGtLuD/00ENp+kldwv3rr79Odxzbt283jz32mClYsKDx9fU1pUqVMh06dDArVqywb5PeEu7r16839957r8mTJ48pXry4GTJkiFm6dKmRZFatWmXf7tKlS+aJJ54wwcHBRpJ9Off0lnA3xpiff/7ZNGjQwOTJk8cEBgaaRx55xPzxxx8O26Qu4X727FmH9vTGmZHFixcbSaZly5YO7b179zaSzIwZM9I8Rzcs4W6MMWPGjDElSpQwHh4eDn1LMi+88EKaGqVKlTLdunX71/EZY0xMTIwZPXq0qVmzpsmXL5/x8fExoaGh5vHHHzeLFi1y2DZ13zdv3pymzt9//2169OhhChUqZPLly2ciIyPNvn370h3Lrl27TKNGjYyfn58pUaKEGTNmjJkxY0a6P9dVq1aZyMhIExQUZPz8/ExERITp3r272bJlS6b2DwBuRTZjsjBXAAAAAABwU5yTBQAAAAAWImQBAAAAgIUIWQAAAABgIbcLWR988IHCwsLk5+enunXrOiwRe6NZs2bJZrM53DK68CIAAAAAWMGtQlbq8r0jRozQtm3bVL16dUVGRurMmTMZPicwMFCnTp2y344fP56DIwYAAABwp3Gr1QXr1q2rOnXq2K+bkZKSotDQUPXr109Dhw5Ns/2sWbP04osvZukCj4mJiUpMTLTfT0lJ0YULF1SwYEHZbDan9wEAAACAezLG6OLFiypevLg8PDI+XuU2FyO+cuWKtm7dqmHDhtnbPDw81Lx5c23cuDHD5126dEmlSpVSSkqK7r77bo0bN06VK1fOcPvx48dr1KhRlo4dAAAAwO3jxIkTKlmyZIaPu03IOnfunJKTk1WkSBGH9iJFimjfvn3pPqd8+fL67LPPVK1aNcXGxmrixImqX7++9uzZk+EPZdiwYRo4cKD9fmxsrO666y6dOHFCgYGB1u0QAAAAALcSFxen0NBQBQQE3HQ7twlZ2VGvXj3Vq1fPfr9+/fqqWLGiPv74Y40ZMybd5/j6+srX1zdNe2BgICELAAAAwL+eRuQ2C18UKlRInp6eOn36tEP76dOnVbRo0UzV8Pb2Vs2aNXXo0CFXDBEAAAAA3Cdk+fj4qFatWlqxYoW9LSUlRStWrHA4WnUzycnJ+v3331WsWDFXDRMAAADAHc6tpgsOHDhQ3bp1U+3atXXPPfdo8uTJio+PV48ePSRJXbt2VYkSJTR+/HhJ0ujRo3XvvfeqTJkyiomJ0dtvv63jx4+rd+/eubkbAAAAAG5jbhWyOnbsqLNnz2r48OGKjo5WjRo1tGTJEvtiGFFRUQ5LKf7999/q06ePoqOjlT9/ftWqVUsbNmxQpUqVcmsXAAAAANzm3Oo6WbkhLi5OQUFBio2NZeELAAAA4A6W2WzgNudkAQAAAIA7IGQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIXcLmR98MEHCgsLk5+fn+rWratNmzZl6nnz5s2TzWZTmzZtXDtAAAAAAHc0twpZ8+fP18CBAzVixAht27ZN1atXV2RkpM6cOXPT5x07dkwvv/yyGjZsmEMjBQAAAHCncquQNWnSJPXp00c9evRQpUqVNG3aNPn7++uzzz7L8DnJycnq0qWLRo0apfDw8BwcLQAAAIA7kduErCtXrmjr1q1q3ry5vc3Dw0PNmzfXxo0bM3ze6NGjVbhwYfXq1StT/SQmJiouLs7hBgAAAACZ5TYh69y5c0pOTlaRIkUc2osUKaLo6Oh0n/PLL79oxowZ+uSTTzLdz/jx4xUUFGS/hYaGOjVuAAAAAHcWtwlZWXXx4kU99dRT+uSTT1SoUKFMP2/YsGGKjY21306cOOHCUQIAAAC43Xjl9gAyq1ChQvL09NTp06cd2k+fPq2iRYum2f7w4cM6duyYHnnkEXtbSkqKJMnLy0v79+9XREREmuf5+vrK19fX4tEDAAAAuFO4zZEsHx8f1apVSytWrLC3paSkaMWKFapXr16a7StUqKDff/9dO3bssN9at26tJk2aaMeOHUwDBAAAAOASbnMkS5IGDhyobt26qXbt2rrnnns0efJkxcfHq0ePHpKkrl27qkSJEho/frz8/PxUpUoVh+cHBwdLUpp2AAAAALCKW4Wsjh076uzZsxo+fLiio6NVo0YNLVmyxL4YRlRUlDw83ObgHAAAAIDbkM0YY3J7ELeyuLg4BQUFKTY2VoGBgbk9HAAAAAC5JLPZgMM+AAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWcruQ9cEHHygsLEx+fn6qW7euNm3alOG2CxYsUO3atRUcHKy8efOqRo0amjt3bg6OFgAAAMCdxq1C1vz58zVw4ECNGDFC27ZtU/Xq1RUZGakzZ86ku32BAgX06quvauPGjdq1a5d69OihHj16aOnSpTk8cgAAAAB3CpsxxuT2IDKrbt26qlOnjt5//31JUkpKikJDQ9WvXz8NHTo0UzXuvvtuPfTQQxozZkymto+Li1NQUJBiY2MVGBiY7bEDAAAAcG+ZzQZucyTrypUr2rp1q5o3b25v8/DwUPPmzbVx48Z/fb4xRitWrND+/ft1//33Z7hdYmKi4uLiHG4AAAAAkFluE7LOnTun5ORkFSlSxKG9SJEiio6OzvB5sbGxypcvn3x8fPTQQw9p6tSpeuCBBzLcfvz48QoKCrLfQkNDLdsHAAAAALc/twlZ2RUQEKAdO3Zo8+bNGjt2rAYOHKjVq1dnuP2wYcMUGxtrv504cSLnBgsAAADA7Xnl9gAyq1ChQvL09NTp06cd2k+fPq2iRYtm+DwPDw+VKVNGklSjRg3t3btX48ePV+PGjdPd3tfXV76+vpaNGwAAAMCdxW2OZPn4+KhWrVpasWKFvS0lJUUrVqxQvXr1Ml0nJSVFiYmJrhgiAAAAALjPkSxJGjhwoLp166batWvrnnvu0eTJkxUfH68ePXpIkrp27aoSJUpo/Pjxkq6dX1W7dm1FREQoMTFRP/74o+bOnauPPvooN3cDAAAAwG3MrUJWx44ddfbsWQ0fPlzR0dGqUaOGlixZYl8MIyoqSh4e/3dwLj4+Xs8//7z+/PNP5cmTRxUqVNDnn3+ujh075tYuAAAAALjNudV1snID18kCAAAAIN2G18kCAAAAAHdAyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBCXrk9AAAAAMAqayrWsLReo707LK2HOwNHsgAAAADAQhzJAgAAQI7Z2qSBZbVqrVpvWS3AShzJAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAu5Xcj64IMPFBYWJj8/P9WtW1ebNm3KcNtPPvlEDRs2VP78+ZU/f341b978ptsDAAAAgLPcKmTNnz9fAwcO1IgRI7Rt2zZVr15dkZGROnPmTLrbr169Wp07d9aqVau0ceNGhYaG6sEHH9TJkydzeOQAAAAA7hQ2Y4zJ7UFkVt26dVWnTh29//77kqSUlBSFhoaqX79+Gjp06L8+Pzk5Wfnz59f777+vrl27prtNYmKiEhMT7ffj4uIUGhqq2NhYBQYGWrMjAAAAd6itTRpYVqvWqvVp2tZUrGFZfUlqtHeHpfXg3uLi4hQUFPSv2cBtjmRduXJFW7duVfPmze1tHh4eat68uTZu3JipGgkJCbp69aoKFCiQ4Tbjx49XUFCQ/RYaGur02AEAAADcOdwmZJ07d07JyckqUqSIQ3uRIkUUHR2dqRqvvPKKihcv7hDUbjRs2DDFxsbabydOnHBq3AAAAADuLF65PYCcMmHCBM2bN0+rV6+Wn59fhtv5+vrK19c3B0cGAAAA4HbiNiGrUKFC8vT01OnTpx3aT58+raJFi970uRMnTtSECRP0888/q1q1aq4cJgAAAIA7nNtMF/Tx8VGtWrW0YsUKe1tKSopWrFihevXqZfi8t956S2PGjNGSJUtUu3btnBgqAAAAgDuY2xzJkqSBAweqW7duql27tu655x5NnjxZ8fHx6tGjhySpa9euKlGihMaPHy9JevPNNzV8+HB9+eWXCgsLs5+7lS9fPuXLly/X9gMAAADA7cutQlbHjh119uxZDR8+XNHR0apRo4aWLFliXwwjKipKHh7/d3Duo48+0pUrV/T444871BkxYoRGjhyZk0MHAAAAcIdwq5AlSX379lXfvn3TfWz16tUO948dO+b6AeWwve0esLRexW+XW1oPAAAAuNO5zTlZAAAAAOAOCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWMjtrpMFAKmOP93Gslqlpn9vWS0AAHBn40gWAAAAAFiIkAUAAAAAFmK6IACXiB78pKX1ir79uaX1AAAAXIUjWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWMgrtwcAIHf8PfY5y2rlf/Ujy2oBAAC4O45kAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIjrZAHZcHHqYEvrBfR729J6AAAAyD0cyQIAAAAACxGyAAAAAMBChCwAAAAAsBDnZAG3oITZoy2t599tuKX1AAAAkDGOZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWYuELALiN/fPtu5bW82v3kqX1AAC4HWX5SFbTpk0VExOTpj0uLk5Nmza1YkwAAAAA4LayHLJWr16tK1eupGn/559/tG7dOksGBQAAAADuKtPTBXft2mX/9x9//KHo6Gj7/eTkZC1ZskQlSpSwdnQAAAAA4GYyHbJq1Kghm80mm82W7rTAPHnyaOrUqZYODgAAAADcTaZD1tGjR2WMUXh4uDZt2qSQkBD7Yz4+PipcuLA8PT1dMkgAAAAAcBeZDlmlSpWSJKWkpLhsMAAAAMCt7p+lMyyr5RfZy7JauHVkawn3gwcPatWqVTpz5kya0DV8+HBLBgYAAAAA7ijLIeuTTz7Rc889p0KFCqlo0aKy2Wz2x2w2GyELwG0jYe1Xltbzv7+DpfUAAMCtKcsh64033tDYsWP1yiuvuGI8AAAAAODWshyy/v77b7Vv394VYwEAAHeoi1uWWFovoHYLS+sBQFZk+WLE7du317Jly1wxFgAAAABwe1k+klWmTBm9/vrr+vXXX1W1alV5e3s7PN6/f3/LBpeeDz74QG+//baio6NVvXp1TZ06Vffcc0+62+7Zs0fDhw/X1q1bdfz4cb377rt68cUXXTo+AAAAAHe2LIes6dOnK1++fFqzZo3WrFnj8JjNZnNpyJo/f74GDhyoadOmqW7dupo8ebIiIyO1f/9+FS5cOM32CQkJCg8PV/v27fXSSy+5bFwAAACAO7nw+y+W1SpQ9T7Lat0ushyyjh496opxZMqkSZPUp08f9ejRQ5I0bdo0LV68WJ999pmGDh2aZvs6deqoTp06kpTu4wAAAABgtWxdJ0uSrly5oqNHjyoiIkJeXtkuk6X+tm7dqmHDhtnbPDw81Lx5c23cuNGyfhITE5WYmGi/HxcXZ1ltAACAW9lf+3dZWq94+WqW1gPcRZYXvkhISFCvXr3k7++vypUrKyoqSpLUr18/TZgwwfIBpjp37pySk5NVpEgRh/YiRYooOjrasn7Gjx+voKAg+y00NNSy2gAAAABuf1kOWcOGDdPOnTu1evVq+fn52dubN2+u+fPnWzq43DBs2DDFxsbabydOnMjtIQEAAABwI1me5/f9999r/vz5uvfee2Wz2eztlStX1uHDhy0d3PUKFSokT09PnT592qH99OnTKlq0qGX9+Pr6ytfX17J6AAAAAO4sWQ5ZZ8+eTXclv/j4eIfQZTUfHx/VqlVLK1asUJs2bSRJKSkpWrFihfr27euyfgEAAABkzRGLD76ER0RYWs/VsjxdsHbt2lq8eLH9fmqw+vTTT1WvXj3rRpaOgQMH6pNPPtHs2bO1d+9ePffcc4qPj7evNti1a1eHhTGuXLmiHTt2aMeOHbpy5YpOnjypHTt26NChQy4dJwAAAIA7V5aPZI0bN04tW7bUH3/8oaSkJL333nv6448/tGHDhjTXzbJax44ddfbsWQ0fPlzR0dGqUaOGlixZYl8MIyoqSh4e/5cb//rrL9WsWdN+f+LEiZo4caIaNWqk1atXu3SsAAAAAO5MWQ5Z9913n3bs2KEJEyaoatWqWrZsme6++25t3LhRVatWdcUYHfTt2zfD6YE3BqewsDAZY1w+JgC4k+05dMqyWpXLFLOsFgAAuSVbF7iKiIjQJ598YvVYAAAAAMDtZSpkxcXFKTAw0P7vm0ndDgAAAADuRJkKWfnz59epU6dUuHBhBQcHp7uKoDFGNptNycnJlg8SAAAAANxFpkLWypUrVaBAAUnSqlWrXDogAAAAAHBnmQpZjRo1SvffAAAAAABHWb5O1syZM/X111+naf/66681e/ZsSwYFAAAAAO4qyyFr/PjxKlSoUJr2woULa9y4cZYMCgAAAADcVZZDVlRUlEqXLp2mvVSpUoqKirJkUAAAAADgrrJ8nazChQtr165dCgsLc2jfuXOnChYsaNW4AKds3h9jWa065YMtqwUAAIDbX5aPZHXu3Fn9+/fXqlWrlJycrOTkZK1cuVIDBgxQp06dXDFGAAAAAHAbWT6SNWbMGB07dkzNmjWTl9e1p6ekpKhr166ckwUAAADgjpflkOXj46P58+drzJgx2rlzp/LkyaOqVauqVKlSrhgfAAAAALiVLIesVOXKlVO5cuWsHAsAAAAAuL1MhayBAwdqzJgxyps3rwYOHHjTbSdNmmTJwAAAAADAHWUqZG3fvl1Xr16VJG3btk02my3d7TJqBwAAAIA7RaZC1nvvvafAwEBJ0urVq105HgAAAABwa5lawr1mzZo6d+6cJCk8PFznz5936aAAAAAAwF1lKmQFBwfr6NGjkqRjx44pJSXFpYMCAAAAAHeVqemC7dq1U6NGjVSsWDHZbDbVrl1bnp6e6W575MgRSwcIAAAAAO4kUyFr+vTpeuyxx3To0CH1799fffr0UUBAgKvHBgAAAABuJ1Mha9euXXrwwQfVokULbd26VQMGDCBkAQAAAEA6srzwxZo1a3TlyhWXDgoAAAAA3FWmjmSlLnxRuHBhFr4AAAAAXGjNngRL6zWq7G9pPfw7Fr4AAAAAAAux8AUAAAAAWChTIUuSWrRoIUksfAEAAAAAN5GphS+uN3PmTAUEBOjQoUNaunSpLl++LEkyxlg+OAAAAABwN1kOWRcuXFCzZs1Urlw5tWrVSqdOnZIk9erVS4MGDbJ8gAAAAADgTrIcsl588UV5e3srKipK/v7/t1JJx44dtWTJEksHBwAAAADuJtPnZKVatmyZli5dqpIlSzq0ly1bVsePH7dsYAAAAADgjrJ8JCs+Pt7hCFaqCxcuyNfX15JBAQAAAIC7ynLIatiwoebMmWO/b7PZlJKSorfeektNmjSxdHAAAAAA4G6yPF3wrbfeUrNmzbRlyxZduXJFQ4YM0Z49e3ThwgWtX7/eFWMEAAAAALeR5SNZVapU0YEDB3Tffffp0UcfVXx8vB577DFt375dERERrhgjAAAAALiNLB/JkqSgoCC9+uqrVo8FAAAAANxetkJWTEyMZsyYob1790qSKleurJ49eyooKMjSweH29OO2q5bWa3W3t6X1AAAAAGdkebrgli1bFBERoXfffVcXLlzQhQsXNGnSJEVERGjbtm2uGCMAAAAAuI0sH8l66aWX1Lp1a33yySfy8rr29KSkJPXu3Vsvvvii1q5da/kgAQAAAMBdZDlkbdmyxSFgSZKXl5eGDBmi2rVrWzo4AAAAAHA3WZ4uGBgYqKioqDTtJ06cUEBAgCWDAgAAAAB3leWQ1bFjR/Xq1Uvz58/XiRMndOLECc2bN0+9e/dW586dXTFGAAAAAHAbWZ4uOHHiRNlsNnXt2lVJSUmSJG9vbz333HOaMGGC5QMEAAAAAHeS5ZDl4+Oj9957T+PHj9fhw4clSREREfL397d8cAAAAADgbjI9XTA5OVm7du3S5cuXJUn+/v6qWrWqqlatKpvNpl27diklJcVlAwUAAAAAd5DpkDV37lz17NlTPj4+aR7z9vZWz5499eWXX1o6OAAAAABwN5kOWTNmzNDLL78sT0/PNI+lLuE+ffp0SwcHAAAAAO4m0yFr//79uvfeezN8vE6dOtq7d68lgwIAAAAAd5XpkBUfH6+4uLgMH7948aISEhIsGRQAAAAAuKtMh6yyZctqw4YNGT7+yy+/qGzZspYMCgAAAADcVaZD1hNPPKHXXntNu3btSvPYzp07NXz4cD3xxBOWDg4AAAAA3E2mr5P10ksv6aefflKtWrXUvHlzVahQQZK0b98+/fzzz2rQoIFeeukllw0UAAAAANxBpo9keXt7a9myZRo7dqxOnTql6dOn6+OPP9apU6c0duxYLVu2TN7e3q4cqyTpgw8+UFhYmPz8/FS3bl1t2rTpptt//fXXqlChgvz8/FS1alX9+OOPLh8jAAAAgDtXpkOWdC1oDRkyRDt27FB8fLwSEhK0Y8cODRkyJN3rZ1lt/vz5GjhwoEaMGKFt27apevXqioyM1JkzZ9LdfsOGDercubN69eql7du3q02bNmrTpo12797t8rECAAAAuDNlKWTltkmTJqlPnz7q0aOHKlWqpGnTpsnf31+fffZZutu/9957atGihQYPHqyKFStqzJgxuvvuu/X+++9n2EdiYqLi4uIcbgAAAACQWTZjjMntQWTGlStX5O/vr2+++UZt2rSxt3fr1k0xMTH63//+l+Y5d911lwYOHKgXX3zR3jZixAh9//332rlzZ7r9jBw5UqNGjUrTHhsbq8DAQKf3wx28NuuKZbXe6O76I5yAO3ugy1bLai3/opZltW4lX/+aYmm99vem/X6xzfMHLKv//Yfl0rS9OPWSZfUlaXK/fGnaxn+VbFn9YR0807TNXGVZeUlSjybW1suM93+09iNP31Y2h/tPDP3T0vpfTiiZpq3PuPOW1f/kPwUtqwXcKeLi4hQUFPSv2cBtjmSdO3dOycnJKlKkiEN7kSJFFB0dne5zoqOjs7S9JA0bNkyxsbH224kTJ5wfPAAAAIA7RqZXF7xT+Pr6ytfXN7eHAQAAAMBNuU3IKlSokDw9PXX69GmH9tOnT6to0aLpPqdo0aJZ2h4AcOtJb3ofAAC3siyHrOTkZM2aNUsrVqzQmTNnlJLiOFd+5cqVlg3uej4+PqpVq5ZWrFhhPycrJSVFK1asUN++fdN9Tr169bRixQqHc7KWL1+uevXquWSMAAAAAJDlkDVgwADNmjVLDz30kKpUqSKbzfbvT7LIwIED1a1bN9WuXVv33HOPJk+erPj4ePXo0UOS1LVrV5UoUULjx4+3j7VRo0Z655139NBDD2nevHnasmWLpk+fnmNjBgAAAHBnyXLImjdvnr766iu1atXKFeO5qY4dO+rs2bMaPny4oqOjVaNGDS1ZssS+uEVUVJQ8PP5vWkn9+vX15Zdf6rXXXtN//vMflS1bVt9//72qVKmS42MHAAAAcGfIcsjy8fFRmTJlXDGWTOnbt2+G0wNXr16dpq19+/Zq3769i0cFAAAAANdk+WziQYMG6b333pObXF4LAAAAAHJUlo9k/fLLL1q1apV++uknVa5cWd7e3g6PL1iwwLLBAQAAAIC7yXLICg4OVtu2bV0xFgAAAABwe1kOWTNnznTFOAAAAADgtpDtixGfPXtW+/fvlySVL19eISEhlg0KAAAAANxVlhe+iI+PV8+ePVWsWDHdf//9uv/++1W8eHH16tVLCQkJrhgjAAAAALiNLIesgQMHas2aNVq0aJFiYmIUExOj//3vf1qzZo0GDRrkijECAAAAgNvI8nTBb7/9Vt98840aN25sb2vVqpXy5MmjDh066KOPPrJyfAAAAADgVrJ8JCshIUFFihRJ0164cGGmCwIAAAC442U5ZNWrV08jRozQP//8Y2+7fPmyRo0apXr16lk6OAAAAABwN1meLvjee+8pMjJSJUuWVPXq1SVJO3fulJ+fn5YuXWr5AAEAAADAnWQ5ZFWpUkUHDx7UF198oX379kmSOnfurC5duihPnjyWDxAAAAAA3Em2rpPl7++vPn36WD0WAAAAAHB7mQpZCxcuVMuWLeXt7a2FCxfedNvWrVtbMjAAAAAAcEeZCllt2rRRdHS0ChcurDZt2mS4nc1mU3JyslVjAwAAAAC3k6mQlZKSku6/AQDAnaFHk9weAQC4jywv4T5nzhwlJiamab9y5YrmzJljyaAAAAAAwF1lOWT16NFDsbGxadovXryoHj16WDIoAAAAAHBXWQ5ZxhjZbLY07X/++aeCgoIsGRQAAAAAuKtML+Fes2ZN2Ww22Ww2NWvWTF5e//fU5ORkHT16VC1atHDJIAEAAADAXWQ6ZKWuKrhjxw5FRkYqX7589sd8fHwUFhamdu3aWT5AAAAAAHAnmQ5ZI0aMkCSFhYWpY8eO8vPzc9mgAAAAAMBdZTpkperWrZsrxgEAAAAAt4Ush6zk5GS9++67+uqrrxQVFaUrV644PH7hwgXLBgcAAAAA7ibLqwuOGjVKkyZNUseOHRUbG6uBAwfqsccek4eHh0aOHOmCIQIAAACA+8hyyPriiy/0ySefaNCgQfLy8lLnzp316aefavjw4fr1119dMUYAAAAAcBtZDlnR0dGqWrWqJClfvnz2CxM//PDDWrx4sbWjAwAAAAA3k+WQVbJkSZ06dUqSFBERoWXLlkmSNm/eLF9fX2tHBwAAAABuJsshq23btlqxYoUkqV+/fnr99ddVtmxZde3aVT179rR8gAAAAADgTrK8uuCECRPs/+7YsaPuuusubdy4UWXLltUjjzxi6eAAAAAAwN1kOWTdqF69eqpXr54VYwEAAAAAt5epkLVw4cJMF2zdunW2BwMAAAAA7i5TIatNmzaZKmaz2ZScnOzMeAAAAADArWUqZKWkpLh6HAAAAABwW3DqnKx//vlHfn5+Vo0FAADAZfq2suX2EADcIbK8hHtycrLGjBmjEiVKKF++fDpy5Igk6fXXX9eMGTMsHyAAAAAAuJMsh6yxY8dq1qxZeuutt+Tj42Nvr1Klij799FNLBwcAAAAA7ibLIWvOnDmaPn26unTpIk9PT3t79erVtW/fPksHBwAAAADuJssh6+TJkypTpkya9pSUFF29etWSQQEAAACAu8pyyKpUqZLWrVuXpv2bb75RzZo1LRkUAAAAALirLK8uOHz4cHXr1k0nT55USkqKFixYoP3792vOnDn64YcfXDFGAAAAAHAbWT6S9eijj2rRokX6+eeflTdvXg0fPlx79+7VokWL9MADD7hijAAAAADgNrJ0JCspKUnjxo1Tz549tXz5cleNCQAAAADcVpaOZHl5eemtt95SUlKSq8YDAAAAAG4ty9MFmzVrpjVr1rhiLAAAAADg9rK88EXLli01dOhQ/f7776pVq5by5s3r8Hjr1q0tGxwAAAAAuJssh6znn39ekjRp0qQ0j9lsNiUnJzs/KgAAAABwU1kOWSkpKa4YBwAAcMKwDp65PQQAwP+XpXOyrl69Ki8vL+3evdtV4wEAAAAAt5alkOXt7a277rqLKYEAAAAAkIEsry746quv6j//+Y8uXLjgivFk6MKFC+rSpYsCAwMVHBysXr166dKlSzd9zvTp09W4cWMFBgbKZrMpJiYmZwYLAAAA4I6V5XOy3n//fR06dEjFixdXqVKl0qwuuG3bNssGd70uXbro1KlTWr58ua5evaoePXro6aef1pdffpnhcxISEtSiRQu1aNFCw4YNc8m4AAAAAOB6WQ5Zbdq0ccEwbm7v3r1asmSJNm/erNq1a0uSpk6dqlatWmnixIkqXrx4us978cUXJUmrV6/OoZECAAAAuNNlOWSNGDHCFeO4qY0bNyo4ONgesCSpefPm8vDw0G+//aa2bdta1ldiYqISExPt9+Pi4iyrDQAAAOD2l+WQlWrr1q3au3evJKly5cqqWbOmZYO6UXR0tAoXLuzQ5uXlpQIFCig6OtrSvsaPH69Ro0ZZWhMAAADAnSPLC1+cOXNGTZs2VZ06ddS/f3/1799ftWrVUrNmzXT27Nks1Ro6dKhsNttNb/v27cvqEJ0ybNgwxcbG2m8nTpzI0f4BAAAAuLcsH8nq16+fLl68qD179qhixYqSpD/++EPdunVT//799d///jfTtQYNGqTu3bvfdJvw8HAVLVpUZ86ccWhPSkrShQsXVLRo0azuwk35+vrK19fX0poAAAAA7hxZDllLlizRzz//bA9YklSpUiV98MEHevDBB7NUKyQkRCEhIf+6Xb169RQTE6OtW7eqVq1akqSVK1cqJSVFdevWzdoOAAAAAIALZXm6YEpKiry9vdO0e3t7KyUlxZJB3ahixYpq0aKF+vTpo02bNmn9+vXq27evOnXqZF9Z8OTJk6pQoYI2bdpkf150dLR27NihQ4cOSZJ+//137dixI8ev8QUAAADgzpHlkNW0aVMNGDBAf/31l73t5MmTeumll9SsWTNLB3e9L774QhUqVFCzZs3UqlUr3XfffZo+fbr98atXr2r//v1KSEiwt02bNk01a9ZUnz59JEn333+/atasqYULF7psnAAAAADubNm6GHHr1q0VFham0NBQSdKJEydUpUoVff7555YPMFWBAgVueuHhsLAwGWMc2kaOHKmRI0e6bEwAAAAAcKMsh6zQ0FBt27ZNP//8s33lv4oVK6p58+aWDw4AAAAA3E22rpNls9n0wAMP6IEHHrB6PAAAAADg1jJ9TtbKlStVqVIlxcXFpXksNjZWlStX1rp16ywdHAAAAAC4m0wfyZo8ebL69OmjwMDANI8FBQXpmWee0aRJk9SwYUNLB4ic90Z3n9weAgAAAOC2Mn0ka+fOnWrRokWGjz/44IPaunWrJYMCAAAAAHeV6ZB1+vTpdK+PlcrLy0tnz561ZFAAAAAA4K4yHbJKlCih3bt3Z/j4rl27VKxYMUsGBQAAAADuKtMhq1WrVnr99df1zz//pHns8uXLGjFihB5++GFLBwcAAAAA7ibTC1+89tprWrBggcqVK6e+ffuqfPnykqR9+/bpgw8+UHJysl599VWXDRQAAAAA3EGmQ1aRIkW0YcMGPffccxo2bJiMMZKuXTMrMjJSH3zwgYoUKeKygQIAAACAO8jSxYhLlSqlH3/8UX///bcOHTokY4zKli2r/Pnzu2p8AAAAAOBWshSyUuXPn1916tSxeiwAAAAA4PYyvfAFAAAAAODfEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALCQV24PAACA293kfvlyewgAgBzEkSwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQix8AQAA4CY++U/B3B4CgEzgSBYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABZym5B14cIFdenSRYGBgQoODlavXr106dKlm27fr18/lS9fXnny5NFdd92l/v37KzY2NgdHDQAAAOBO4zYhq0uXLtqzZ4+WL1+uH374QWvXrtXTTz+d4fZ//fWX/vrrL02cOFG7d+/WrFmztGTJEvXq1SsHRw0AAADgTuOV2wPIjL1792rJkiXavHmzateuLUmaOnWqWrVqpYkTJ6p48eJpnlOlShV9++239vsREREaO3asnnzySSUlJcnLyy12HQAAAICbcYsjWRs3blRwcLA9YElS8+bN5eHhod9++y3TdWJjYxUYGHjTgJWYmKi4uDiHGwAAAABklluErOjoaBUuXNihzcvLSwUKFFB0dHSmapw7d05jxoy56RRDSRo/fryCgoLst9DQ0GyPGwAAAMCdJ1dD1tChQ2Wz2W5627dvn9P9xMXF6aGHHlKlSpU0cuTIm247bNgwxcbG2m8nTpxwun8AAAAAd45cPTFp0KBB6t69+023CQ8PV9GiRXXmzBmH9qSkJF24cEFFixa96fMvXryoFi1aKCAgQN999528vb1vur2vr698fX0zNX4AAAAAuFGuhqyQkBCFhIT863b16tVTTEyMtm7dqlq1akmSVq5cqZSUFNWtWzfD58XFxSkyMlK+vr5auHCh/Pz8LBs7AAAAAKTHLc7Jqlixolq0aKE+ffpo06ZNWr9+vfr27atOnTrZVxY8efKkKlSooE2bNkm6FrAefPBBxcfHa8aMGYqLi1N0dLSio6OVnJycm7sDAAAA4DbmNuuYf/HFF+rbt6+aNWsmDw8PtWvXTlOmTLE/fvXqVe3fv18JCQmSpG3bttlXHixTpoxDraNHjyosLCzHxg4AAADgzuE2IatAgQL68ssvM3w8LCxMxhj7/caNGzvcBwAAAICc4BbTBQEAAADAXRCyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALCQ21wnCwAA4Fb25YSSuT0EALcIjmQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYyCu3BwAAQG77/sNyuT0EAMBthJAFALlo+Re1cnsIAADAYkwXBAAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQm4Tsi5cuKAuXbooMDBQwcHB6tWrly5dunTT5zzzzDOKiIhQnjx5FBISokcffVT79u3LoREDAAAAuBO5Tcjq0qWL9uzZo+XLl+uHH37Q2rVr9fTTT9/0ObVq1dLMmTO1d+9eLV26VMYYPfjgg0pOTs6hUQMAAAC409iMMSa3B/Fv9u7dq0qVKmnz5s2qXbu2JGnJkiVq1aqV/vzzTxUvXjxTdXbt2qXq1avr0KFDioiISHebxMREJSYm2u/HxcUpNDRUsbGxCgwMdH5nAAAAALiluLg4BQUF/Ws2cIsjWRs3blRwcLA9YElS8+bN5eHhod9++y1TNeLj4zVz5kyVLl1aoaGhGW43fvx4BQUF2W832xYAAAAAbuQWISs6OlqFCxd2aPPy8lKBAgUUHR190+d++OGHypcvn/Lly6effvpJy5cvl4+PT4bbDxs2TLGxsfbbiRMnLNkHAAAAAHeGXA1ZQ4cOlc1mu+nN2YUqunTpou3bt2vNmjUqV66cOnTooH/++SfD7X19fRUYGOhwAwAAAIDM8srNzgcNGqTu3bvfdJvw8HAVLVpUZ86ccWhPSkrShQsXVLRo0Zs+P3XaX9myZXXvvfcqf/78+u6779S5c2dnhw8AAAAAaeRqyAoJCVFISMi/blevXj3FxMRo69atqlWrliRp5cqVSklJUd26dTPdnzFGxhiHhS0AAAAAwEpucU5WxYoV1aJFC/Xp00ebNm3S+vXr1bdvX3Xq1Mm+suDJkydVoUIFbdq0SZJ05MgRjR8/Xlu3blVUVJQ2bNig9u3bK0+ePGrVqlVu7g4AAACA25hbhCxJ+uKLL1ShQgU1a9ZMrVq10n333afp06fbH7969ar279+vhIQESZKfn5/WrVunVq1aqUyZMurYsaMCAgK0YcOGNItoAAAAAIBV3OI6Wbkps2vhAwAAALi93VbXyQIAAAAAd0HIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALEbIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAAAAAMBChCwAAAAAsBAhCwAAAAAsRMgCAAAAAAsRsgAAAADAQoQsAAAAALAQIQsAAAAALETIAgAAAAALuU3IunDhgrp06aLAwEAFBwerV69eunTpUqaea4xRy5YtZbPZ9P3337t2oAAAAADuaG4Tsrp06aI9e/Zo+fLl+uGHH7R27Vo9/fTTmXru5MmTZbPZXDxCAAAAAJC8cnsAmbF3714tWbJEmzdvVu3atSVJU6dOVatWrTRx4kQVL148w+fu2LFD77zzjrZs2aJixYrl1JABAAAA3KHc4kjWxo0bFRwcbA9YktS8eXN5eHjot99+y/B5CQkJeuKJJ/TBBx+oaNGimeorMTFRcXFxDjcAAAAAyCy3CFnR0dEqXLiwQ5uXl5cKFCig6OjoDJ/30ksvqX79+nr00Ucz3df48eMVFBRkv4WGhmZ73AAAAADuPLkasoYOHSqbzXbT2759+7JVe+HChVq5cqUmT56cpecNGzZMsbGx9tuJEyey1T8AAACAO1OunpM1aNAgde/e/abbhIeHq2jRojpz5oxDe1JSki5cuJDhNMCVK1fq8OHDCg4Odmhv166dGjZsqNWrV6f7PF9fX/n6+mZ2FwAAAADAQa6GrJCQEIWEhPzrdvXq1VNMTIy2bt2qWrVqSboWolJSUlS3bt10nzN06FD17t3boa1q1ap699139cgjjzg/eAAAAABIh1usLlixYkW1aNFCffr00bRp03T16lX17dtXnTp1sq8sePLkSTVr1kxz5szRPffco6JFi6Z7lOuuu+5S6dKlc3oXAAAAANwh3GLhC0n64osvVKFCBTVr1kytWrXSfffdp+nTp9sfv3r1qvbv36+EhIRcHCUAAACAO53NGGNyexC3sri4OAUFBSk2NlaBgYG5PRwAAAAAuSSz2cBtjmQBAAAAgDsgZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhQhYAAAAAWIiQBQAAAAAWImQBAAAAgIUIWQAAAABgIUIWAAAAAFiIkAUAAAAAFiJkAQAAAICFCFkAAAAAYCFCFgAAAABYiJAFAAAAABYiZAEAAACAhQhZAAAAAGAhtwlZFy5cUJcuXRQYGKjg4GD16tVLly5duulzGjduLJvN5nB79tlnc2jEAAAAAO5EXrk9gMzq0qWLTp06peXLl+vq1avq0aOHnn76aX355Zc3fV6fPn00evRo+31/f39XDxUAAADAHcwtQtbevXu1ZMkSbd68WbVr15YkTZ06Va1atdLEiRNVvHjxDJ/r7++vokWLZrqvxMREJSYm2u/HxsZKkuLi4rI5egAAAAC3g9RMYIy5+YbGDcyYMcMEBwc7tF29etV4enqaBQsWZPi8Ro0amUKFCpmCBQuaypUrm6FDh5r4+Pib9jVixAgjiRs3bty4cePGjRs3btzSvZ04ceKmmcItjmRFR0ercOHCDm1eXl4qUKCAoqOjM3zeE088oVKlSql48eLatWuXXnnlFe3fv18LFizI8DnDhg3TwIED7fdTUlJ04cIFFSxYUDabzfmdyQFxcXEKDQ3ViRMnFBgY6Hb1c6IP9uHW6IN9uDX6cPf6OdEH+3Br9ME+3Bp9sA+5Xz8n+rgd9sEVjDG6ePHiTWfSSbk8XXDo0KF68803b7rN3r17s13/6aeftv+7atWqKlasmJo1a6bDhw8rIiIi3ef4+vrK19fXoS04ODjbY8hNgYGBLn3Burp+TvTBPtwafbAPt0Yf7l4/J/pgH26NPtiHW6MP9iH36+dEH7fDPlgtKCjoX7fJ1ZA1aNAgde/e/abbhIeHq2jRojpz5oxDe1JSki5cuJCl863q1q0rSTp06FCGIQsAAAAAnJGrISskJEQhISH/ul29evUUExOjrVu3qlatWpKklStXKiUlxR6cMmPHjh2SpGLFimVrvAAAAADwb9ziOlkVK1ZUixYt1KdPH23atEnr169X37591alTJ/t8yJMnT6pChQratGmTJOnw4cMaM2aMtm7dqmPHjmnhwoXq2rWr7r//flWrVi03d8flfH19NWLEiDTTHt2lfk70wT7cGn2wD7dGH+5ePyf6YB9ujT7Yh1ujD/Yh9+vnRB+3wz7kJpsx/7b+4K3hwoUL6tu3rxYtWiQPDw+1a9dOU6ZMUb58+SRJx44dU+nSpbVq1So1btxYJ06c0JNPPqndu3crPj5eoaGhatu2rV577TW3mvMJAAAAwL24TcgCAAAAAHfgFtMFAQAAAMBdELIAAAAAwEKELAAAAACwECELAAAAACxEyAIAAAAACxGyAOAWdeXKFe3fv19JSUm5PZQsa9q0qWJiYtK0x8XFqWnTppb00bNnT128eDFNe3x8vHr27Ol0/W3btun333+33//f//6nNm3a6D//+Y+uXLnidH3J9fsQFRWl9BYRNsYoKirK6fo50cfatWvTfQ8kJSVp7dq1TteXJE9PT505cyZN+/nz5+Xp6WlJH7i5nHi/Xb58WQkJCfb7x48f1+TJk7Vs2TJL6rv6vXA7vE5Hjx7t8H+Q6vLlyxo9enQujMh1WML9NhYTE6Pg4GBLal25ckXff/+9Nm7cqOjoaElS0aJFVb9+fT366KPy8fGxpJ/0nD59Wh9//LGGDx/udK0///xTwcHB9uurpbp69ao2btyo+++/P9u1z58/r127dql69eoqUKCAzp07pxkzZigxMVHt27dXxYoVnR1+GuHh4Vq6dKnKli1reW1jjFavXq1Dhw6pWLFiioyMlLe3d7br/fnnn/Lz81OhQoUkSevWrdO0adMUFRWlUqVK6YUXXlC9evWcGvM777yjxx9/XKVKlXKqzs388MMP2rRpkyIjI9WgQQOtXLlSEydOVEpKih577DE9/fTTTveRkJCgfv36afbs2ZKkAwcOKDw8XP369VOJEiU0dOhQp/uQpIMHD2rVqlU6c+aMUlJSHB5z9v3m4eGh6OhoFS5c2KH9zJkzKlGihK5evepUfenaB45Tp06l6ePcuXMqWrSo0+G0Tp06Gjp0qNq1a6cjR46ocuXKatu2rTZv3qyHHnpIkydPdqq+5Pp9yKj++fPnVbhwYSUnJztVPyf6yIl9yOj1+tdffykiIkKXL192uo8bJScn6/fff1epUqWUP39+y+vHxcVp5cqVKl++vCV/f0aPHq2XX35Z/v7+Du2XL1/W22+/7fTvjJx4vz344IN67LHH9OyzzyomJkYVKlSQt7e3zp07p0mTJum5555zqr6rX6s59TqNiYnRpk2b0v3b0LVrV6dq58T7+ZZhcFuYMGGCmTdvnv1++/btjYeHhylevLjZsWOHU7UPHjxowsPDjZ+fn2nUqJHp0KGD6dChg2nUqJHx8/MzZcqUMQcPHnR2FzK0Y8cO4+Hh4VSNv/76y9SpU8d4eHgYT09P89RTT5mLFy/aH4+Ojnaqj99++80EBQUZm81m8ufPb7Zs2WJKly5typYtayIiIkyePHnM1q1bs13/vffeS/fm6elphg0bZr/vjJYtW5qYmBhjjDHnz583devWNTabzYSEhBgPDw9ToUIFc+bMmWzXv+eee8yiRYuMMcZ8//33xsPDw7Ru3dq88sorpm3btsbb29v+eHbZbDbj6elpmjdvbubNm2cSExOdqnejadOmGS8vL1OrVi0TGBho5s6dawICAkzv3r3NM888Y/LkyWMmT57sdD/9+/c3tWrVMuvWrTN58+Y1hw8fNsZc+7nVqFHD6frGGDN9+nTj6elpihQpYqpXr25q1Khhv9WsWTPbdXfu3Gl27txpbDabWbVqlf3+zp07zbZt28y4ceNMqVKlnBp7bGysiYmJMTabzRw6dMjExsbabxcuXDCzZ882xYoVc6oPY4wJDAw0hw4dMsZc+x374IMPGmOM+eWXX0zJkiXdYh9sNlu679tjx44Zf39/p+vnRB8Z1d+/f78JCAhwqnbq704PDw8zduxYh9+vkyZNMm3atLHsPTdgwADz6aefGmOMSUpKMg0aNDA2m83kzZvXrFq1yun67du3N1OnTjXGGJOQkGDKli1rvL29jZeXl/nmm2+cru/h4WFOnz6dpv3cuXNO/402xrXvt1QFCxY0u3fvNsYY88knn5hq1aqZ5ORk89VXX5kKFSo4Xd9V74WcfJ0uXLjQBAQEGJvNZoKCgkxwcLD9lj9/fqfrZ/QzWrFihSlUqJDT9W8lXrkd8mCNadOm6YsvvpAkLV++XMuXL9dPP/2kr776SoMHD3bqUPhzzz2nqlWravv27QoMDHR4LC4uTl27dtULL7ygpUuXZqv+rl27bvr4/v37s1X3ekOHDpWHh4d+++03xcTEaOjQoWrSpImWLVtm/wbROHFQ99VXX1X79u01adIkffzxx2rTpo1atGihTz75RNK1KUFjxozRd999l636L774okqUKCEvL8e3bEpKiubMmSNvb2/ZbDb1798/2/uwZMkSJSYmSpJee+01Xbx4UYcPH1bp0qX1559/qk2bNho+fLg++uijbNXfs2ePKleuLEkaP368xo0bp1deecX++Pvvv6/hw4fr4YcfzvY+SNKnn36q77//Xk899ZQCAwP15JNPqnfv3qpSpYpTdSVpypQp+vDDD9WnTx+tWrVKrVq10jvvvKPnn39eknTvvffqrbfe0oABA5zq5/vvv9f8+fN17733ymaz2dsrV66sw4cPO1U71RtvvKGxY8c6/B9YoUaNGrLZbLLZbOlOC8yTJ4+mTp3qVB/BwcH2PsqVK5fmcZvNplGjRjnVh3Ttd0Lqt7g///yz/bUZGhqqc+fOOVXb1fswcOBAe53XX3/d4ehDcnKyfvvtN9WoUSPb9XOij8cee8xev3v37vL19XWov2vXLtWvXz/b9SXp3XfflXTt/3ratGkOU658fHwUFhamadOmOdVHqm+++UZPPvmkJGnRokU6evSo9u3bp7lz5+rVV1/V+vXrnaq/du1avfrqq5Kk7777TsYYxcTEaPbs2XrjjTfUrl07p+obYxx+H6XauXOnChQo4FTt1Pquer+lSkhIUEBAgCRp2bJleuyxx+Th4aF7771Xx48fz3ZdV78XcvJ1OmjQIPXs2VPjxo1Lc9TSGfnz53f4nXf9ayk5OVmXLl3Ss88+a1l/twJC1m0iOjpaoaGhkq5NZ+rQoYMefPBBhYWFqW7duk7VXr9+vTZt2pQmYElSYGCgxowZ41QfqR/K0gs5qe3p/WLPip9//lnfffedateuLenaPrVv315NmzbVihUr7H1l19atWzVlyhQFBARowIABeuWVV9SnTx/743379lXr1q2zXf/pp5/Wb7/9pi+//NJh2oe3t7eWLVumSpUqZbt2elauXKm33npLpUuXliSVLFlSb775psM+ZZWXl5f93JOjR4+qZcuWDo+3bNnSkg/8rVq1Uvfu3XXmzBnNmjVLM2fO1NSpU1WrVi316dNHnTp1sv+RzaqjR48qMjJSktSkSRMlJyc7TDFt3LixXnjhBaf34ezZs2mmUkjXztNx9r2Q6u+//1b79u0tqXW9o0ePyhij8PBwbdq0SSEhIfbHfHx8VLhwYafPHVi1apWMMWratKm+/fZbhw94Pj4+KlWqlIoXL+5UH5JUu3ZtvfHGG2revLnWrFlj/4Lh6NGjKlKkiFO1Xb0P27dvl3TtQ9nvv//uMKXbx8dH1atX18svv5z9HciBPoKCguz1AwIClCdPHof69957r1O/k6Rr/5fStffzggULXDJtL1XqFFBJ+vHHH9W+fXuVK1dOPXv21Hvvved0/djYWPvraMmSJWrXrp38/f310EMPafDgwdmum1Mfjl35fktVpkwZff/992rbtq2WLl2ql156SdK1aczpfcbJLFe/F3LydXry5En179/f0oAlSZMnT5YxRj179tSoUaPs72/p/4Kis6cM3HJy/NgZXKJYsWJm/fr1xhhjypUrZ7766itjjDH79u1zejpFsWLFbjqNa+HChU5NaylYsKCZMWOGOXbsWLq3xYsXOz0VIW/evObAgQMObVevXjVt2rQx1apVM7t27XKqj7x585qjR4/a7+fLl88+xcsYY44fP278/PyyXd8YYxYsWGBCQ0Pt00GMMcbLy8vs2bPHqbqprj+EX7hwYfuUilTHjh0zvr6+2a7funVrM3ToUGOMMZGRkWmmN37yySembNmy2a5vzLV9SG86y9q1a023bt1M3rx5Td68ebNdv2TJkmbt2rXGGGNOnjxpbDabWbx4sf3x1atXWzKtpWHDhmbKlCnGmGuvpSNHjhhjjOnbt6+JjIx0ur4xxvTs2dN89NFHltTKLceOHTPJyckuq79jxw5TpUoVExgYaEaOHGlv79u3r+ncubMlfbh6H7p3725iY2NdVj8n+hg5cqS5dOmSy+rnlLvuusssXbrUJCUlmdDQUPPDDz8YY4zZvXu3CQ4Odrp+2bJlzfz5882lS5dMSEiIWbFihTHm2uu4YMGC2a47a9YsM3PmTGOz2cx7771nZs2aZb99+eWXZsOGDU6PPXWcrn6/ff3118bb29t4eHiYBx54wN4+btw406JFC6fr58T7zdXatm1r5s+f77L6q1evNleuXHFZ/VsJR7JuE4899pieeOIJlS1bVufPn7cfJdi+fbvKlCnjVO3evXura9euev3119WsWTP7N0qnT5/WihUr9MYbb6hfv37Zrl+rVi399ddfGS5WEBMT49RUPunaAhG7du1yWCDCy8tLX3/9tdq3b+/0FLXQ0FAdOXJEYWFhkqR58+apWLFi9sdPnTplX/Ahu9q2bat77rlHXbt21Q8//KBZs2Y5VS89qVNyrl69qqNHj9qn90nXjpY6s5DKhAkT1LBhQ/3111+677779Oqrr2rz5s2qWLGi9u/fr/nz5zs93SGjozwNGzZUw4YNNWXKFM2fPz/b9R999FH16tVL3bp108KFC9W1a1cNGjRIHh4estlsGjx4sB588MFs1081btw4tWzZUn/88YeSkpL03nvv6Y8//tCGDRu0Zs2abNedMmWK/d9lypTR66+/rl9//VVVq1ZNs6iJM1NPU+3fv19Tp07V3r17JUkVK1ZU3759VaFCBadrS1KpUqX0999/a8aMGfY+KlWqpB49elgyfal69eoOq52levvtt9NM3c0uV+/DzJkz7f8+ceKEJNlnPVjl+j5cYcSIES6tL107IjNr1iytWLEi3ZP9V65c6XQfPXr0UIcOHVSsWDHZbDY1b95ckvTbb79Z8p548cUX1aVLF+XLl0+lSpVS48aNJV2bRli1atVs1+3WrZskqXTp0qpfv75TCyDdTE683x5//HHdd999OnXqlKpXr25vb9asmX16qjNc/V5w1et04cKF9n+nHvn8448/0v3b4MysHElq1KiRUlJSdODAgXT3wZkFyG41rC54m7h69aree+89nThxQt27d1fNmjUlXZvHGxAQoN69eztV/80339R7772n6Ohoh6l9RYsW1YsvvqghQ4Zku/Z3332n+Ph4+1z1G/39999auHCh/Rd9drzyyivasWNHuueNJSUlqV27dvrhhx+yvarNqFGjVL58eXXq1Cndx1999VXt27dP3377bbbqX88YowkTJmjKlCk6e/asdu3aZcl0wR49ejjcb9mypTp06GC/P2TIEO3atUtLlizJdh+HDx/Wq6++qh9//FGXLl2SdC3s1qlTR4MHD1abNm2yXVvKeOUlq8THx+ull17Sxo0bVb9+fU2dOlVTpkzRq6++qqtXr6pRo0aaP3++Jf0fPnxYEyZM0M6dO3Xp0iXdfffdeuWVV5z6sJQ6/fPf2Gw2HTlyJNv9SNK3336rTp06qXbt2vYpIL/++qs2b96sefPmOX1+iHTtw+MjjzyioKAg+1TgrVu3KiYmRosWLXL6j3V4eLg2b96sggULOrTHxMTo7rvvdvpnJLl+H5KSkjRq1ChNmTLF/p7Lly+f+vXrpxEjRljygTk+Pl4TJkzI8IOfsz+n06dP6+WXX7bXv/FjixWrkfXt21ezZs3SQw89ZA9B10s9J8ZZ33zzjU6cOKH27durZMmSkqTZs2crODhYjz76qNP1t2zZohMnTuiBBx6wr6K7ePFiBQcHq0GDBk7XT0lJ0aFDh1zy4Tgn3m+pUzNvnDIeHx+vfv366bPPPnOqvqvfC656nXp4ZO6KTjabzen326+//qonnnhCx48fT/NetqL+rYSQdZtYu3at6tevn+bbnqSkJG3YsMGybwaOHDmikydPysvLS0WLFs30h7asOHfunHx8fJyaH32jpKQkJSQk2Gve2EdSUpJOnjxp2dLfN9ZPSEiQp6enw4nbztaPiorSL7/8oqeeesol87Nv3If4+Hh5enrKz8/P6dopKSk6efKkvL29VbBgQZd9M+qK11J69X18fHT16tVsn+t1O4qIiFCXLl3SXPdkxIgR+vzzzy1ZwKNq1aqqV6+ePvroI/t5XsnJyXr++ee1YcOGdL8Vz4qMQvvp06cVGhpqybV7XL0Pzz33nBYsWKDRo0fbw+7GjRs1cuRItWnTJtsL2Vyvc+fOWrNmjZ566ql0P/g5uxBMy5YtFRUVpb59+6Zb34pwUqhQIc2ZM0etWrVyutbtytUfjnPi/ebqSya4+r1wO7xOa9SooXLlymnUqFHp/oyuP1fL3RGybhOuvu5ATEyMXn31Vc2fP19///23JCkkJEQ9evRIs5LOrVj/dtgHfka3Rh85sQ8//vijPD097YtspFq6dKlSUlLSLBqSHa6+5o2/v7927dqVZrrywYMHVb169XQvRplVefLk0Y4dO1S+fHmH9v3796tGjRrZvmZM6tSZNm3aaPbs2Q5/9JOTk7VixQotX77ckpVPXbUPqYKCgjRv3rw0r5kff/xRnTt3VmxsrFP1pWsrJS5evNiSIyXpCQgI0Lp165xeDfFmihcvrtWrV6e70qMzrp+i+2+yM0U3dVW7zJg0aVKW61/PVR+Oc+L9FhcXJ2OM8ufPr4MHDzosyJOcnKxFixZp6NCh+uuvv7Ldh+T694KrXqfXmzNnjjp27JjmS+ErV65o3rx5Tl8nK2/evNq5c6fTp7K4hVw5EwyWc+V1RM6fP2/KlStn8ubNa55++mnz7rvvmnfffdf06dPH5M2b19SqVctcvnzZ/Pbbb9m6VpOr698O+5BR/aeffpqf0W22D8YYU7VqVYcFNVL99NNPplq1atmuez1XX/OmZcuW5rPPPkvT/tlnn9mvf+Os+vXrm++++y5N+3fffWfq1q2b7bo2m83YbDbj4eFh/3fqzcfHx5QrV87pa7qlctU+pAoJCTF//PFHmvY//vjDsmvShIWFpduHVSpWrGi2bdvmsvrGGDNx4kTz/PPPm5SUFEvrhoWFOdzy5s1rv55i/vz57dfJKl26dLbqN27c2OEWGBho/P39Tc2aNU3NmjVN3rx5TWBgoGnSpInT++Lv7++Sa2LmxPsttX5GN09PT/PGG284vS+ufi+46nV6PVf/bWjSpIn56aefnK7jDghZbq5t27ambdu2xsPDw7Rq1cp+v23btqZ169YmLCzM6dXIBgwYYKpUqWKio6PTPHbq1ClTtWpV8/jjj5vAwEAza9asW67+7bAP/IxujT5yYh+MMcbPz89htcpUR48edfkFZK26IORHH31kQkJCzAsvvGDmzp1r5s6da1544QVTuHBh89FHH5n//e9/9lt2zZs3z9x1113m7bffNuvWrTPr1q0zb7/9tgkLCzPz5s1zuBBydoSFhZmzZ89me3yZ4ep9GDVqlOncubP5559/7G3//POP6dKli8MKbs6YO3euefzxx018fLwl9W60dOlS8+CDD6b7nrBKmzZtTFBQkCldurR5+OGHHf6Wtm3b1pI+vvjiC9OgQQOzb98+e9u+fftMw4YNzeeff+50/Xfeecc88sgj5sKFC/a2CxcumEcffdRMnDjR6fqu/nDsyvfb6tWrzapVq4zNZjMLFiwwq1evtt82bNhgTp48aUk/rn4v5MTrNKO/DTt27LDkYsQLFiwwlSpVMjNnzjRbtmxx+B2X3d9ztypClpvr3r276d69u7HZbKZjx472+927dzdPP/20GTdunNO/tEqVKmWWLFmS4eM//fSTsdls2f6D7er6OdGHu9fPiT7Yh8wrUqSIffnl6y1fvtyEhIQ4VTs4ONjkz5/feHh42P+degsMDDQeHh7m+eefd6oPY0yab6QzujnzzWhmajvbh6u5eh/atGljAgICTKFChUyzZs1Ms2bNTKFChUxgYKBlH9Bq1KhhAgICTL58+UyVKlXsR1FSb84KDg42Pj4+xsPDw+TLl8/hNWvFhz5jjMPfzvRuVggPD0/3iNyWLVtMWFiY0/WLFy+e5tIbxhjz+++/O3WZlVS3w4djV18ywdXvBVe+TmvUqGFq1qxpPDw8TNWqVR3GXa1aNRMQEGDat2/v9D646+/q7OCcrNvEqFGj9PLLLytv3ryW1/b19dXhw4ftKyHd6M8//1RYWFi2Txh1df2c6MPd6+dEH+xD5j3zzDPauHGjvvvuO0VEREiSDh06pHbt2qlOnTr69NNPs1179uzZ9gtCTp482a0vCHn8+PFMb5vdRW1WrFihd99912EZ+hdffNG+/LazXL0PN64aejPZXX561KhRN33c2SXYZ8+efdPHnVl5Nif5+/trzZo1qlOnjkP7pk2b1LhxY6fPUwwICNCiRYvsS7enWrVqlVq3bm2/GHx2pbcCXepqw1atCrdixYoMV+ZzduW/VK68ZIKr3wuulDr2UaNGadCgQfbVKaX/+9vQrl07hwstZ8e//c6zagGyWwHXybpNpL5xz5w5Yz85tHz58pYsJV2oUCEdO3Ysww+WR48edaofV9fPiT7cvX5O9ME+ZN5bb72lFi1aqEKFCva+/vzzTzVs2FATJ050qnZOXfMmJ7j6j/GHH36oAQMG6PHHH7evCvbrr7+qVatWevfdd/XCCy843Yer98HV1+2RXP/B0V1C1L9p1qyZnnnmGX366ae6++67JV1brv+5556zJLS3bdtWPXr00DvvvKN77rlH0rVrcA0ePNiSa0AdPXrU6Ro3M2rUKI0ePVq1a9dOd2ENK6R3yYQpU6Zo9OjRllwy4VYOUf8mdexhYWHq2LGjJSsJp+d2ClH/hiNZt4mLFy/q+eef17x58+zfJnl6eqpjx4764IMPnFoSs2fPnjp8+LCWL1+e5huMxMRERUZGKjw8PNvfMrm6/u2wD/yMbo0+cmIfUhljtHz5cu3cuVN58uRRtWrVLL1IY1xcXLrtNptNvr6+Tn9bKUmbN2/WqlWr0v1W2tmVzlL99ddf+uWXX9Ltw9kLKpcsWVJDhw5V3759Hdo/+OADjRs3TidPnnSqfipX7kNOiYmJ0TfffKPDhw9r8ODBKlCggLZt26YiRYqoRIkSTtWOioq66eN33XWXU/Wla1863OxDvRXXaDp79qy6deumJUuW2L/cSEpKUmRkpGbNmuX0FzQJCQl6+eWX9dlnn+nq1auSrl2HsFevXnr77bddMtPFSsWKFdNbb72lp556ymV9uPqSCa6WE69TV5szZ85NH3d29cJbCSHrNtGxY0dt375dU6dOdbgWyoABA1SjRg3Nmzcv27X//PNP1a5dW76+vnrhhRdUoUIFGWO0d+9effjhh0pMTNTmzZuz/YfO1fVvh33gZ3Rr9JET+5BTPDw8bvrHumTJkurevbtGjBiR6QtVXm/cuHF67bXXVL58eRUpUsShL5vNppUrV2Zr3NebNWuWnnnmGfn4+KhgwYJp+nD2A0e+fPm0Y8eOdJehr1mzpv3ivs5w9T6cP39ew4cPzzDsXrhwwan6krRr1y41b95cQUFBOnbsmPbv36/w8HC99tprioqK+tcPVf/m316rVkxTe++99xzuX716Vdu3b9eSJUs0ePBgDR061Kn6xhidOHFCISEh+vPPP+1T1SpUqGDJctzJyclav369qlatKh8fH/t16CIiIiwLV67+cFywYEFt2rTJPkXaFVx9yQRXv1Zd/TqVpPz586e7DzabTX5+fipTpoy6d++epanIN9a/3tWrV5WQkCAfHx/5+/tb8jvplpHD54DBRfz9/c26devStK9du9aS1ciOHDliWrRo4bDEqoeHh4mMjLRkSVdX18+JPty9fk70wT5k3s8//2yGDRtmevXqZXr06OFws8Ls2bNNyZIlzWuvvWYWLlxoFi5caF577TUTGhpqPv74Y/PGG2+Y4OBgM3bs2GzVL1y4sJk5c6YlY81IyZIlzRtvvOGyE9k7d+5s3nrrrTTtb7/9tunYsaMlfbh6H1q2bGnKli1rJkyYYGbOnGlmzZrlcLNCs2bNzODBg40xxuTLl88cPnzYGGPM+vXrTalSpZyuv2PHDofb5s2bzfTp002FChXMt99+63T9m3n//fctWfgiOTnZeHt7mwMHDlgwqvT5+vqaI0eOuKx+cHCwwy11OXpfX19LFiAZMmSIGT16tAUjzZirL5nw/fffO9y+/vpr85///MeUKFHCfPrpp07Xz4hVr1NjjJk0aZIpWLCgefLJJ82UKVPMlClTzJNPPmkKFSpkxo4da3r37m18fX3N9OnTLenPGGMOHDhgmjVrdtOFpdwRR7JuE3fddZcWL16sqlWrOrTv2rVLrVq10p9//mlJP3///bcOHjwoSSpTpowlJ4rmZP2c6MPd6+dEH+zDzf3buQnfffed032knh/SoUMHh/avvvpKH3/8sVasWKG5c+dq7Nix2rdvX5brFytWTGvXrlXZsmWdHmtGXP3N9xtvvKGJEyeqQYMG9hkCv/76q9avX69BgwYpMDDQvm12p/W5eh8CAgL0yy+/qHr16i6pL127CO22bdsUERGhgIAA7dy5U+Hh4Tp+/LjKly+vf/75xyX9Ll68WG+//bZWr17tkvrStelXNWrUyHB6bVZUrlxZM2bM0L333mvByNKqXbu23nzzTTVr1swl9dNz8OBBPffccxo8eHCai6dn1YABAzRnzhxVq1ZN1apVS3O+qBVTjOfPn68hQ4aoX79+9v+HX3/9VR988IEmTJigihUr2retVq2a0/2l+vLLLzV//nz973//s6zm9ax8nbZr104PPPCAnn32WYf2jz/+WMuWLdO3336rqVOnavr06ZZOr9yyZYuefPLJbP29uWXldsqDNT7++GPTvHlzc+rUKXvbqVOnzIMPPmimTZuWiyMDkFVFixY1c+bMcWkffn5+6X6rfuDAAZMnTx5jzLWjdqn/zqo333zTDBgwwJkh/qvBgweb8ePHu6z+jReSzeiW3QvJGuP6fahdu7bZuHGjy+obc+2Cx6lLk19/JGvZsmWmZMmSLuv34MGDll03LiNvvvmmJUfjjDFm4cKF5r777jO///67JfVu9NNPP5kaNWqYRYsWmb/++svExsY63Fxl8+bNpnz58k7XufHCytffrLiYsjG5d9mHw4cPm7x581pa83pWvk7z5s2b7qyMgwcP2vfh0KFDlr/3tm/fbgICAiytmdtYXfA28dFHH+nQoUO666677OeDREVFydfXV2fPntXHH39s33bbtm25NUwAmXDlyhXVr1/fpX2EhoZqxowZmjBhgkP7jBkzFBoaKuna+Tw3zp/PrJdfflkPPfSQIiIiVKlSpTTfSi9YsCB7A7/O+PHj9fDDD2vJkiWqWrWq5d98u3o1Ncn1+/Dhhx9q6NChGj58uKpUqZKm/vVH47KrdevWGj16tL766itJ187diIqK0iuvvKJ27do5Xf/Gb+eNMTp16pRGjhxp2ZHSmjVrOhwxNsYoOjpaZ8+e1YcffmhJH127dlVCQoKqV68uHx8f5cmTx+FxZ89FadWqlaRr/x837otVS6ynx8vLS3/99ZfTdVatWmXBaG4uJ97TN7p8+bKmTJni9AIwUs68TgsUKKBFixbppZdecmhftGiRfcZGfHy8AgICslV/4cKFDvdT38/vv/++GjRokL1B36IIWbeJNm3a5PYQAFikd+/e+vLLL/X666+7rI+JEyeqffv2+umnn+zX7dmyZYv27dunb775RtK11QE7duyYrfr9+/fXqlWr1KRJkzQLOlhl/PjxWrp0qf0k9hsXjXAHrt6H4OBgxcXFqWnTpg7tVn7wfuedd/T444+rcOHCunz5sho1aqTo6GjVq1dPY8eOdbp+cHBwmp+FMUahoaFOLep0vRv/hnp4eCgkJESNGzdWhQoVLOlj8uTJltTJiKtDyu3w4djVy4ffuGiEMUYXL16Uv7+/Pv/8c6fr58Tr9PXXX9dzzz2nVatW2S8FsHnzZv3444+aNm2aJGn58uVq1KhRturfuA82m00hISFq2rSp3nnnHafGfqvhnCwAuMXkxLkJ0rVvdT/++GMdOHBA0rVr6z3zzDMKCwtzunZAQIDmzZunhx56yOlaGcmfP7/effddde/e3SX1jTH65ptvMlyZz4qjca7eh3vuuUdeXl4aMGBAmlUeJWX7g1J6fvnlF+3atUuXLl3S3XffbdkFm9esWeNwP/WDZZkyZeTlxXfFOeXGVUZv/HBcrFixLNd87LHHNGvWLAUGBv7rtbyseL9Jrr1kwo0Xzk59rdatWzfbswJyw/r16/X+++87XHe1X79+Lp9hcbvht9Nt6NKlS2l+cVgxJQRAzti1a5dq1KghSdq9e7fDY1YeoSldunSa6YJWKVCggEuXYpYkX19fl36D/uKLL+rjjz9WkyZN0g0oVnD1PuzevVvbt29Ps2S1K9x333267777LK9rZRC8meTkZH3//ff25dUrV66s1q1b26+n5A59xMTEaMaMGQ71e/bs6dS1MlPd+LnCCkFBQfb3lRVj/Df/dskEZ0NWTlw4Oydepw0aNMiRo5Opx3ncZeZBVnEk6zZx9OhR9e3bV6tXr3ZYycnVc7EBuK+YmBht2rQp3W90nb3mzcyZM7VkyRLNnDlT/v7+TtXKyPjx43Xq1ClNmTLFJfULFCigzz//3H6uiyu4eh/uv/9+DR8+3LKjShlx9YWnDx8+rMmTJ9s/WFaqVEkDBgywLMgfOnRIrVq10smTJ+2BdP/+/QoNDdXixYst6cfVfWzZskWRkZHKkyePwzSvy5cva9myZbr77rud3odU7vrhODQ0VM8++6yGDRuWrev/ZYYrg25OvE6la4H60KFD6b6f77//fqfrz5kzR2+//bZ9hd5y5cpp8ODBLr0QdW4gZN0mGjRoIGNMjkwJAZAzDh06pMOHD+v+++9Xnjx57F+aWGHRokXq0qWLLl26pMDAwDTf6Dp7En7NmjV1+PBhGWMUFhaWZsqjFQvwtG3bVitXrlTBggVVuXJlyxfXKF26tH766SfLznVIj6v34euvv9bIkSM1ePDgdBfWsGKZaldfeHrp0qVq3bq1atSoYf92ff369dq5c6cWLVqkBx54wKn60rVFI4wx+uKLL+wn958/f15PPvmkPDw8tHjx4lu+j4YNG6pMmTL65JNP7NMok5KS1Lt3bx05ckRr1651eh9y4sPx2bNnHaaphYSEWFbb1ZdMcHXQzYnX6a+//qonnnhCx48f140RwYov7SdNmqTXX39dffv2tb+ff/nlF33wwQd644030iy44c4IWbeJfPnyaevWrTkyJQSAa50/f14dOnTQqlWrZLPZdPDgQYWHh6tnz57Knz+/JScHlytXTq1atdK4ceNccqRp1KhRN318xIgRTvfRo0ePmz4+c+ZMp+rPnj1bS5Ys0WeffZZmJTiruHof0vu23mazWTrLoUiRInrzzTdddl5ZzZo1FRkZmWZq69ChQ7Vs2TJLAnvevHn166+/prnW5M6dO9WgQQNdunTplu8jT5482r59e5ovBf744w/Vrl1bCQkJTtV39Yfj+Ph49evXT3PmzLEfPfH09FTXrl01depUS35PDRkyRAUKFNDQoUOdrpUeVwfdnHid1qhRQ+XKldOoUaPSvU6js0fkSpcurVGjRqWZLTF79myNHDkyV1aAdBXOybpN1KlTRydOnCBkAbeBl156Sd7e3oqKinK4OGbHjh01cOBAS0LWyZMn1b9/f5dN5bMiRP0bZwPIv+nQoYP++9//qnDhwi47GufqfciJDyweHh4uPX9j79699uXhr9ezZ0/LVuzz9fXVxYsX07RfunRJPj4+btFHYGCgoqKi0oSsEydOZHu57etNnTpVH330kcOH49atW6ty5coaOXKk0yFr4MCBWrNmjRYtWuQQ4vr3769Bgwbpo48+cqq+5PpLJmzZssUhYEnXlrgfMmSIateu7VRtKWdepwcPHtQ333yjMmXKWFLvRqdOnUp3AY369evr1KlTLukztxCybhOffvqpnn32WZ08eTLda6FYeeVyAK61bNkyLV26VCVLlnRoL1u2rI4fP25JH5GRkdqyZYvCw8MtqZeRrVu3OpybULNmTcv7cNX0om7dumnr1q168sknXbbwRSpX7YOrl6yWrn0p8MEHH7hsifKQkBDt2LEjzTWxduzYocKFC1vSx8MPP6ynn35aM2bMsE/z+u233/Tss8+qdevWbtFHx44d1atXL02cONH+IXb9+vUaPHiwOnfu7HR9V384/vbbb/XNN9+ocePG9rZWrVopT5486tChg2Uhy5WXTHB10M2J12ndunV16NAhl4WsMmXK6KuvvtJ//vMfh/b58+dbdt27W0aOXPIYLrdx40ZTunTpHLlyOQDXypcvnzlw4ID934cPHzbGGLN582ZToEABS/r49NNPzV133WVGjBhhvvnmG/O///3P4eas06dPmyZNmhibzWby589v8ufPb2w2m2natKk5c+aMBXtgzKVLl0yPHj2Mp6en/feel5eX6dmzp4mPj3e6vr+/v1m3bp0FI82Yq/fBGGMOHTpk+vbta5o1a2aaNWtm+vXrZw4dOmRJbWOMSU5ONi1atDDh4eHm4YcfNm3btnW4OWvUqFEmODjYTJgwwaxdu9asXbvWjB8/3gQHB5vRo0dbsAfG/P3336Z169bGZrMZHx8f4+PjYzw8PEybNm1MTEyMW/SRmJho+vfvb6/r4eFhfH19zYsvvmj++ecfp+tXrlzZjB07Nk37mDFjTJUqVZyunydPHvPHH3+kad+9e7fx9/d3ur4xxgQHB5uZM2daUis9/fr1MyVLljTz5s0zUVFRJioqyvz3v/81JUuWNAMGDHC6fk68ThcsWGAqVapkZs6cabZs2WJ27tzpcHPWN998Yzw9PU1kZKQZPXq0GT16tImMjDReXl5mwYIFFuzBrYNzsm4TlSpVUsWKFTVkyJB0v3HNiW8zAVijVatWqlWrlsaMGaOAgADt2rVLpUqVUqdOnZSSkmK/WLAzbraylhXn6nTs2FFHjhzRnDlz7FMe//jjD3Xr1k1lypTRf//7X6fqS9Izzzyjn3/+2eFiqKnTix544AGnv/muUKGCvvrqK5fOBHD1PuTEohF9+/bVp59+muFS985OiTTGaPLkyXrnnXf0119/SZKKFy+uwYMHq3///pYeYTx06JD9yGvFihVd8m3+wYMHtW/fPpf1kZCQoMOHD0uSIiIiLJsS/O2336pjx45q3ry5w2tpxYoV+uqrr9S2bVun6jdr1kwFCxbUnDlz5OfnJ0m6fPmyunXrpgsXLujnn392eh+KFi2qdevWueyIyZUrVzR48GBNmzZNSUlJkiRvb28999xzmjBhgnx9fS3px5Wv05w4j3Pr1q169913HfZh0KBBLpnpkJsIWbeJvHnzaufOnS47vAsg5+zevVvNmjXT3XffrZUrV6p169bas2ePLly4oPXr17v8+lNWCAoK0s8//6w6deo4tG/atEkPPvigYmJinO6jUKFCaaYXSdKqVavUoUMHnT171qn6ixcv1tSpUzVt2jRLLtCcHlfvQ04sGpETF55OlXo+ihVTr3LakSNHXDo9d+XKlapfv749oLiCKz8c7969W5GRkUpMTFT16tUlXVvQwc/PT0uXLlXlypWd7sPVl0xI5aqgmxP+bUo6X9pnHiHrNvHII4+oe/fuateuXW4PBYAFYmNj9f7772vnzp26dOmS7r77br3wwgsqVqyY5X39888/ln8wCwgI0Lp16+wXVU61fft2NWrUSHFxcU734e/vr61btzosDiJJe/bs0T333KP4+Hin6ufPn18JCQlKSkqSv79/mnNdnV3mXnL9Pvj5+en3339P8839gQMHVK1aNYfrKmZXqVKltHTpUpctdX/06FElJSWl2YeDBw/K29vbkgDcrl073XPPPXrllVcc2t966y1t3rxZX3/9tdN9eHh4qGTJkmrUqJEaN26sRo0aWfrFaL58+ZSUlKQ6derY6zdo0MBlK2O6QkJCgr744guHI31dunSxbB9cfcmE2NhYJScn25dXT3XhwgV5eXkpMDDQqfo58Tp1tR9//FGenp6KjIx0aF+6dKlSUlLUsmXLXBqZ9QhZt4np06frjTfeUM+ePdNdMceqEyIBuF5UVJRCQ0PTnQYVFRWlu+66y+k+kpOTNW7cOE2bNk2nT5/WgQMHFB4ertdff11hYWHq1auXU/UfffRRxcTE6L///a+KFy8u6dqKhl26dFH+/Pn13XffOb0Prp5eNHv27Js+3q1bN6fqS67fh9DQUE2aNEnt27d3aP/qq6/08ssvKyoqyqn6kusvPN2oUSP17Nkzzc/7888/16effqrVq1c73UdISIhWrlyZZmns33//Xc2bN9fp06ed7uPkyZNavXq11qxZozVr1ujgwYMqXry4GjVqpCZNmqh3795O1b969ao2bdpkr79hwwZduXJFtWvXVpMmTfTGG284Vf92+HDs6ksmtGzZUo888oief/55h/Zp06Zp4cKF+vHHH52qnxOvU0maO3eupk2bpqNHj2rjxo0qVaqUJk+erNKlS+vRRx91qna1atU0YcKENBd5X7JkiV555RXt3LnTqfq3lNw6GQzWun7BixtvLHwBuBcPDw9z+vTpNO3nzp2z7P08atQoEx4ebj7//HOTJ08e++Ia8+bNM/fee6/T9aOiokyNGjWMt7e3CQ8PN+Hh4cbb29vUrFnTnDhxwun6xhiza9cuU7x4cVOwYEHTtGlT07RpU1OwYEFTokQJs3v3bkv6cDVX70NOLBpRo0YNExAQYPLly2eqVKliatas6XBzVkBAgDl48GCa9oMHD5qgoCCn6xtjjJ+fn9m3b1+a9r179xo/Pz9L+rjRgQMHTLdu3YyXl5dL/k7v3r3b0vpVq1Y1ixcvTtP+008/mWrVqjld3xhj9u3bZ1544QX7e+GFF14we/futaR2TsifP3+6i3fs3bvXkkWLcuJ1+uGHH5pChQqZN954w+Fvw8yZM03jxo2dru/n52eOHj2apv3o0aOWLXByq2AJ99tE6oX7ALg/8/9PML7RpUuXLJvWN2fOHE2fPl3NmjXTs88+a2+vXr26faqOM0JDQ7Vt2zb9/PPPDlN/mjdv7nTtVFWrVtXBgwcdphd17tzZ0ulFycnJ+v777x2WoW/durU8PT0tqe/qfXj99dcVEBCgd955R8OGDZN0bdGIkSNHqn///k7Xl6Q2bdpYUicjNpst3WsDpU7NskLVqlU1f/58DR8+3KF93rx5qlSpkiV9JCQk6JdfftHq1au1evVq+4WD+/btm+acvOw4cOCAvfaaNWuUmJiohg0bauLEiZbUP3jwYLo/iwoVKujQoUNO1//222/VqVMn1a5dW/Xq1ZMk+4V3582bZ+npEK66ZEJiYqJ9wYvrXb16VZcvX3a6fk68TqdOnapPPvlEbdq0cTiXs3bt2nr55Zedrh8UFKQjR46kmeZ76NAh5c2b1+n6t5TcTnkAgGteeukl89JLLxkPDw/zzDPP2O+/9NJLpn///qZu3bqmfv36lvTl5+dnjh07ZoxxXCZ+z549Jm/evE7VvnLlivH09DS///670+O8WR/h4eHpfmtslYMHD5qyZcsaf39/+1EZf39/U758eUuWQHf1Ply9etXMnj3bREdHG2OMiYuLM3FxcS7py5Uefvhh0759e5OUlGRvS0pKMu3atTMtWrSwpI+FCxcaLy8v07VrVzNr1iwza9Ys89RTTxkvLy/z3XffWdKHt7e3KVy4sHnppZfM//73P3PhwgVL6qay2WymcOHCZuzYsWbnzp0mJSXF0vpFihQxK1asSNO+fPlyExIS4nT98PBw8/rrr6dpHz58uAkPD3e6vjGuv2RC48aNTd++fdO0P//88+a+++5zun5OvE4z+ttw4MABS46WPf3006Zq1aoOv0MPHjxoqlWrZnr16uV0/VsJIes2snr1avPwww+biIgIExERYR555BGzdu3a3B4WgExq3Lixady4sbHZbKZ+/fr2+40bNzYPPvigefrpp+3Xz3LW3XffbebOnWuMcfxDOmrUKEs+DJQuXdrs2LHD6To3U7x4cZeGrJYtW5oWLVqY8+fP29vOnTtnWrRoYVq1amVJH67ehzx58tg/MOWEixcvmtjYWIebs/bs2WMKFixoIiIiTPfu3U337t1NRESECQkJsTTI//DDD6Z+/frG39/fFCxY0DRp0sSsXr3asvqPPvqoKViwoPl/7J13VBTJ9/afIecggiiigKCCgKCuCQNiThh2zYqC2RVZMX9dA5jQXVzBnAVzDqsuoEhQTCjJSBAEDJgToMT7/sE7/WOc0YXpbkS3P+fMOVAzPLdqmFDVdeu5tWvXpmHDhtHmzZspOTmZM30vLy9ydHQkVVVVatOmDc2bN49CQ0M5q7fG9+RYXV1dZlpoSkoKqaurs9YnKhuDhYUFnT17lnl9njlzhho0aECTJk1irX/p0iVSU1Oj9u3b0+LFi2nx4sXUvn17UlNT42w+xvfr1Nramk6cOEFEkt8NgYGBnKT/vn37llq3bk1KSkpkZmZGZmZmpKSkRJ06daI3b96w1q9OCIusH4Tdu3eTkpISDR48mAICAiggIIAGDx5MysrKtHfv3m/dPQEBgUowZswYTianX+PEiROkq6tLfn5+pKGhQX/88QeNGzeOVFRUKCwsjLX+tm3bqFevXhILFK5ZtmwZjR49moqKinjR19DQoKSkJKn2hIQE1rt9YvgeQ8eOHTm7wv0l0tPTqVevXqShocEUwVVQUOD0TPDjx49p3rx51KtXL/r555/Jx8eH19fWl9i3bx/l5uay0khMTKTAwED6+eefycjIiOrUqUPDhw/nqIdlBWtPnTpFM2bMoBYtWpC6ujonO+B8T4579uxJO3bskGrfsWMHdevWjbU+EZGBgQFFRERItV+4cIFq1qzJSYz4+HgaPnw42djYUPPmzcnd3Z2zi2MVhc3rdOvWrWRiYkIHDhwgTU1N2r9/Py1dupT5mQtKS0spNDSUVq1aRWvXrqWoqChOdKsbgrvgD4K1tTUmTJiA6dOnS7SvXr0aW7duZc4TCAgICIi5ePEifH19JWziFy5ciG7durHWdnR0RFpaGoqKilC/fn2pXHsu6jMNGDAA4eHh0NLSgp2dnVQMtnbMNWrUwOnTp9G2bVuJ9piYGPTt25cTC3e+x3Do0CHMmzcP06dPR/PmzaX0uSi07OTkBCKCl5eXzGLEHTt2ZB2jIkyZMgW+vr6oWbMmbzF0dHSQkJDAqt4VESE+Ph4RERGIiIhAaGgoiEjmWR55ePXqFaKiohAREYHIyEjcvXsX+vr6ePnyJWttIsK5c+eQmJgIdXV12Nvbo0OHDhz0usyBb+HChRg8eDBat24NoOxM1uHDh+Hj48O4lALyOybzXTKhovj5+WHSpEnQ09PjRZ/t63Tv3r1YvHgxU+urTp068PHxYe06Wxns7Oxw9uxZmJqaVllMrhEWWT8IqqqquHPnjlTNjbS0NNja2nJSC0VAQKBqyMvLg5+fH8LDw/H8+XMpY5v09PRv1LOK4+Pj89X7Fy1axDoG33bMbm5uiIuLw/bt29GyZUsAwLVr1zB+/Hg0b94cu3btYqUP8D8GBQUFqTaRSMSYq3BhHKGlpYWbN2+iUaNGrLXYwMUC6N/Q1tZGYmKiXDFWr16NyMhIXLp0CR8+fEDTpk3RoUMHODs7o3379tDX12fVt2nTpkksqjp06MDU5LKzs5NppsMH8k6OZb1WZcHmdct3yYSKwvdrlc3rtDz5+fnIzc2FkZERRz2rOFyN4VsiuAv+IJiamiI8PFxqkXX+/Pnv+iqAgMB/kXHjxiEqKgqjRo1C7dq1q2xyxCVcLKL+DbYLkH8jMDAQo0ePRps2bZjag8XFxXB1dUVAQAAnMfgeQ0ZGBq/6APDTTz8hOzv7my+yqvs14/3796Njx46YMGEC2rdvD11dXU71nz59igkTJsDZ2Rm2tracaleGhw8foqioqNJ/VxUuyWvWrEGPHj1Qt25dNG3aFACQmJgINTU1hIaG8h5fTHV/rYrR0NDgpfbdfwVhkfWDMGPGDEybNg0JCQlMaktMTAx27drF2WRAQECgavjnn39w5swZODk5caqrr69f4QUbF6lwAHDjxg0mXdnGxgbNmzfnRLc8z58/l7Bj5uKqKxHh/fv3OHDgAB4/fsyMwdraWupiFhfwMQYAqF+/Pic6X2Pbtm2YNGkSHj9+DFtbW2ZBKoaLlMQfgdjY2Ao9Tt60x8OHD1focb1798a2bdtQu3btSun/CFRF2YfvEUdHxwp/N3CR6v1fQVhk/SBMnjwZxsbG8Pf3x6FDhwCUTQYOHjzIujq3gIBA1aKvr48aNWpwrrtmzRrONb/Eo0ePMGzYMMTExDDnDt6+fYu2bdviwIEDqFu3LusY79+/x6+//ooDBw4w6UOKiooYMmQI1q9fz2qngIhgaWmJO3fuwMrKipeFFcDvGMQkJydj7dq1EgtFT09PznaeXrx4gQcPHkikPnKdkvhfYs+ePZg5cyZvZ8uio6M5qdnEBYGBgRV+LNu6bkVFRWjcuDFOnz6N8ePHs9L60eC71t1/FWGR9QNQXFyM5cuXw8PDA5cuXfrW3REQEGDJkiVLsHDhQgQFBXGaqjF69OhK/428B7THjRuHoqIi3Lt3j5nMJycnw93dHePGjUNISEil+/I548ePR3x8PE6fPs0UL71y5Qq8vLwwceJEHDhwQG5tBQUFWFlZ4dWrV7CysmLd1y/B5xiALxd4tbW15azAq4eHBxwdHbF//36ZxhcCleN7SSXjgr/++qtCjxOJRKwXWcrKysL59C8gT3r3/v374erq+uMVEOaSb+BoKMADmpqalJGR8a27ISAgwAEODg6kra1NWlpaZGtryxTCFd+qEm1tbaZOSmVQU1OjuLg4qfYbN25wVvNGQ0ODLl68KNUeHR1NGhoarPVPnTpF7dq147WoMt9jqIoCrxoaGjLrG1U15Wv68EWTJk0oKyuL1xh8j+N712cD3yUTKgrfz1FVvE7l/W6oKNX5dVRRhJ2sH4TOnTsjKioKZmZm37orAgICLKlOqRsk51V1U1NTmYffS0pKJKyY2WBgYCAznU5XV5e1UxtQ5i6Yn5+Ppk2bQkVFRerMBhfn1vgew9OnT+Hm5ibVPnLkSPzxxx+s9QHAxcUFiYmJvKVUVpSRI0dCR0dHrr/Nzs6GSCRi0livX7+Offv2wcbGBhMmTGAed/v2bU76KvBtiI2NRXh4OMLCwngpmVBR2rdvL9cZMAsLC8TGxsLAwECi/e3bt2jWrBnjPFsVr1N5vxtk8fbtW6lsic2bN6NWrVqcxfgWCIusH4SePXti7ty5uHXrlsxaKPLWlBAQEKh6qsKZj2/++OMPeHp6Yv369WjRogWAMhMMLy8v/Pnnn5zE+P333+Ht7Y3du3fD2NgYAJCTk4NZs2ZhwYIFrPWr4gwb32NwdnbGxYsXpRZAly5dQvv27VnrA0Dfvn0xffp03Lp1C3Z2dlLGF2y/f0JCQqClpYV27doBANavX4+tW7fCxsYG69evZxajGzdulDvG8OHDMWHCBIwaNQo5OTno2rUrmjRpgr179yInJwcLFy5kNYb/EpWZHHt7e1dYd/Xq1fJ2iUFPT4+TFNkvoaioiKdPn0oZ17x69QpGRkbM+cSzZ8/Kpf/w4UOZZxwLCgrw+PFjuTSrmpUrV8LMzAxDhgwBAAwePBhHjx6FsbExzp49y7g+Dh8+/Ft2kxOEOlk/CF+rLyEcPBYQ+P54+/Ytjhw5ggcPHmDWrFmoUaMG4uLiUKtWLZiYmFRZP+StVaKvr4/8/HwUFxdDSansep74588vAsm7IyQueFxQUIB69eoBALKysqCqqip1jqq6OmLxPYaqKPDK9/ePnZ0dVq5ciV69euHWrVv46aef4O3tjYiICDRu3JgTG3x9fX1cvXoVjRo1QmBgIA4ePIiYmBiEhYVh0qRJVVqbju/6QJXR59uYolOnThV6nEgkwoULFyqtX9UoKCggJydHapH15MkTNGjQQG7DkVOnTgEoy3IICgqS2P0uKSlBeHg4zp07xziUVgXyvk7Nzc2xd+9etG3bFufOncPgwYNx8OBBHDp0CFlZWQgLC+Opx1WPsJP1g1AV9SUEBASqhqSkJHTp0gW6urp4+PAhxo8fjxo1auDYsWPIyspCcHDwt+7iv1IVu0BVkVZZUlKC48ePS9jQ9+vXj1k4soXvMUyZMgUAsGHDBmzYsEHmfQC7xRDf3z8ZGRmwsbEBUGbk0adPHyxfvhxxcXHo1asXJzGKioqgqqoKoKy+pHjB2bhxYzx9+pSTGBWFTdpjRfjf//5XYfdSvo0pIiIiKv03XMB1yQTxYlQkEmHbtm3Q0tJi7ispKUF0dDQaN24st375z4nPDYyUlZVhZmYGf39/ufWrkpycHKZ+6+nTpzF48GB069YNZmZmaNWq1TfuHbcIiywBAQGBaoa3tzfGjBmDVatWQVtbm2nv1avXd5NCUVEnQz8/P5n5+BWhommV+/fvR15eXqVdsO7cuQNXV1fk5OQwDokrV66EoaEh/v77b04KvvI9hh/hApyKigry8/MBlC2AxGfMatSogffv33MSo0mTJti0aRN69+6Nc+fOYcmSJQDKdiA+P/8iL0lJSTLbRSIR1NTUUK9ePaiqqsqd9ije7fiSvqWlJczNzTFv3rwKa1ZFMeuqhK+SCeLFKBFh06ZNUFRUZO5TUVGBmZkZNm3aJHe/xe9jc3Nz3Lhxg7PX5LdAX18f2dnZMDU1RUhICJYuXQqg7Ln74bKuvqXrhgC3nD9/nnr37k0WFhZkYWFBvXv3pnPnzn3rbgkICFQSHR0dSktLIyJJh6WHDx+SqqpqlfalZ8+e9OTJE970+XaoYhOjdevW1LdvX3r9+jXT9vr1a3J1daU2bdpw2cV/he/nydbWlpUbWWRkJPXp04caNGhADRo0oL59+1J0dDQnfevbty91796dfH19SVlZmR49ekRERKGhoWRlZcVJjIiICNLT0yMFBQVyd3dn2ufNm0cDBgzgJIZIJCIFBYUv3lRVVcnNzY0+fvzISl8kEkncxG0KCgrUoUMHiddzdcLZ2Zk6der0xRsXDB48mKysrCgkJITevXtH7969o5CQEGrUqBENGTKEtb6zszO9efOGfUdlUFhYSC4uLpSSksKLfmWR18Hw119/pfr161OXLl3IwMCAPnz4QERE+/fvr3L3XL4RdrJ+EDZs2AAvLy/88ssv8PLyAlCWd9+rVy/89ddf+PXXX79xDwUEBCqKqqqqzCv0KSkpMDQ0lFu3Mlf9xelK8h7QrihUBceC5Y2RkJCAGzduSLj86evrY9myZfjpp5+46l6F4Pt5evjwoUw3yIqwZ88euLu7Y+DAgUzKWExMDDp37oxdu3ax3n1dt24dpkyZgiNHjmDjxo3MmcR//vkHPXr0YKUtxtnZGS9fvsT79+8l/t8TJkzgrFbd8ePHMWfOHMyaNQstW7YEUOZi6O/vj0WLFqG4uBhz587F77//Lpc5zLlz5zB//nwsW7ZMQn/BggX4/fffoauri4kTJ2LmzJnYvn27XGN49OgRTp06haysLBQWFkrcx9aYwsHBQeL3oqIiJCQk4Pbt23LV+JPF6dOnERoaypioAED37t2xdetW1q+loqIiZGVl4enTp3LtzP8bysrKX9wN5ZqKnAmW18Hwr7/+gpmZGbKzs7Fq1SomtfLp06cSKcw/BN94kSfAESYmJrR27Vqp9nXr1lGdOnW+QY8EBATkZezYsdS/f38qLCwkLS0tSk9Pp8zMTHJ0dCQvLy+5df/tSnr5W1VRFbVQ5I1hb29P4eHhUu3h4eFka2vLRdcqTHWubdS4cWNavXq1VLu/vz81btyYbdd+GH766ScKCQmRag8JCaGffvqJiIiOHz8ud/2yJk2aUExMjFT7pUuXyMbGhoiIzp07R6ampnLpnz9/njQ0NMjW1paUlJTIwcGB9PT0SFdXl7OdJlksWrSIZsyYwYmWqakpJSUlSbUnJiaSiYkJa/06derQ3bt3Wet8id9++43mzJnDmz5R2XNhaGhIlpaWpKSkxHwuzJ8/n0aNGsVr7B8NYSfrB+Ht27cyr8J069YNc+bM+QY9EhAQkBd/f3/88ssvMDIywsePH9GxY0fk5OSgTZs2WLZsmdy65Q+ZP3z4EHPnzsWYMWPQpk0bAMCVK1cQFBSEFStWsB7Dj8CKFSswbdo0LF68WMKZz9fXFytXrpTYGeTTqKC6k56ejr59+0q1u7q64n//+x8nMUpLS5GWlobnz59LnTPr0KGDXJqOjo4QiUQVeiwX7pS3bt1C/fr1pdrr16+PW7duASjbzZHXaOPBgwcyX4c6OjqMO6KVlRVevnwpl/68efMwc+ZM+Pj4QFtbG0ePHoWRkRFGjBjB2Y6iLEaOHImWLVtyUvqB75IJv/76K1auXIlt27ZxZo5TnuLiYuzYsQPnz5+XWa6HC5v7qjgTvHv3bmzevBnp6em4cuUK6tevjzVr1sDc3Bz9+vXjJEZ1QFhk/SC4urri+PHjmDVrlkT7yZMn0adPn2/UKwEBAXnQ1dXFuXPnEBMTg8TEROTm5qJZs2bo0qULK92OHTsyP/v6+mL16tUYNmwY0+bq6go7Ozts2bKFs/Sc7xnxZ+fgwYOZyTj9/7Q98aKCiP7zZTJMTU0RHh4uVYvr/PnzjIsYG65evYrhw4cjMzNTKm2SzXNf3rHt06dP2LBhA2xsbJiLDlevXsWdO3c4S2Fq3Lgx/Pz8sGXLFqioqAAoSzHz8/NjnOceP34sdwHW5s2bY9asWQgODmbSil+8eIHZs2cz6a2pqaly/0/u3buH/fv3AwCUlJTw8eNHaGlpwdfXF/369cPkyZPl0v03rly5AjU1NU60Nm7ciLS0NNSrV0+qZMKLFy+wefNm5rHyLKz5LnZ8+/ZtNGvWDEBZ+nh5KnrB4N+IjY2VeB7EmJiYICcnh7X+xo0bsXDhQvz2229YtmwZ8/7V09PDmjVrhEWWQPXDxsYGy5YtQ2RkpMQXRExMDGbMmCFR60Iem1UBAYGqx8nJCU5OTgDKdqu55MqVKzLdrlq0aIFx48ZxGut75VvZS39vzJgxA9OmTUNCQgLatm0LoOxM1q5duxAQEMBaf9KkSWjRogXOnDmD2rVrczaZLO/sOG7cOEybNo1xFSz/mOzsbE7irV+/Hq6urqhbty7s7e0BlO1ulZSU4PTp0wDKdgXlXdRt374d/fr1Q926dZmFVHZ2NiwsLHDy5EkAQG5uLn7//Xe59DU1NZlzWLVr18aDBw/QpEkTAJB7d6w8AwcOlPidiPD06VPcuHGDk10mgP+SCXwXO66KzyS+zgSLWbt2LbZu3Yr+/fvDz8+PaW/RogVmzpzJWr86IRQj/kEwNzev0ONEIlGVFlUUEBCoPCtXroSZmRmGDBkCoGwn5ejRozA2NsbZs2fRtGlT1jEaNWqEfv36YdWqVRLts2fPxsmTJ1kVtSwuLsa+ffvQvXv3f70q36tXL2zfvh21a9euVIySkhLExMTA3t7+Xw+Z29ra4p9//uFkV0UWU6ZMga+vL2rWrFmpv6tOY2BbAPf48ePw9/dn6olZW1tj1qxZnFyV1tTURGJiotROGZfo6urixo0bUgWgU1NT0aJFC7x7946TOB8+fMDevXuZXYhGjRph+PDhEmlZbCgtLUVYWJiEfteuXb9aMLqi9O/fH71798b48eMxc+ZMnDx5EmPGjMGxY8egr6+P8+fPs9J3d3eX+F1BQQGGhoZwcXFBt27dWGlXlv3798PV1bXSJROqkkePHgEA6taty6nuuHHj8OrVKxw6dAg1atRAUlISFBUV0b9/f3To0IF1DUR1dXXcv38f9evXl/jcSU1Nhb29vdwFm6sl3/JAmICAgICANGZmZswB9rCwMNLT06PQ0FAaO3Ysde3alZMYZ86cITU1NbK1taWxY8fS2LFjyc7OjtTU1OjMmTOs9dXV1enhw4cc9PTLqKqqUnp6Oq8xKgIbe3U+x1AZy+e9e/dSbm4uL/1gS6dOneiff/7hNUatWrVo586dUu07d+4kIyMjTmLIa81eUdhY8FeEBw8eUGJiIhER5ebm0sSJE8nOzo4GDhwo93s9ICCAeV4yMzOppKSEs/6ygW3JhOfPn9PFixfp4sWL9Pz5c876VVJSQj4+PqSjo8OYFOnq6pKvry9nz93bt2+pS5cupKenR4qKimRqakrKysrUoUMHTj4jrK2t6cSJE0QkabgTGBgoWLgLfN/o6OggISFB7quVAgIC/JOTk8PsWJw+fRqDBw9Gt27dYGZmhlatWnESo1evXkhNTcXGjRuZ3Ye+ffti0qRJnOyWtGzZEgkJCTIP+nOFra0t0tPTK7yTzxfEIiGEzzFUxvJZngPtb968wZ49ezB69Ggpw4V3794hODhY5n2VxdPTEzNmzEBOTg7s7OygrKwscb849Y4Nv/32GyZPnoy4uDjG/vzatWvYsWMHZ6lqRkZGGDBgAEaOHInOnTtzsrtUHjMzM7Rr1w4jR47EL7/8ImFFzwXl5w2ampqsiuuK8fb2xtChQ6GmpgZzc3M8ffoURkZGrHXZIu97Oi8vD56enggODmYMWhQVFeHm5oa1a9eyLgcwf/58bN++HX5+fkwq+aVLl7B48WJ8+vSJlTGSGPGZ4EuXLiEpKYmzM8FivL298euvv+LTp08gIly/fh379+/HihUrsG3bNk5iVBu+8SJPoIqpCrtkAQEBdtSuXZvZyWrYsCEdOnSIiIju379P2trarPWroqjlwYMHycLCgtauXUuXL1+mxMREiRsX/PPPP+Tg4EB///03PXnyhCkuKr5VFWw+V/keA5+Wz76+vvTLL7988f5BgwbR0qVLWcf5vLju5wV2ueLgwYPUtm1b0tfXJ319fWrbti0dPHiQM/1jx47RL7/8Qurq6mRsbExeXl4UGxvLmX5cXBzNnDmT6tatS6qqqtSvXz86fPgwffr0iRN9c3NzevnypVT7mzdvyNzcXC5NU1NT2rBhAz18+JBEIhHdvHmTMjMzZd6qEnnf0xMmTCALCws6e/Ys8x4+c+YMNWjQgCZNmsS6X7Vr16aTJ09KtZ84ceK7KtezZ88esrS0ZN7PJiYmtG3btm/dLc4RzmT9x2Cbdy8gIMA/U6dOxenTp2FlZYX4+Hg8fPgQWlpaOHDgAFatWsWJnbShoSEuX74sdQaFK2RdpReJRJy68ZWPUd4MgcsYFYHN5yrfYxBfVbeysuLc8tnBwQH+/v7o3LmzzPvDw8Mxc+ZMxMfHyx0DADIzM796P9vd0uLiYixfvhweHh6cn2+RxYcPH3DkyBHs378fFy5cgIWFBUaOHImFCxdyok9EiIyMxL59+3D06FGUlpZi4MCB2LFjBytdBQUF5OTkSO00PXv2DPXq1UNBQUGlNbds2QJPT08UFxd/8TFV/X4G5H9P16xZE0eOHIGzs7NEe0REBAYPHowXL16w6peamhqSkpLQsGFDifbk5GQ4ODhwcp6pvFFaeUQiEdTU1GBpaYkOHTpAUVGRdaz8/Hzk5uZWi91LPhAWWf8xhEWWgED1p6ioCAEBAcjOzsaYMWPg6OgIAPjrr7+gra3Nifvf9OnToaqqKuHuxCV8T4wBICoq6qv3l7es5xM2n6t8j6FTp05fvE8kEuHChQtya2tra+POnTuMFfbnZGVlwdbWVqZTWXVDS0sLt2/fhpmZWZXGvXv3LkaMGIGkpCReFhFxcXEYO3YsK/1Tp04BKDO+CAoKgq6uLnNfSUkJwsPDce7cObnNcj58+IDMzEzY29vj/PnzMDAwkPk4Lgx/Koq872kNDQ3cvHkT1tbWEu137txBy5YtkZeXx6pfrVq1QqtWraQWQp6enoiNjcXVq1dZ6QNlRmovXrxAfn4+k3L65s0baGhoQEtLC8+fP4eFhQUiIiLkSi3/+PEjiIhJnczMzMTx48dhY2NT5QYnvPOtttAEvg1CuqCAwI9Dr1696MmTJ3L97dSpU0lHR4eaN29OEyZMoOnTp0vcBCrOf/VzVVdXl65cufLF+69cuUK6urqcxEpLS6OpU6dS586dqXPnzuTp6UlpaWmcaBMRubq60q5duzjT+xofP36kgwcPUr9+/UhVVZXq1avHaUpndnY2rVy5kpo2bUqKiorUrl072rhxo9x6n6dolr+pqKhQw4YN6e+//2bd7127dlUotXHfvn28m7TI+552cXGhQYMGSZic5Ofn06BBg6hz586s+xUZGUmamppkbW1NHh4e5OHhQdbW1qSlpUXR0dGs9YnKnl9nZ2eJ91dqaiq5uLjQgQMHKDs7m5ycnOjnn3+WS79r167M6/HNmzdkZGREdevWJTU1NdqwYQMnY6guCIus/xhsHXMEBASqD2wm987Ozl+8derUiZP+BQcHU9u2bal27dqM+9hff/3FOEtxQXR0NI0YMYLatGlDjx49YuJevHiRlW5RURH5+PhQdnb2vz520qRJ9OLFC7lj8TWG8qSmplJISAjl5+cTEVFpaSlrTWdn568uDmbPnk3Ozs6s44SEhJCKigq1bNmSuQjQsmVLUlVVpbCwMNb6REQbN24kY2NjmjFjBu3bt49OnjwpceOCkJAQcnNzIx0dHapRowZNmDCBoqKiONEmItq0aRN16NCBFBUVqUmTJrR8+XJOHT7NzMxYvc65oirmMU2aNJHLrTEpKYnq1KlDBgYG5OLiQi4uLmRgYEAmJiZ0+/ZtTvr2+PFj+t///kcDBw6kgQMH0vz58+nx48ecaBMRWVhYUHx8vFR7XFwcc/YuJiaGjI2N5dI3MDBgnoutW7eSvb09lZSU0KFDh6hx48Zy97s6Iiyy/mP8V6+4Cgj8iFTn9/OGDRuoZs2atHTpUlJXV2f6uXPnTk4m3kRER44cIXV1dRo3bhypqqoyMdauXUs9e/Zkra+lpUUZGRmsdb4G32N4+fIlubi4MDsRYn13d3fy9vZm3XclJSVau3YtFRcXM+3FxcUUGBhIysrKdPjwYVYxiIgcHBxkLubmzJnDmeWzLHON8js4XKCurk6DBg2iEydOUGFhISea5albty7NmjWLEhISONeuTnDxuVdQUEDZ2dm8mGvk5eXRli1byNvbm7y9vWnr1q3MxQ15GDBgAGOCExQUxJmRyZdQV1eXachy/fp1UldXJyKijIwM0tTUlFtf/FwPGjSIFi9eTERlJQjE+j8KwiLrB6CwsJAsLCzo7t27//rYixcv8v4GFRAQqBq4WmRlZ2dXaMemMlhbW9Px48eJSLKft27dIgMDA05iODg4UFBQkFSMuLg4qlWrFmv9qkgh43sMo0aNou7du1N2draEfkhICNnY2LDW/9///kcikYh0dHTIwcGBHBwcmBo+XKXAqaqqynTCTE5OJlVVVU5iVAXv37/nVZ+L3cl/IzIykvr06UMNGjSgBg0aUN++fTlLU6sobD73UlJSqF27dkyNKfGNzWLa0dGRXr9+TUREPj4+lJeXJ5fOl1BWVmbSwhUUFOjZs2ec6n9Or169qFmzZhQXF8e0xcXFUfPmzal3795ERHTq1CmytbWVS9/Ozo4CAgIoKyuLdHR06PLly0REdOPGDU4+86oTQp2sHwBlZWV8+vSpQo9t164dz70REBD4HigtLcXSpUvh7++P3NxcAGWHvWfMmIH58+ezruGTkZHBGHaUR1VVlfXhbzHJycno0KGDVLuuri7evn3LWr9nz56YO3cubt26JdOZz9XVlXUMvscQFhaG0NBQKdc8KyurfzUnqQjLli1Dv379sHfvXqSlpYGI0LFjRwwfPpypN8UWQ0NDJCQkSDlhJiQkfFeuZNra2szPnz59QmFhocT9bOuJid0p8/PzkZWVJaXPtp7Ynj174O7ujoEDB2LatGkAgJiYGHTu3Bm7du2Sq9ZaVTNmzBgoKSnh9OnTqF27toSjp7zcu3cPeXl50NfXh4+PDyZNmsS6HlZ5GjdujHnz5qFTp04gIhw6dOiLrxU3NzfW8bZv345Ro0ahefPmTE264uJidO7cGdu3bwdQZhTj7+8vl/7ChQsxfPhwTJ8+HS4uLmjTpg2Ass8qWd8Z3zPCIusH4ddff8XKlSuxbds2KCkJ/1YBAYGvw3dRS3Nzc5nFiENCQqSct+TF2NgYaWlpUo5wly5d4sRBdcqUKQBk25xzZSnN9xjy8vJkTvhev34NVVVV1vpAWeFprhZUshg/fjwmTJiA9PR0tG3bFkDZ5H7lypXw9vbmLE5UVBT+/PNPpji3jY0NZs2ahfbt23Oin5eXhzlz5uDQoUN49eqV1P1sX08vXrzAmDFjEBISIvN+tvrLli3DqlWrMH36dKZt2rRpWL16NZYsWfJdLLISEhJw8+ZNNG7cmDNNBwcHuLu7o127diAi/Pnnn9DS0pL5WHls+jdt2gRvb2+cOXMGIpEIv//+u8zFoUgk4mSRZWxsjHPnzuH+/ftISUkBADRq1AiNGjViHvM119J/45dffkG7du3w9OlTCcfIzp07Y8CAAfJ3vDryjXfSBDiif//+pK2tTbVr16Zu3brRgAEDJG4CAgI/HmzSZvguarl161YyMTGhAwcOkKamJu3fv5+WLl3K/MwFy5cvJxsbG7p69Sppa2vTxYsXac+ePWRoaEiBgYGcxOAbvsfQs2dP+v3334mo7PWSnp5OJSUlNGjQILndwWTBp3lHaWkprV69mkxMTCSKl65Zs4azFLndu3eTkpISDR48mAICAiggIIAGDx5MysrKtHfvXk5iTJkyhaytrZlzeDt27KAlS5ZQ3bp1ac+ePaz1hw8fTk5OThQbG0uampoUFhZGu3fvpkaNGtHp06dZ66uoqFBqaqpUe2pqapWmbbL53GvRogWnhjJEZUXihwwZQi1atCAFBQWytbVlUmfL37g4PygSiXhPF6wq+DDjqW4Ii6wfhDFjxnz1JiAg8H1QWFhI7u7ulJ6e/q+PXb58Ob1580auOKqqqpScnCzVfv/+fVJTU5NL83P27NlDlpaWEhPjbdu2caJNVPalLF64iWOoqakxiwouKW/JzCV8j+HWrVtkZGREPXr0IBUVFfrll1/I2tqaatWqxZkFOt/mHeV5//49L2ebGjduTKtXr5Zq9/f358zxzNTUlCIiIoiozCFPvGAJDg7m5HkyNjama9euMfri9/fJkyfJycmJtX6DBg1o06ZNUu0bN24kS0tL1voVRV7nPyKi8PBwatOmDUVERNDLly/p3bt3Eje28L0IevjwYZUsRrKzs2n9+vU0Z84czst78GnGU90QihELCAgIVDN0dXWRkJAAc3Nz3mJURVFLMfn5+cjNzeXt/ExhYSHS0tKQm5sLGxubL6bqVJaSkhIsX74cmzZtwrNnz5CSkgILCwssWLAAZmZmGDt2LCdxAP7GAADv3r3DunXrkJiYiNzcXDRr1gy//vorateuzYm+o6Mjpk+fDjc3N4kirvHx8ejZsydycnI4icMnqqqquHPnDiwtLSXa09LSYGtrW+Fzz19DS0sLd+/eRb169VC3bl0cO3YMLVu2REZGBuzs7JizkfKio6ODpKQkmJmZoX79+ti3bx+cnJyQkZGBJk2aID8/n5X+xo0b8dtvv8HDw0MibXPXrl0ICAjAxIkTWemLKSwsxPPnz1FaWirR/qWi15VBfNb083Q7IuIsBZhvPn36hKSkJJnPERfnRMPDw+Hq6goLCwvcv38ftra2ePjwIYgIzZo1Y1XAHCg7N/b8+XNs27YN1tbWzOdFaGgovL29cefOHdZjqC4Ih3d+IIqLixEZGYkHDx5g+PDh0NbWxpMnT6Cjo8PpF7aAgAC/9O/fHydOnJA4+8A1q1atQu/evXH+/Hnm4PGVK1eQnZ2Ns2fPchbn+fPnSE5OBlA2sTE0NORMW4yKigq0tbWhra3N6WfdsmXLEBQUhFWrVmH8+PFMu62tLdasWcPpIouvMQBli/b58+dzqlkePsw7mjVrhvDwcOjr68PR0fGrBgVxcXFyxSiPqakpwsPDpRZZ58+fh6mpKWt9ALCwsEBGRgbq1auHxo0b49ChQ2jZsiX+/vtv6OnpsdZv1KgRkpOTYWZmhqZNm2Lz5s0wMzPDpk2bOFlQT548GcbGxvD398ehQ4cAANbW1jh48CD69evHWj81NRUeHh64fPmyRDuXC6CIiAjWGv/GkydPcOnSJZmLILFhiLyEhITAzc0NL1++lLqPq+do3rx5mDlzJnx8fKCtrY2jR4/CyMgII0aMQI8ePVjr823GU50QFlk/CJmZmejRoweysrJQUFCArl27QltbGytXrkRBQQE2bdr0rbsoICBQQaysrODr64uYmBiZrnZsv6gBoGPHjkhOTsaGDRtw//59AMDAgQMxZcoU1KlTh7X+hw8fMGXKFOzfv5+ZaCgqKmLIkCFYv349dHV1WccoLi6Gj48PAgMDmV0ALS0teHp6YtGiRYwzlrwEBwdjy5Yt6Ny5MyZNmsS0N23alHnO2ML3GADgzZs32L59u4Shg7u7O2rUqMFaG+DHvKNfv36MMUe/fv04cYH7GjNmzMC0adOQkJAgc5eGC9zd3ZGYmIiOHTti7ty56Nu3L9atW4eioiKZ5iqVxcvLC0+fPgUALFq0CD169MDevXuhoqKCXbt2sdYHgAEDBvBmTsCH89/ndOzYkXPN8uzatQsTJ06EiooKDAwMJMYgEolYf3Z7enpi0KBBWLhwIWrVqsW2uzK5d+8e9u/fDwBQUlLCx48foaWlBV9fX/Tr1w+TJ09mpV8VZjzVhm+arCjAGf369aORI0dSQUGBxKHQiIiIKs2VFhAQYI+ZmdkXb+bm5t+6exVi8ODBZGVlRSEhIcx5h5CQEGrUqBENGTKEkxiTJk0iIyMj2rRpEyUmJlJiYiJt2rSJjI2NadKkSaz11dTU6OHDh0Qkedj+zp07chfi/By+xxAVFUU6OjpkamrKGCHVq1ePdHR0KCoqioMR/BgGJEREx44dIycnJ6pRowbVqFGDnJyc6MSJE7zFe/jwIR09epQSExN50c/Ly6ObN2/SixcvONEzNzenly9fSrW/efOGk88lDQ0NunfvHmudf4NPk5a6devS0qVLqaSkhLWWLLS1tTk7S/klatWqxdRdtba2ZgySEhISOPncqyoznuqAsMj6QahRowbdv3+fiCQnAxkZGT9cBW0BAQH2tG/fnhYsWEDh4eG8mDpoaGjInLRER0eThoYGJzF0dHTo7NmzUu1nzpwhHR0d1vrNmjWj3bt3E5Hk56qPjw+1a9eOtT4R/2OwtbWl8ePHU3FxMdNWXFxMEyZMkLuY6Ofwbd7B9+S+umFrayu3sUNF0NbWlsud70umDjk5OaSiosK6X3w4/30O3yYtNWrU4HUR5O7uzql5kCz69etHW7ZsISKiGTNmkKWlJS1dupSaNWtGnTt3Zq1fFWY81QUhXfAHobS0VGYu7qNHjyQKIAoICHw/FBYWIiMjAw0aNOC8/l23bt0QHR2N1atXo7i4GC1atICzszM6duwIJycn1sU0DQwMZKYE6urqQl9fn5W2GFVVVakUNaCsRpeKigpr/YULF2L06NF4/PgxSktLcezYMSQnJyM4OBinT59mrQ/wP4a0tDQcOXIEioqKTJuioiK8vb0RHBzMWh8oS4OaP38+Zs2axYt5x8OHD2V+vxUUFODRo0ecxFi4cCE6deqENm3aQE1NjRNNeXn48CGKiop406dK+p2dOnWK+Tk0NFTifV1SUoLw8HCZr+HKsnLlSsyePRvLly+HnZ2dVKos22LNALB06VJs2rQJbm5uOHDgANPu5OSEpUuXstYfO3YsDh8+jLlz57LWksW6deswaNAgXLx4UeZzxEUq+erVq5nUZR8fH+Tm5uLgwYOwsrLiJK3V1tYWKSkpWLduHbS1tZGbm4uBAwdyasZTXRDcBX8QhgwZAl1dXWzZsgXa2tpISkqCoaEh+vXrh3r16mHnzp3fuosCAgIVJD8/H56enggKCgIAxtXO09MTJiYmnH6BFxcXIzY2FlFRUYiMjMSFCxegoKDA2k1ty5YtOHz4MHbv3g1jY2MAQE5ODkaPHo2BAwdy4kTm6+uL+/fvY+fOnUwuf0FBAcaOHQsrKyssWrSIdYyLFy/C19dXwplv4cKF6NatG2ttgP8xODk5YdasWejfv79E+4kTJ+Dn58epiyTXiCf3/fv3R1BQkMzJ/blz5xhjFTZ07doVV65cQXFxMX766Sd07NgRzs7OcHJygrq6Omv9ylDeobE66Jd35Pt8yqisrAwzMzP4+/ujT58+rPpVFc5/GhoauHv3LszMzCSeh/T0dNjY2LD+3CspKUGfPn3w8eNHmYsgtouU7du3Y9KkSVBTU5N55is9PZ2VvgC3CDtZPwj+/v7o3r078yExfPhwpKamombNmswBRgEBge+DefPmITExEZGRkRJuTl26dMHixYs5XWSlp6fj1q1bSExMRFJSErS1tWU6xVWWjRs3Ii0tDfXq1WOsl7OysqCqqooXL15g8+bNzGPldYeLj49HeHg46tati6ZNmwIAEhMTUVhYiM6dO2PgwIHMY48dOyZXjPbt2+PcuXNy/W1F4HsM06ZNg5eXF9LS0tC6dWsAwNWrV7F+/Xr4+fkhKSmJeay9vX2Fdcv369+Q97kXLwxFIhFGjx4tcV/5yT0XnDt3DsXFxbh27Rqio6MRFRWFwMBAFBQU4KeffsKlS5c4ifM9IjauMTc3R2xsLGrWrMlLnKpw/uPDpKU8K1asQGhoKBo1agQAUosgtsyfPx8+Pj6YO3cusyjlmuzsbIhEIsb97/r169i3bx9sbGwwYcIETmK8ffsW169fl+nA6ObmxkmM6oCwyPpBqFu3LhITE3Hw4EHmiuvYsWMxYsSIKr8KJyAgwI4TJ07g4MGDaN26tcQXc5MmTfDgwQNOYgwfPhxRUVEoKChAhw4dGMcze3t7TiYDn++c8IGenh5+/vlniTau7LbLc+PGDQlnvubNm3OmzfcYhg0bBgCYPXu2zPvEuxOV3Skov6tERDh+/Dh0dXXRokULAMDNmzfx9u3bSi3GPqeqJvdilJSU4OTkBENDQ9SoUQPa2to4ceIEZ06S3zsZGRkVepydnR3Onj1b6dcx385/ADB+/Hh4eXlhx44dEIlEePLkCa5cuYKZM2diwYIFrPX9/f2xY8cOjBkzhn1nZVBYWIghQ4bwtsACyr4bJkyYgFGjRiEnJwddunSBra0t9u7di5ycHCxcuJCV/t9//40RI0YgNzcXOjo6UgvRH2mRJRhfCAgICFQz1NXVmQPZ5Q0XEhISODFDICo7xG5oaEhz5syh0NBQysvL40S3suzbt49yc3N5jXHp0iX69OlTpf8uOzub2rVrRyKRiPT19UlfX59EIhE5OTlRdnY2Dz39MvKO4eHDhxW+ycvs2bNp3LhxMs01Zs6cKbduVbJ582YaNmwY1alThwwMDKh///60Zs0aSkhIoNLS0irtS/n3PB/Ia3xRUdj0n0/nPyL+TVpq1apFKSkpnGjJ4rfffqNly5bxpk9EpKenxxipBQQEUNu2bYmIKDQ0lBOjGSsrK/Ly8vpm3zlVibDI+kHYtWsXnT59mvl91qxZpKurS23atGH15SkgIFD1tG/fnrG+FlvcEhFNnTqVunfvzkmM169f08mTJ2n69OnUrFkzUldXpzZt2tC8efMoNDSUkxgVge8JH5sY3bt3p1atWjETDiKi+/fvU5s2bTj7P1QUvp+nXr160ZMnT+T625o1a0o8R2Lu379PNWrUYNs18vT0pICAAKn2tWvXkpeXF2t9orKLDkZGRrRy5Ur68OEDJ5rywvciq7rq8+38V56CggK6c+cOXbt2jdP/9/Lly8nT05Mzvc/x9PQkXV1d6tChA02dOpWmT58uceMCTU1NysjIICKivn37kp+fHxERZWZmkpqaGmt9DQ0N3j/zqwvCIusHoWHDhhQeHk5ERJcvXyZ1dXXavHkz9e3blwYMGPCNeycgIFAZLl68SFpaWjRp0iRSU1MjLy8v6tq1K2lqatKNGzd4iZmamkqjR48mJSUlUlBQ4CWGLPie8LGJoaamRnFxcVLtN27cqPLSGNV1YkxUduVbVj2pEydOkJ6eHtuuUZ06dWS+7m/evEkmJias9YmIjh8/TtOnTydHR0dSU1OTuODA1RX3oKAgmbuRBQUFFBQUxPy+d+9eVru7BQUFdP/+fSoqKpJ5/8WLF+XaFa0o8r6WHBwcmOehvEZcXBzVqlWL0z6mpqZSSEgI5efnExFxtlvZv39/0tHRIXNzc+rTpw9Tm058Y4uzs/MXb506deJgBEQtW7akOXPmUHR0NKmpqVFCQgIREV25coWT99uAAQPo4MGDrHW+B4QzWT8I2dnZsLS0BFB2nuOXX37BhAkT4OTkBGdn52/bOQEBgUrRrl07JCQkwM/PD3Z2dggLC0OzZs1w5coV2NnZcRLj1atXjKNgZGQk7t69Cz09PfTt27dKzkZ8D5iamsq00i4pKUGdOnW+QY+qJ+7u7hg7diwePHiAli1bAgCuXbsGPz8/uLu7s9Z/9eqVzHIAOjo6ePnyJWt9oOwMofgc4bt373Dx4kUcPnwYffr04cRtEyh7nnr06AEjIyOJ9g8fPsDd3Z05izJ8+HC59CvqStquXTsWo+CP5ORkmaY7urq6ePv2LScxXr16hcGDByMiIgIikQipqamwsLDA2LFjoa+vz9pIRU9Pj9U5xH+jKsxBVq5ciQEDBuCPP/7A6NGjGUOeU6dOMe/vylK+DEDv3r0xa9Ys3L17V6YDo6urq/ydr25861WeADcYGhoyV1wdHBwoODiYiIjS0tI4qdAtICDwY6GgoEBGRkb0888/U2BgICUlJX2TflTnnawTJ05Qy5YtKTY2lmmLjY2l1q1b0/Hjxzns4b9TnXeySkpKaOXKlVSnTh3mnEudOnVo5cqVEue05KVJkya0du1aqfbAwECytrZmrS/m5cuXdPToUfL09CQ7OztSUFBgzmdxgUgkoufPn0u1JyQkkL6+Pmv9adOmUfPmzenixYukqanJ/D9PnDhBDg4OrPUriryvJXNzczp37pyURlBQEGf/51GjRlH37t0pOztbIkZISAjZ2NhwEqOqyM7O5u1saHFxMb1+/VqiLSMjQ2Yx6oog/lz4t1tVZlFUBcJO1g9C165dMW7cODg6OiIlJQW9evUCANy5c4eTIoECAgJVS0lJCY4fPy7hatevXz/OihInJSWhSZMm//q4mJgYtGjRgqnh9F9izJgxyM/PR6tWrZjnvbi4GEpKSvDw8ICHhwfz2NevX3+rbn5zFBQUMHv2bMyePRvv378HwE3hWDHe3t6YOnUqXrx4ARcXFwBAeHg4/P39sWbNGk5i2NnZ4d69e9DX10eHDh0wfvx4dOzYsVK29l/C0dERIpEIIpEInTt3lngPl5SUICMjQ6JUg7xUhSspn/Dt/AcAYWFhCA0NZezJxVhZWSEzM5OTGADw4sULpn5bo0aNYGhoyIluaWkpli5dCn9/f6ZgsLa2NmbMmIH58+dz4jr48eNHEBFTND4zMxPHjx+HtbU1unfvLne//4sIi6wfhPXr1+P3339HdnY2jh49CgMDAwBlNrpiC18BAYHvgzt37sDV1RU5OTlMvZWVK1fC0NAQf//9N2xtbVnHqMgCCwB69uyJhIQE3gqjVgXyWtJzNYHnAi5s9fmm/MSycePGnFmue3h4oKCgAMuWLcOSJUsAAGZmZti4cSNnds+TJk1Cx44dOXlvfY44DTEhIQHdu3eHlpYWc5+KigrMzMykbPzl4cWLF1KpiACQl5dXpa+fzZs3o1atWpX+u7lz56K0tBSdO3dGfn4+OnToAFVVVcycOROenp6c9C0vLw8aGhpS7a9fv+bkQlJeXh48PT0RHBzMLCwUFRXh5uaGtWvXyoxdGebPn4/t27fDz88PTk5OAMpqfC1evBifPn3CsmXLWI+hX79+GDhwICZNmoS3b9+iVatWUFZWxsuXL7F69WpMnjyZlX5wcDCGDBki9XwXFhbiwIEDgoW7gICAgAB/tG7dmvr27SuRrvH69WtydXWlNm3aVGlf+E5Ta9KkCWVlZfGmT8T/GFasWEFv3rzhTZ+oeqcL5ubmkru7OykqKjJpP0pKSuTh4cG5TfPz58+/qfsfG5fHXbt20cePHznu0f9RFa6k58+fp3nz5tHYsWPJ3d1d4sYVfDn/ERH17NmTsWsXP0clJSU0aNAg+vnnn1nrT5gwgSwsLOjs2bP07t07evfuHZ05c4YaNGhAkyZNYq1fu3ZtOnnypFT7iRMnqE6dOqz1iYgMDAzo9u3bRES0detWsre3p5KSEjp06BA1btyYtb6CgoLMtMOXL1/+cOmCwiLrByEqKuqrNwEBge8HNTU15kuuPLdu3eLEQrcysDlf8fLlS6n2N2/ecFJrhYioU6dOMhc3796948xpqyKwmXjzPYaoqCiZLnNFRUUS3w3Lly+Xe6HI98SyOsHFYjc2NpaCg4MpODiYU7dQvl1JFy9eTAoKCtSyZUvq168f9e/fX+LGFXw5/xGVfYYaGRlRjx49SEVFhX755ReytramWrVqUVpaGmt9AwMDioiIkGq/cOEC1axZk7W+qqoqJScnS7Xfv3+fs+8GdXV1yszMJCKiQYMG0eLFi4mIKCsrixNXVb7PJlYnhEXWD8KXDhCKbwICAt8P9vb2TEmG8oSHh5OtrW2V9kXeSaVIJJJ5tTInJ4dUVFS46NoXYzx79oyUlJQ4iVER2Ey8+R5DVVw15ntimZOTQyNHjqTatWuToqKixHdbVX+/sflfP3r0iPfi1mlpaTRu3Dj66aefyNramkaMGMGZqY2xsTFjqsUHL1++JBcXF2b+In6e3d3dydvbm7M4b9++paVLl9KgQYOoZ8+eNH/+fLlrxH2Ouro63b17V6r99u3bpKGhwVq/ZcuWMutwTZ06lVq1asVan4jIzs6OAgICKCsri3R0dOjy5ctEVFa6go2VvoODAzk6OpKCggLZ2dmRo6Mjc7O3tydtbW0aNGgQJ2OoLghnsn4Q3rx5I/F7UVER4uPjsWDBAk5ydAUEBKqOFStWYNq0aVi8eDFat24NALh69Sp8fX2xcuVKxlwA4NZggAvKW/WGhoZKWG+XlJQgPDyctRlPUlIS8/Pdu3eRk5MjESMkJAQmJiasYvBNVY2BiGSex3n16hU0NTVZ6wNl1uGyzuAYGRkhPz+ftf6YMWOQlZWFBQsWoHbt2t/F+TRZjB07FkVFRbh37x5z1jI5ORnu7u4YN24cQkJCWMdo0KABtm7dylpHFoWFhWjbti0v2gAwffp0KCsrIysrC9bW1kz7kCFD4O3tzdpeXYyuri7mz5/PidbntGnTBosWLUJwcDDU1NQAlBlJ+Pj4oE2bNqz1V61ahd69e+P8+fOM3pUrV5CdnY2zZ8+y1geAhQsXYvjw4Zg+fTpcXFyYOGFhYXB0dJRbt6rOJlYnRERE37oTAvwRFRUFb29v3Lx581t3RUBAoIKUd4gSTyjFH9XlfxeJRCgpKeG1Lzo6OpUyvhD3XSQS4fOvF2VlZZiZmcHf3x99+vSRu08KCgpSz0t51NXVsXbtWgn3Pz7R1tZGYmJipcxB+B6DuFbPyZMn0aNHD4lD5iUlJUhKSkKjRo04mdh37twZBgYGUhPL0aNH4/Xr1zh//jwrfW1tbVy8eBEODg6s+8oWef7XYtTV1XH58mWpierNmzfRvn171gvSuLg4KCsrM7X0Tp48iZ07d8LGxgaLFy+GiooKK/05c+ZAS0uLM6e/zzE2NkZoaCiaNm0q8Tynp6fD3t6ecdNjQ4cOHeDs7AxnZ2e0bduWeb1yxe3bt9G9e3cUFBQw9aUSExOhpqaG0NDQChsOfY3Hjx9jw4YNuH//PgDA2toaU6ZM4bR2X05ODp4+fYqmTZsyn+nXr1+Hjo4OGjduzEo7KCgIQ4YM4fy5r44IO1k/OLVq1WLcngQEBL4PqqLgZEWp7HU4saOWubk5YmNjOXOYK09GRgaICBYWFrh+/bqEPbKKigqMjIygqKjIeVwu4XsM4h1EIoK2tjbU1dUl9Fu3bo3x48fLP4ByBAQEoHv37qhbt67MiSVbTE1NK/065As2u2h8F7eeOHEi5s6dCzs7O6Snp2PIkCEYOHAgDh8+jPz8fNZumZ8+fcKWLVtw/vx52NvbSxWRXb16NSt9vp3/AKBbt26Ijo7G6tWrUVxcjBYtWsDZ2RkdO3aEk5MTa/c/W1tbpKamYu/evcwiaNiwYRgxYoTEe5ANJiYmvGcoGRsbIzc3F+fOnUOHDh2grq6On376iZNd5NGjRwMo2xl9/vy5lL17vXr1WMeoLgg7WT8I5VNPgLIv1qdPn8LPzw/FxcW4dOnSN+qZgIAAX0yZMgW+vr5yL2SKi4sRGRmJBw8eYPjw4dDW1saTJ0+go6Mjkcoh8HXY7G7wjY+PD2bOnMlZauCXyM/Pl5hYWltbczaxDAsLg7+/PzZv3vzN6z6y+V+fPHkSy5cvx/r169GiRQsAwI0bN+Dp6Yk5c+Yw6VTyoquri7i4ODRo0AArV67EhQsXEBoaipiYGAwdOhTZ2dms9Dt16vTF+0QiES5cuMBKv1evXmjevDmWLFkCbW1tJCUloX79+hg6dChKS0tx5MgRVvrlKS4uRmxsLKKiohAZGYkLFy5AQUEBnz594iwGH+zcuRNaWloYNGiQRLt4IS1ewLDh1atXGDx4MCIiIiASiZCamgoLCwt4eHhAX1+fddpmamoqPDw8cPnyZYn2qsrOqEqERdYPgjj15PN/Z+vWrbFjxw7W27sCAgLVj8qm8pUnMzMTPXr0QFZWFgoKCpCSkgILCwt4eXmhoKAAmzZtYt2/8PBwhIeHy7xauWPHDtb6QNkXdkREhMwYCxcu5CTGv9GrVy9s374dtWvXluvvq8MYqjP6+vrIz89HcXExNDQ0pHZQuCwEXVhYiIyMDDRo0EBm4e9Lly7hp59+kmtnpfw4Pi9u/fkiWJ4x6ejo4ObNm7CyskLXrl3Rp08feHl5ISsrC40aNcLHjx8rrVmV3L59G507d0azZs1w4cIFuLq64s6dO3j9+jViYmLQoEEDzmKlpKQgMjISERERiIqKQkFBATp06IDjx4+z0l2xYgVq1aollea7Y8cOvHjxAnPmzGGl37BhQ2zevFlqwRsVFYUJEyZwkrnk5uaG58+fY9u2bbC2tmYuKoSGhsLb2xt37txhpe/k5AQlJSXMnTtX5hlL8W74j4CQLviDkJGRIfG7goICDA0N/xM5rwIC/1XYXCPz8vJCixYtkJiYyBQvB4ABAwZwkkbm4+MDX19ftGjRgjezgq1bt2Ly5MmoWbMmjI2NJWKIRCLWCxRFRUU8ffpUqsDrq1evYGRkxFxxZXPgnO8xPHv2DDNnzmQWu5+/Zri4asz3xLIqikLn5+fD09MTQUFBAMBcdPD09ISJiQnmzp0LAGjXrp3cMfgeR4sWLbB06VJ06dIFUVFR2LhxI4Cy+YE8xYG/xqNHjwAAdevW5UzT1tYWKSkpWLduHbS1tZGbm4uBAwfi119/lfsCxucMHz5cYlHVsWNHzJ07F/b29px8Rm3evBn79u2Tam/SpAmGDh3K+r2QlZUFc3Nzqfb69esjKyuLlbaYsLAwhIaGSv1vrayskJmZyVo/ISEBN2/e/G9c/K9KK0MBfvn111/p1atX37obAgICVQQbO+kaNWrQ/fv3pXQyMjI4qYXCt90zEVG9evXIz8+PN/0v2as/fvyYs5o0fI+hR48eZGNjQxs2bKDjx4/TiRMnJG5cUL9+fYqJiZFqv3r1KpmZmXESg2+mTZtGzZs3p4sXL5Kmpibzfjhx4gQ5ODh8495VjMTERLK1tSUdHR2mthFRmb33sGHDWOuXlJSQj48P6ejoMPb5urq65OvrSyUlJaz1qwKRSESGhoY0Z84cCg0N5bxYtqqqKlMEujwPHjwgVVVV1vqmpqZfLEZsYmLCWp+o7PsgJSWF+Vn8XoiNjaUaNWqw1m/RogVdvHiRtc73gLCT9Z3z6NEj5mrDvn37MHv2bNSoUQN2dnY4e/YsTE1Nv3EPBQQEqiOlpaUydzEePXoEbW1t1vp82z0DZaUrPj+bwAWBgYEAynaStm3bJnE+raSkBNHR0ZxdheVrDGIuXbrEuzNfTk6OzJ0GQ0NDPH36lLX+v12h5+Kg/IkTJ3Dw4EG0bt1aYkejSZMmePDgAWv98jx//lxmaqi9vT0rXXt7e9y6dUuq/Y8//uDECGb+/PnYvn07/Pz84OTkBKDs9bV48WJ8+vSJtRkD385/QNku9MWLFxEZGYl58+bh3r17cHBwYOJ269aNlb6pqSliYmKkdptiYmI4MTcZNmwYpk2bBm1tbXTo0AFAWaqgl5cXhg4dylofANq3b4/g4GAsWbIEQNnnYGlpKVatWvXVc3kVZeXKlZg9ezaWL18OOzs7qfTf6laWhBXfepUnwA5NTU2qV68eDRs2jNTV1enSpUtExE1VegEBgeoNm/f54MGDafz48YxOeno6ffjwgVxcXGjMmDGs+zZ79mzy9fVlrfM1PDw8aOPGjZzrmpmZkZmZGYlEIjI1NWV+NzMzo4YNG1K3bt3o6tWrnMTiawxirK2tKS4ujjd9IiJLS0vavXu3VHtwcDCZm5uz1hcXp/3SjQvU1dWZ91L591VCQgLp6OhwEuPGjRvUpEkTUlBQIJFIJHHjsqhyQUEBZWdnU2ZmpsSNLbVr1/7iLkqdOnVY6y9ZsoS6du1KmpqapKqqSk5OTjR//nwKCwvjfMdJTGpqKo0ePZqUlJQ4+R+sXLmSDAwMaMeOHfTw4UN6+PAhbd++nQwMDGj58uWs9QsKCmjw4MEkEolIWVmZlJWVSVFRkdzd3amgoIC1PhHRrVu3yMjIiHr06EEqKir0yy+/kLW1NdWqVYvS0tJY65d/zZe/cf0+qA4IO1nfOW/fvkVcXBwuXryIY8eOoVevXqhVqxYKCgoQGhqKgQMHcp6LLSAg8P3j7++P7t27w8bGBp8+fcLw4cORmpqKmjVrYv/+/az1+bZ7BgBLS0ssWLAAV69elXlFdNq0aXLpis+4durUCceOHYO+vj7rvn4JvsYgZs2aNZg7dy6vznzjx4/Hb7/9hqKiIri4uAAoMz2ZPXs2ZsyYwVo/Pj5e4veioiLEx8dj9erVnFlZt2jRAmfOnIGnpyeA/7Nq37ZtGydFZAHAw8MDDRs2xPbt21GrVi3OzymmpKRg7NixvLm2vX79WuYObuPGjTkxH/n9998BSDv/rVq1ijPnv1evXjG6kZGRuHv3LvT09NC3b1907NiRtf6sWbPw6tUrTJkyBYWFhQAANTU1zJkzB/PmzWOtr6KigoMHD2Lp0qVISEiAuro67OzsUL9+fdbaYvg+G1edSpTwjeAu+J3z8eNHxiJXX18fN2/exNOnT9GlSxfY2trizp07MDU1FWplCQh8R2RlZcHU1FRqEkZEyM7OZtKjJk+ejCVLlrCycD9w4ACSkpKQm5uLZs2acWa7zbfdMwCZB8DLx0hPT2cdg2/4HkNVOPMREebOnYvAwECpiSWf7ohnzpzBH3/8gcjISNZaly5dQs+ePTFy5Ejs2rULEydOxN27d3H58mVERUWhefPmrGNoa2sjPj4elpaWrLVkwbdrW6tWrdCqVSsmnVaMp6cnYmNjcfXqVVb6Yvhy/gPKzGxq1qyJ9u3bo2PHjnB2dmaKN3NJbm4u7t27B3V1dVhZWUm5UT569Ah16tSRKDwvDyUlJbh16xbq16/P68UgAfkQFlnfOaqqqnBwcICTkxM2b96M69evo0mTJkwtDxMTE8TGxrJyRBIQEKhaKupqJ8AvJSUl2LVr1xdt6LlYKPKN2C3vS3BRV0dMVU0sxaSlpaFp06bIy8vjRO/Bgwfw8/NDYmIic9Fhzpw5nE3C+/fvj1GjRuHnn3/mRO9zNDU1eXVti4qKQu/evVGvXj1md+/KlSvIzs7G2bNn0b59e1b6spz/nJ2dOXP+A4A7d+6gSZMmnGixQd7yG7/99hvs7OwwduxYlJSUoGPHjrh8+TI0NDRw+vRpODs7c9K/T58+ISkpSebnnqurK2v9ixcvYvPmzUhPT8fhw4dhYmKC3bt3w9zc/Iearwrpgt85jx8/xpUrV3D58mUUFxejefPm+Omnn1BYWIi4uDjUrVv3h3rBCgj8FxCn93xObm4uZ4fBT506JbNdJBJBTU0NlpaWX91l+S/g5eWFXbt2oXfv3rC1teXFhp5vuFxE/RtaWlr46aefvni/jY2NXBPL9+/fS/xORHj69CkWL14MKysrufoqiwYNGmDr1q2c6X3Otm3bMHr0aNy+fRu2trZSu4psJ682NjZ4+fIlK42v0bFjR6SkpGD9+vVM0emBAwdiypQpnJg6HDhwADVr1sS4cePg4uKCdu3aQUNDg7VueTw9PXHs2DHo6elJtL9//x79+/evsgsn8u5vHDlyBCNHjgQA/P3330hPT8f9+/exe/duzJ8/HzExMaz7FhISAjc3N5mvJS7STo8ePYpRo0ZhxIgRiIuLQ0FBAQDg3bt3WL58OauSGNUNYSfrB0JfXx/R0dG4d+8e3NzcYGxsjGfPnqFly5aIior61t0TEBD4F7y9vQEAAQEBGD9+vMQEo6SkBNeuXYOioiInX6RfKmAubhOJRGjXrh1OnDghVxpKp06dvroo4WIy83ldps9hW/C4Zs2aCA4ORq9evVjpfA2+x1AVznwVRZxhUdlFlvi1Wh4igqmpKQ4cOCD3manPF29fgwvHs7///hujRo2SGZeLyeuFCxfw+++/f7eubW/evGGc/6Kiojh3/gPKXks5OTlSWQLPnz+HiYkJioqKWMeoCPK+F9TU1JCWloa6detiwoQJ0NDQwJo1a5CRkYGmTZtW6jX9JaysrNCtWzcsXLiQlzP9jo6OmD59Otzc3CSeh/j4ePTs2RM5OTmcx/xWCDtZPxi6uroYPHgwxo4diwsXLkBDQ0NYYAkIfCeID/gTEW7dugUVFRXmPhUVFTRt2hQzZ87kJNa5c+cwf/58LFu2DC1btgQAXL9+HQsWLMDvv/8OXV1dTJw4ETNnzsT27dsrrf+5ZXhRURESEhJw+/ZtznZX3rx5IxXj9u3bePv2LWPAwAYVFRXezs+I4XsMZmZmX13sfg+pp58flFdQUIChoSEsLS2hpCT/NEZPT+9fdye5Mo0AynZRRo4ciQULFvAyee3SpQsAoHPnzhLtbMaQlJQEW1tbKCgoICkp6auPZWtBr6+vD1dXV2ZHLy0tDUuXLsUff/yBlStXsvoflO/73bt3JSbyJSUlCAkJgYmJifydryJq1aqFu3fvonbt2ggJCWEKTufn53Ni0w+UFTD39vbmzTQtOTmZsZ8vj66uLt6+fctLzG+FsMj6gUhKSmI+JOrXrw9lZWUYGxtjyJAh37hnAgICFUE8mXR3d0dAQACvV569vLywZcsWiVpWnTt3hpqaGiZMmIA7d+5gzZo1/7rT8iX++usvme2LFy9Gbm6uXJqfI+sgfGlpKSZPnowGDRqw1p8xYwYCAgKwbt063lIF+R5DVTjz8Q0Xrm+yqGqXs1evXmH69Om8TV75GI+DgwOz8+Pg4CBz9xvgZieOT+c/cd9FIpHMixfq6upYu3YtqxhVgbu7OwYPHswYm4gX1teuXePsLN4vv/yCyMhITj5/ZGFsbIy0tDQpt9NLly5VemevuiOkCwoICAj8B1FXV0dsbCxsbW0l2m/duoWWLVvi48ePyMzMhLW1NfLz8zmLm5aWhpYtW3LiavclkpOT4ezszLoQ7oABAxAREYEaNWqgSZMmUulXx44dY6X/Nbgaw5fg0pmvolQmRerUqVPo2bMnlJWVv3h+UIyWlhYaN27MybkgPhk9ejTat2+PcePGfeuuVJjMzEzUq1cPIpEImZmZX30sWxtxPp3/MjMzQUSwsLDA9evXYWhoyNynoqICIyMjznaCKoK8xhdA2bms7OxsDBo0CHXr1gVQZnCjp6eHfv36se5bfn4+Bg0aBENDQ17KSqxYsQJ79uzBjh070LVrV5w9exaZmZmYPn06FixYwJRR+BEQdrIEBAQEqhl5eXnw8/P7oqsdF9bkzZs3x6xZsxAcHMxMOF68eIHZs2cz5gWpqakwNTVlHas8V65c4cy840s8ePAAxcXFrHX09PQwYMAADnpUebgaw5do1KgRYmNjedOXRWV2A/v378/soPTv3/9fH6+oqIhVq1Zh+vTpcvfvzZs32L59O+7duwegzEjC3d0dNWrUkFuzPA0bNsS8efNw6dIlXiavQFntzPJjaNKkCTw8PKCrqyuXXvmFE5e1mGSRlJTEm/OfuO+ff5Z+K9jsb/zyyy9SbVwa3Ozfvx9hYWFQU1NDZGSkxPtWJBKxfp3OnTsXpaWl6Ny5M/Lz89GhQweoqqpi5syZP9QCCxB2sgQEBASqHcOGDUNUVBRGjRols96Nl5cX6xjJycno168fMjIymIVUdnY2LCwscPLkSTRs2BAnTpzAhw8fMGrUqErrDxw4UOJ3sSPcjRs3sGDBAixatIj1GMRGIZ/HOHPmDEaPHo1169axjsE3fI/ha8589+/fR0JCAiv9yiDvYf9/o7CwEPv27cO8efPk3vmLjo5G3759oaurixYtWgAAbt68ibdv3+Lvv/+WeYaksvBdE+3GjRvo3r071NXVmXOWsbGx+PjxI8LCwtCsWTNW+kFBQahZsyZ69+4NAJg9eza2bNkCGxsb7N+/n/UizMXFpUqc/3bv3o1NmzYhIyMDV65cQf369fHXX3/BwsKCk52gipCdnY06depUaPcsMDAQEyZMgJqamlSNss/hYqFubGyMadOmYe7cuZyVWxBTUlKCmJgY2NvbQ0NDA2lpacjNzYWNjQ20tLQ4jVUdEBZZAgICAtUMPT09nDlzBk5OTrzGKS0tRVhYGFJSUgCU7W507dqVky9Wd3d3id/FZgUuLi6cuIQB0gWPy8fw8PBgZYpQVfA9Br6c+crj4eGBgIAAaGtrS7Tn5eXB09OTcUiszMSysnz48AGLFi3C6tWr5fp7Ozs7tGnTBhs3bmT6V1JSgilTpuDy5cu4desWl93lhfbt28PS0hJbt25lXjfFxcUYN24c0tPTER0dzUq/UaNG2LhxI1xcXHDlyhV07twZa9aswenTp6GkpMQ6fbYqnP82btyIhQsX4rfffsOyZctw+/ZtWFhYYNeuXQgKCpLrXNvnF5S+hjzPkbm5OW7cuAEDA4MqKcBeo0YNxMbG8nYmS01NDffu3ftPlAgRFlkCAgIC1Qxzc3OcPXsW1tbW37or/2nMzc2/muLGxYSGbz53l+XKma88Xyqe/fLlSxgbG3OS9piamoqIiAiZ6bMLFy5kra+uro6EhAQ0atRIoj05ORkODg74+PEj6xjlEU+9uDRUUVdXR3x8vJQBwt27d9GiRQvWZys1NDRw//591KtXD3PmzMHTp08RHByMO3fuwNnZGS9evJBLV+z85+DggAsXLkikZ4qd/zZv3oyHDx+y6j9QlgK6fPly9O/fX2Jn9fbt23B2dparztjnF5S+xs6dOyutX9VMnz4dhoaG+N///seLfosWLbBy5UopF8wfkep/mU9AQEDgP8aSJUuwcOFCBAUFcV6Mszx5eXmIiopCVlYWCgsLJe7jIu0EKEu5Kn8+xNHRkRPd8rx48QLJyckAyq62lz/UzobffvtN4nexM19ISAhmzZrFSQwxfI2BL2c+oCyNi4hARPjw4YPEWbuSkhKcPXtWauElD1u3bsXkyZNRs2ZNGBsbS50R4WKR1axZM9y7d09qkXXv3j00bdqUtb6Y4OBg/PHHH0hNTQVQdk5r1qxZcqXkfo6Ojg6ysrKkFlnZ2dlSu4zyoKWlhVevXqFevXoICwtjUl3V1NRYLUKr0vkvIyND5meQqqoq8vLy5NL8HhZOlaGkpASrVq1CaGgo7O3tpc4OyrtbLGbp0qWYOXMmlixZgubNm0NTU1Pi/upez60yCIssAQEBgWqGv78/Hjx4gFq1asHMzEzqSy4uLo51jPj4ePTq1Qv5+fnIy8tDjRo18PLlS2hoaMDIyIj1Iuv58+cYOnQoIiMjmTMWb9++RadOnXDgwAFOFhHidLTg4GBmd0NRURFubm5Yu3Yt6wXql86+rV+/Hjdu3GClLYbvMQBlJhpr1qyRMHTw8vJinQ4krjMlEonQsGFDqftFIhF8fHxYxQDKJmXLli3DnDlzWGt9iWnTpsHLywtpaWlo3bo1AODq1atYv349/Pz8JOosyVsPavXq1ViwYAGmTp3KpAJfunQJkyZNwsuXL1mZdgDAkCFDMHbsWPz5559MaYaYmBjMmjULw4YNY6UNAF27dsW4cePg6OiIlJQUpkj3nTt3pOy4K0NGRkaVOf+Zm5sjISFB6vxYSEhItc0c+Pzc5tdguwACyhxmxQvR27dvS9zHxc6r+HXj6uoqocdlTbrqgpAuKCAgIFDN+LeJKRemEc7OzmjYsCE2bdoEXV1dJCYmQllZGSNHjoSXl1elzhnIYsiQIUhPT0dwcDAzebl79y5Gjx4NS0tL7N+/n/UYJk6ciPPnz2PdunUSk9Zp06aha9euTKFOrklPT4eDg4OUqYQ88D2G0NBQuLq6wsHBgdGPiYlBYmIi/v77b3Tt2lVu7aioKBARXFxccPToUYk0LxUVFdSvX58TW3U2dtcV5d/OIYrrQ7GZBJqbm8PHxwdubm4S7UFBQVi8eDEyMjLk0hVTWFiIWbNmYdOmTUyKprKyMiZPngw/Pz+oqqqy0n/79i1+//13ZGdnY/LkyejRoweAss8jFRUVzJ8/n5V+VbBt2zYsXrwY/v7+GDt2LLZt24YHDx5gxYoV2LZtG4YOHco6xpEjR3Do0CGZGQLyXCD7/NxmXFwciouLmV3XlJQUKCoqonnz5pyZg1SER48eoU6dOpU+w/t5CvPn8Ln7XuWQgICAgMB/Dl1dXbp//z7z8927d4mI6OrVq9SoUSPW+jo6OnT9+nWp9mvXrpGuri5rfSIiAwMDioiIkGq/cOEC1axZk5MYsli5ciXVr1+fEy2+x+Dg4EBz5syRap8zZw45Ojqy1icievjwIZWUlHCiJQsPDw/auHEjb/pEZWOo6E1eVFVVKTU1Vao9JSWFVFVV2XRfgry8PEpKSqKkpCTKy8vjTLcqCA4OprZt21Lt2rWZ53r16tV04sQJzmLs2bOHLC0tSSQSkUgkIhMTE9q2bRsn2gEBAaSlpUVTp04lFRUVmjhxInXp0oV0dXXpf//7H2t9f39/6tu3L71+/Zppe/36NfXr14/+/PNP1vqVQVtbmx48eFClMb83hHRBAQEBgf8gysrKzBVIIyMjZGVlwdraGrq6usjOzmatX1paKpXmKI7LVa2a/Px81KpVS6rdyMiIkwLKjo6OUuksOTk5ePHiBTZs2MBaH+B/DPfu3cOhQ4ek2j08PLBmzRrW+kBZDSI+a0xZWlpiwYIFuHr1Km/1pfiuAQWUjePQoUNShgIHDx6ElZUVZ3E0NDSYFF0uz3T+mzshW5v7z53/xDuG+vr6WLNmDWf26iNGjMCIESOQn5+P3NxcTs4NitmwYQO2bNmCYcOGYdeuXZg9ezYsLCywcOFCTgqw+/v7IywsDPr6+kybvr4+li5dim7dumHGjBmsY1QUYpkIl5+fL3O3T9503OqIsMgSEBAQqGbIst0uDxc5646OjoiNjYWVlRU6duyIhQsX4uXLl9i9ezdsbW1Z67u4uMDLywv79+9nUsYeP36M6dOnc+Yq1aZNGyxatAjBwcGM6cLHjx/h4+PDiTX550Vwxc58zs7OUuYC8sL3GAwNDZGQkCA1iU9ISOBscimrxlRgYCB8fX05qTG1ZcsWaGlpISoqSirViIviqGKePHmCS5cuyXQw5CKGj48PhgwZgujoaInUzfDwcJkL4cpSXFwMHx8fBAYGIjc3F0CZWYWnpycWLVok86JHZXB2dpZqK/85xfZzae3atdi6dSv69+8PPz8/pr1FixaYOXMmK+3Pef78OWM0IxKJODOaycrKYs7Dqaur48OHDwCAUaNGoXXr1pzUvZPl4vjixQsmVnXnxYsXcHd3xz///CPz/h/pTJaQLiggICBQzThx4oTE7fDhw/S///2P07SW2NhYunDhAhERPXv2jLp3707a2trUrFkzSkhIYK2flZVFDg4OpKysTBYWFmRhYUHKysrk6OhI2dnZrPWJiG7dukV16tQhAwMDcnFxIRcXFzIwMCATExO6ffs2JzH4hu8x+Pj4kJ6eHvn5+VF0dDRFR0fTihUrSE9Pj3x9fTkYAZGtrS2NHz+eiouLmbbi4mKaMGEC2drachKDb3bu3EkqKiqkpaVF9evXJzMzM+Zmbm7OWZybN2/SiBEjqFmzZtSsWTMaMWIExcXFcaI9adIkMjIyok2bNlFiYiIlJibSpk2byNjYmCZNmsRa/+3btxK3Fy9eUFhYGLVq1YrOnz/PWl9NTY1JEdTS0mJS0VJSUkhNTY21PhHR+/fvaeTIkaSoqMikCyopKdGIESPo7du3rPXNzc2Z/2fz5s1p06ZNREQUGhpK+vr6rPVHjRpFZmZmdPToUcrOzqbs7Gw6cuQImZubk5ubG2v9ylD+f1QZhg8fTk5OThQbG0uampoUFhZGu3fvpkaNGtHp06d56Om3Q1hkCQgICHwn7N27l1xdXVnrlJaWUmZmJn38+JGDXn09TlhYGAUGBlJgYCCdO3eO8xh5eXm0ZcsW8vb2Jm9vb9q6dSvl5+dzpl9cXExHjhyhJUuW0JIlS+jYsWMSiwku4HMMpaWltHr1ajIxMZE4g7JmzRoqLS3lJIaamhpzvq889+/f52xyLKa0tJSzfpenbt26tHTpUt7OlhUWFpK7uzulp6fzok9Udg7y7NmzUu1nzpwhHR0d3uJGRkZSs2bNWOtYW1szZ6/KT+ADAwM5Oz84ePBgsrKyopCQEHr37h29e/eOQkJCqFGjRjRkyBDW+mPHjqXFixcTEdG6detIXV2dunTpQnp6euTh4cFaPy8vjyZPnkyqqqqkoKBACgoKpKKiQpMnT6bc3FzW+pVB3kWWsbExXbt2jYjKznUlJycTEdHJkyfJycmJ0z5+a4RFloCAgMB3woMHD0hTU5O1TklJCSkrK1NKSgoHvfpxSU1NJSsrK9LQ0CBHR0dydHQkDQ0NatSoEaWlpX3r7lWa9+/f0/v37znXbdu2LR0/flyq/fjx49SqVStOYgQFBZGtrS2pqqqSqqoq2dnZUXBwMCfaREQ1atTg/X+qo6PD6yLL0NCQMbApz927d3k1grl37x4nn0tbt24lExMTOnDgAGlqatL+/ftp6dKlzM9coKGhQRcvXpRqj46OJg0NDdb6JSUlVFRUxPy+f/9+8vT0pMDAQCooKGCtLyY3N5fZrZS1uMrOzubVjIZIfuMLbW1tysjIICKievXq0aVLl4iIKD09ndTV1bns4jdHOJMlICAg8B3w8eNHBAYGwsTEhLWWgoICrKys8OrVK04P3Jdn2rRpsLS0lDrLsm7dOqSlpXFiurBixQrUqlULHh4eEu07duzAixcvWNdVmjZtGho0aICrV68yBg6vXr3CyJEjMW3aNJw5c4aVPsD/GDIyMlBcXAwrKyuJgrSpqalQVlZmVd9IDN81pviuLwUAY8eOxeHDhzF37lzWWl+if//+OHHiBCf9lcXUqVOxZMkS7Ny5k7FrLygowLJlyzB16lTW+uX/j0CZ8cHTp0/h5+cHBwcH1vrjxo2Duro6fv/9d+Tn52P48OGoU6cOAgICOLFWBwADAwPo6upKtevq6kqYScjLo0ePYGpqyvw+dOhQDB06FESE7Oxs1KtXj3UMANDU1Pzqe8nGxob3sgckp/FFo0aNkJycDDMzMzRt2hSbN2+GmZkZNm3ahNq1a3Pcy2+LUCdLQEBAoJqhr68v5Wr34cMHaGhoYM+ePXB1dWUd4++//8aqVauwceNGTowuPsfExASnTp1C8+bNJdrj4uLg6uqKR48esY5hZmaGffv2MQfNxVy7dg1Dhw5lXXdIU1OTcbQrT2JiIpycnBhzATbwPYaOHTvCw8MDo0ePlmjfs2cPtm3bhsjISFb6AP81pviuLwWUHbbv06cPPn78KNPBkIsir0uXLoW/vz86d+6M5s2bQ1NTU+J+tuYaAwYMQHh4OFRVVdG0aVMAZa/VwsJCKbOZY8eOVVpfbMjz+bSxdevW2LFjB2dmMAB4cf4DykxUDh8+jN27d8PY2BgAkJOTg9GjR2PgwIGYOHEiK31FRUU8ffpUqt+vXr2CkZFRlZk6aGtrIzExkddFVnZ2NurUqVPpQtF79uxBcXExxowZg5s3b6JHjx54/fo1VFRUsGvXLgwZMoSnHlc9wk6WgICAQDXj810esatdq1atOLnaCgBubm7Iz89H06ZNoaKiAnV1dYn72doNv3r1SuYVYx0dHbx8+ZKVtpicnByZVz4NDQ3x9OlT1vqqqqoyHbtyc3OhoqLCWh/gfwzx8fHM7k95WrduzcnuBgBOFjlf4+nTp1KLUABo27YtJ88RULajGBoayhR4LX+R42tOn5Vh+/bt0NPTw82bN3Hz5k2J+7hwSdTT08PPP/8s0VZ+V4Utn/+fxZ9LYldMruDa+e/zUgypqamoV68es6uUlZUFVVVVvHjxgvUiS3wx4XNyc3M5f564pDLF58ULdHlfWyNHjmR+bt68OTIzM3H//n3Uq1cPNWvWlEuzuiIssgQEBASqGZ/vOvABVzWSvoSlpSVCQkKkJvL//PMPZ1dXTU1NERMTA3Nzc4n2mJgYxjaeDX369MGECROwfft2tGzZEkDZDtOkSZM42U0E+B+DSCSSuVB89+4dZ1fV+a4xVRX1pfz9/bFjxw6MGTOGEz1ZlF+kiHeDuFrAAcDOnTs50xJTo0YNpKSkoGbNmvDx8UFAQIBE2imXfPjwAVOmTMH+/fsZC31FRUUMGTIE69evl3nRpiJ8XoqBD7y9vQGU/T8XLFggUZ+spKQE165d4ySlki/kfW7ZQkRQV1dHs2bNvkl8vhEWWQICAgLVkLdv30oUd23SpAk8PDw4+zLkeyHn7e2NqVOn4sWLF3BxcQEAhIeHw9/fn7MF3vjx4/Hbb7+hqKhIIsbs2bM5KcoZGBiI0aNHo02bNkz6WHFxMVxdXREQEMBaH+B/DB06dMCKFSuwf/9+Jq2npKQEK1asQLt27Vjri+GzxhTf9aWAsl1LWTt+XLN9+3b89ddfSE1NBQBYWVnht99+w7hx41hrf/z4EUTETPAzMzNx/Phx2NjYoFu3bnJpFhYW4v3796hZsyaCgoKwcuVK3hZZ48aNQ3x8PM6cOcPUiLty5Qq8vLwwceJEHDhwQC7dRYsWVfpv9u/fD1dXV6mUzi8RHx8PoGzRcOvWLYmdbhUVFTRt2pTzWl9cwscC/Wvw+T6oVnwTuw0BAQEBgS8SGxtLNWrUIBMTExowYAANGDCA6tatSwYGBnTz5k3O4qSlpdH8+fNp6NCh9OzZMyIiOnv2LGc1pjZs2CBhHW5ubk5BQUGcaBOV2XnPnj2b1NTUGDtjDQ0N8vHx4SwGUZnL4KlTp+jUqVOUmprKqTbfY7hz5w4ZGBhQgwYNaMyYMTRmzBhq0KABGRoa0q1btziJURU1pm7cuMFbfSkiouXLl5OnpydnerJYsGABaWpq0ty5c+nkyZN08uRJmjt3LmlpadGCBQtY63ft2pU2btxIRERv3rwhIyMjqlu3LqmpqdGGDRvk0uzSpQvZ2dnRmDFjSCQS0dChQ8nd3V3mjS18O/9VBnmd88aMGUPv3r3joUeVQ97+VwV8vw+qE4LxhYCAgEA1o3379rC0tMTWrVuhpFSWcFBcXIxx48YhPT0d0dHRrGNERUWhZ8+ecHJyQnR0NO7duwcLCwv4+fnhxo0bOHLkCOsYYl68eAF1dXVoaWlJ3RcTE4MWLVowbmjykJubi3v37kFdXR1WVlZSWo8ePUKdOnX+1aDhW8LnGJ48eYJ169YhMTER6urqsLe3x9SpUxnHRLaYmppi0qRJmDdvXrV+jr/GgAEDcOHCBRgYGKBJkyZSxhfyGEV8jqGhIQIDAzFs2DCJ9v3798PT05P1WcWaNWsiKioKTZo0wbZt27B27VrEx8fj6NGjWLhwIbMrXhmePXuGv/76Cw8ePMCxY8fQvXv3L75Xjx8/zqr/9erVw5kzZ6SMZpKSktCrVy9OzHIqChfGEeL+1q1bl6tuVRi2/T9y5AgOHTqErKwsFBYWStwXFxfHqm98vw+qFd96lScgICAgIImamhrdu3dPqv3OnTuc1RFp3bo1+fv7E5FkUclr166RiYkJJzEqQlVccZU3xsCBA8nPz0+qfeXKlfTLL79w0bUKw/fzNHnyZHrx4oVcf8t3jakzZ85QSEiIVHtISIjM4rvyIN7l+9KNC3R1dWXWpktOTiZdXV3W+urq6pSZmUlERIMGDWKK4mZlZXHyuWFmZkYvX75krfMlNm/eTF26dKGnT58ybU+fPqVu3brRpk2beIsrC3kL7ZaUlJCPjw/p6OgwO9O6urrk6+vLe92q8mRlZcldND0gIIC0tLRo6tSppKKiQhMnTqQuXbqQrq4u/e9//2PdN77fB9UJ4UyWgICAQDVDR0cHWVlZUpbI2dnZnJ2HuHXrFvbt2yfVbmRkVKVXEqkKkinkjREdHY3FixdLtffs2RP+/v4se1U5+H6e9uzZg5kzZ8rl7sV3jam5c+fCz89Pqp2IMHfuXPTs2ZN1jKo4kzJq1Chs3LhRyg5+y5YtGDFiBGt9S0tLnDhxAgMGDEBoaChTj+v58+fQ0dFhrc+Hi2RVOv9VBfPnz8f27dvh5+cnUdNt8eLF+PTpE5YtW1Zpzap0/gOADRs2YMuWLRg2bBh27dqF2bNnw8LCAgsXLmTtOgvw/z6oTgiLLAEBAYFqxpAhQzB27Fj8+eefjHV1TEwMZs2aJZViIS96enp4+vSplKtdfHw8JwWPfwS+ZNWurKyM9+/ff4Me8QebRdyKFSvQp08fhISE8FJjKjU1FTY2NlLtjRs3RlpaGivtqmb79u0ICwtjijZfu3YNWVlZcHNzYxzqAPmes4ULF2L48OGYPn06XFxcGPOIsLAwODo6ctL/8PBwhIeHyzQ42bFjR6X1qsL5ryoJCgrCtm3bJNxH7e3tYWJigilTpsi1yKpq57+srCzme0ddXZ1xJx01ahRat26NdevWsY7B5/ugOiEssgQEBASqGX/++SdEIhHc3NxQXFwMoGxiP3nyZJlX9OVh6NChmDNnDg4fPgyRSITS0lLExMRg5syZUkVf/6vY2dnh4MGDWLhwoUT7gQMHZE76/6vwXWNKV1cX6enpMDMzk2hPS0ursPtbReDzHAoA3L59m7GqfvDgAYCyc1Q1a9bE7du3mcfJ+5z98ssvaNeuHZ4+fcoUIwaAzp07Y8CAASx6XoaPjw98fX3RokUL1K5dm5P/bVU4/1Ulr1+/llmUuXHjxnLvAlW185+xsTFev36N+vXro169erh69SqaNm2KjIwMTnbU+X4fVCu+Za6igICAgMCXycvLo6SkJEpKSqK8vDxOtQsKCmjcuHGkpKREIpGIlJWVSUFBgUaOHCl3Lr88yHv2oSpinDp1ipSUlMjNzY127dpFu3btolGjRpGSkhIdP36c+45+Bb6fJzb6enp6tHPnTm47VI4JEyaQnZ2dxLmv1NRUsre3p7Fjx3ISg+9zKFVJamoqhYSEUH5+PhGVOVhygbGxMQUHB3OixYaqOMfZpEkTysrKqvTftWzZUqZL5dSpU6lVq1ZcdI13xo4dy5znW7duHamrq1OXLl1IT0+PPDw8qqwf2dnZVXqOjQ8Ed0EBAQGBaoa4UOzn7m+vX7+GkpISJ+crxGRlZeH27dvIzc2Fo6MjZ8VdK4qOjg4SEhI4K1DMdYwzZ85g+fLlSEhIYJz5Fi1ahI4dO/LQ0y/D9/PExo3M2NgYFy9e5O218+7dO/To0QM3btxgnNoePXqE9u3b49ixY9DT02Mdo3Hjxli0aBGGDRsm8VyIz6FwkSLFN69evcLgwYMREREBkUiE1NRUWFhYwMPDA/r6+qzPERoYGOD69eto0KABRz2WDzav1dGjR2Ps2LHo0KEDDz0rc23t3bs36tWrJ1HrKzs7G2fPnkX79u1Zx+B7x7W0tBSlpaWMs+2BAwdw+fJlWFlZYeLEiTJTqPmgKr4b+Ob79FoVEBAQ+IEZOnSozMKbhw4dwtChQzmJcenSJQBltsm9evXC4MGDq3yBBVRv4wsA6N27N2JiYpCXl4eXL1/iwoULUgus/fv3Iy8vj203v0p1vh7q5eWFtWvX8qavq6uLy5cv48yZM5gyZQpmzJiB8PBwXLhwgZMFFvD1cyj79+/nJAbfTJ8+HcrKysjKymIKEgNlZzxDQkJY648bN06mWc73xLt379ClSxdYWVlh+fLlePz4Maf65ubmSElJwYABA/D27Vu8ffsWAwcORHJyMurXr89aPzAwEO7u7qhVqxbi4+PRsmVLGBgYID09nRMDGKDsAoa4cDlQ9n0UGBiIqVOnIicnh5MYFaE6f+ZVmG+5jSYgICAgII2+vj7dvXtXqv3evXtUo0YNTmIoKyuTmZkZzZs3j+7cucOJZnk6depEb968kWp/9+4dderUiZMY7u7u9P79e6n23NxcieKobOyMKwKX6Uvv3r2j48ePS/3/+R7DpEmT5LZw79+/P+no6JC5uTn16dOHKaAtvlUVtra2cqV4ERGZm5szxY2bN2/OWIaHhoaSvr4+Z33kk1q1alFCQgIRSaZ/PnjwgDQ1NVnrT5s2jfT09KhDhw40depUmj59usStqmCbOvv8+XPy9/cne3t7UlJSoh49etDhw4epsLCQdd8UFBSYwu7lefnyJSkoKLDWb9SoEe3bt4+IJJ+HBQsW0K+//span4j/MVSUqkgl5xthJ0tAQECgmlFQUMAYXpSnqKgIHz9+5CTGkydPMGPGDERFRcHW1hYODg74448/OCv4GRkZKZXKAgCfPn3CxYsXOYkRFBQk8/n4+PEjgoODmd9NTU0lrsxyDbG44jp48GAmFe3jx49o0aIFBg8eDHt7exw9epR5nLxjCAkJYXYtAWD9+vVwcHDA8OHD8ebNG6Z948aNctm3A2VOlQMHDkTHjh1Rs2ZN6OrqStyqiocPH6KoqEiuv3VxccGpU6cAAO7u7pg+fTq6du2KIUOGcGIaURXk5eVJ7GCJef36Nati32KSkpLg4OAABQUF3L59G/Hx8cwtISGBtX5VYWhoCG9vbyQmJuLatWuwtLTEqFGjUKdOHUyfPh2pqalya3/psyA3Nxdqampy64qpih1XIpJpOsHVGP5LCO6CAgICAtWMli1bYsuWLVIpWJs2bULz5s05iVGzZk1MnToVU6dORUZGBvbt24egoCDMmzcPHTp0wIULF+TSTUpKYn6+e/euRHpJSUkJQkJCWFvEv3//HkQEIsKHDx8kvvhLSkpw9uxZGBkZsYpRVURHR2P+/PkAgOPHj4OI8PbtWwQFBWHp0qX4+eefWenPmjULK1euBFBWG23GjBnw9vZGREQEvL29OXEuq2r3Mz7YsmULY0n+66+/wsDAAJcvX4arq+t3UZ8JANq3b4/g4GAsWbIEABjX0FWrVqFTp06s9SMiIlhrVCeePn2Kc+fO4dy5c1BUVESvXr1w69Yt2NjYYNWqVUydsYogth0XiURYuHChxGK3pKQE165dg4ODA+s+8+n8V34MCxYs4G0M/yWERZaAgIBANWPp0qXo0qULEhMT0blzZwBl9WliY2MRFhbGeTxzc3PMnTsXTZs2xYIFCxAVFSW3loODA0QiEUQiEVxcXKTuV1dXZ31+R09Pj4nRsGFDqftFIhF8fHxYxagq3r17xxichISE4Oeff4aGhgZ69+6NWbNmsdbPyMhg7OaPHj2KPn36YPny5YiLi0OvXr1Y65fnxYsXSE5OBgA0atQIhoaGnOrziYKCAhQU/i+5Z+jQoZydf6wq/vjjD7i4uODGjRsoLCzE7NmzcefOHbx+/RoxMTGcxhLveIuNSKqS+vXrS9ViqyhFRUU4deoUdu7cibCwMNjb2+O3337D8OHDGUOh48ePw8PDo1KLrPj4eABlu0C3bt2SMIdQUVFB06ZNMXPmTLn6XB7xjqujoyOz43rkyBHcuHGjUkWLZVFVY6gogoW7gICAgAAvxMfH0/Dhw8nGxoaaN29O7u7ulJKSwnmcS5cu0eTJk8nQ0JC0tbVp5MiR9M8//8it9/DhQ8rIyCCRSESxsbH08OFD5vbkyRNOzhVFRkZSREQEiUQiOnbsGEVGRjK3y5cv0+PHj1nHqAxszg5YWVnRwYMHKTc3lwwNDSk8PJyIiBISEsjAwIB13/T19Zkzd05OTrR582YiIsrIyCB1dXXW+kT/dwZOUVGRRCIRiUQiUlJSIg8PD85LD3wNNv+HRYsWybSLfvv2LQ0dOpRt13insLCQXFxc6Nq1a7R06VIaNGgQ9ezZk+bPn09PnjzhJEZJSQn5+PiQjo4OKSgokIKCAunq6pKvry8nVttubm4UFRXFQU+/jIGBAenr69OUKVMoPj5e5mPevHlDZmZmcumPGTOG3r17x6KHX6ekpISKioqY3/fv30+enp4UGBhIBQUFnMTgewwV5Uc4kyUssgQEBAS+U1asWCHTXKIizJ07l8zMzEhZWZl69+5N+/bt42xCXFhYSGPGjKH09HRO9GRRVFREY8aMkdvogEvYTAbWr19PSkpKpKenR02bNmUmq4GBgeTs7My6b3379qXu3buTr68vKSsr06NHj4iozNDBysqKtT5RWR0rCwsLOnv2LL17947evXtHZ86coQYNGtCkSZM4iVER2Pwf6tatS23atJH4+4iICDI1NaWffvqJqy7ySs2aNXm5ECNm7ty5ZGhoSBs2bKDExERKTEyk9evXk6GhISe1xPr160fKyspkaWlJy5YtY16rXBIcHEwfP37kXLeqyMzMlFn3rLS0lDIzMzmPl52dTdnZ2ZzrVgS+zX6qAqFOloCAgMB3Cps6Ik5OThgxYgQGDx4st+HB19DT00N8fDzMzc051xajra2NW7duwczMjLcYFcHW1hb//PMPTE1N5fr7GzduIDs7G127doWWlhaAsvpcenp6cHJyYtW3rKwsTJkyBdnZ2Zg2bRrGjh0LoMzuu6SkBIGBgaz0gbLzfUeOHIGzs7NEe0REBAYPHowXL16wjlER2NRPevPmDSZOnIiQkBD4+/sjJSUFAQEBmDVrFnx8fJiaQdWZ6dOnQ1VVFX5+frzo16lTB5s2bYKrq6tE+8mTJzFlyhRO7NBfvHiB3bt3IygoCHfv3kWXLl0wduxY9OvXT+4UwfJ4eHggICAA2traEu15eXnw9PTEjh07WMfgE0VFRTx9+lTqzOmrV69gZGSEkpIS1jFKS0uxdOlS+Pv7Izc3F0DZe2vGjBmYP3++RFptRalMKuOxY8cqrV9dERZZAgICAt8pbCaVYu7evSuzqOXnE6nKMnr0aDg4OFTqXENl6devHwYOHIjRo0fzop+dnQ2RSMScO7l+/Tr27dsHGxsbTJgwgZeY3yMaGhq4efMmrK2tJdrv3LmDli1b8l5DTMy+ffvQr18/aGpqyq3xv//9D35+flBSUsI///zDnIn8HvD09ERwcDCsrKzQvHlzqedh9erVrPTV1NSQlJQkdQ4yOTkZDg4OnDmfiomLi8POnTuxbds2aGlpYeTIkZgyZQqren5fWqS8fPkSxsbGMl1dqxMKCgp49uyZ1HnHzMxM2NjYcPJemzdvHrZv3w4fHx/mIs+lS5ewePFijB8/HsuWLau0pru7e4Uf+yMY6Yip/pdmBAQEBAQ4JyMjAwMGDEBSUhJEIhHjTCU+bMz2iqiVlRV8fX0RExMjc8I3bdo0VvoA0LNnT8ydOxe3bt2SGYPtQnH48OGYMGECRo0ahZycHHTt2hVNmjTB3r17kZOTg4ULF8qlK3bxqghsJ8YA8ODBA+zcuRMPHjxAQEAAjIyM8M8//6BevXpo0qQJa/02bdpg0aJFCA4OZpweP378CB8fH7Rp04a1PlBm/BIeHo7nz58zLoBixLsPw4cPZxVj7dq1CAgIwLBhw3Dz5k1MmzYN+/btQ9OmTVnpVhW3b99Gs2bNAAApKSkS93FhItC0aVOsW7dOavdz3bp1nD9HXDr/Ad+/I2lVOv8FBQVh27ZtEp+f9vb2MDExwZQpU+RaZP1IC6fKIOxkCQgICHynsNnJ6tu3LxQVFbFt2zaYm5vj+vXrePXqFWbMmIE///wT7du3Z9W3r6UJikQipKens9IH8NW0FZFIxHqhqK+vj6tXr6JRo0YIDAzEwYMHERMTg7CwMEyaNEnuMXxupx0XF4fi4mI0atQIQNkEWVFREc2bN5fbSl9MVFQUevbsCScnJ0RHR+PevXuwsLCAn58fbty4gSNHjrDSB8qs4Xv06IGCggJmsp2YmAg1NTWEhoayXsj5+PjA19cXLVq0QO3ataUWDMePH2elDwA9evRAbGwsNm/ejF9++QUfP36Et7c3du3aBR8fH8yePZt1jO+dqKgo9O7dG/Xq1WMWz1euXEF2djbOnj3L+jNDlvPfuHHjZDr/la/xVhEUFBS+utAUO5KKyylUN8SfGVFRUWjTpo2U85+ZmRlmzpzJapdPTFXvWP7ICIssAQEBge8UNousmjVr4sKFC7C3t4euri6uX7+ORo0a4cKFC5gxYwZj5/tfRktLC7dv34aZmRlcXV3h5OSEOXPmICsrC40aNeJksrF69WpERkYiKCgI+vr6AMrOB7m7u6N9+/aYMWMGK/02bdpg0KBB8Pb2lni9XL9+HQMHDuSs+HR+fj727t2L+/fvAwCsra0xYsQIqKurs9auXbs2Vq1ahVGjRrHW+hJdu3ZFUFAQ6tSpI9F+5swZjBs3Dk+fPuUt9vfE48ePsWHDBon/85QpU6SeN3moWbMmSktLMWzYMIwfP17mzszbt2/h6OiIjIyMSmlHRUWBiODi4oKjR48yZROAskVK/fr1ORkD37i7uyMgIIBZdPJBq1at0KpVK6kdS09PT8TGxuLq1ausYxw5cgSHDh2SmaoeFxfHWr/a8G38NgQEBAQE2MLGTU1PT49x/7OwsKALFy4QEVFaWhpn1t5iSktLZTpiVXdatmxJc+bMoejoaFJTU6OEhAQiIrpy5QqZmJhwEqNOnTp0+/ZtqfZbt25R7dq1Wetramoy/+fyr5eMjAxSVVVlrV9YWEgWFhZ09+5d1lpfokaNGpSWlsabvpjo6GgaMWIEtW7dmnG2Cw4OpujoaN5jC1SN89/Dhw+/y88iWfDl/BcZGUmamppkbW1NHh4e5OHhQdbW1qSlpcXJeyEgIIC0tLRo6tSppKKiQhMnTqQuXbqQrq4uJy6V1YnKW4QICAgICFQL2rdvL/dOga2tLRITEwGUXblctWoVYmJi4Ovry8pIozzBwcGws7ODuro61NXVYW9vj927d3OiLSYqKgp9+/aFpaUlLC0t4erqiosXL3KivXLlSmzevBnOzs4YNmwYkwp36tQptGzZkpMY79+/l+m+9+LFC3z48IG1vp6ensxdmPj4eJiYmLDWV1ZWxqdPn1jrfI1x48Zh3759vMY4evQounfvDnV1dcTHx6OgoABAWbHoFStW8Br7e2Hnzp04fPiwVPvhw4cRFBTEWj8iIgJFRUVS7Xl5efDw8JBbNykpiTnH9+7dO9y6dQtJSUkyb9Wd0tJS+Pr6QldXF/Xr10f9+vWhp6eHJUuWSJ1VlBdzc3OkpKRgwIABePv2/7s5YwAAWW5JREFULd6+fYuBAwciOTkZ9evXZ62/YcMGbNmyBWvXroWKigpmz56Nc+fOYdq0aXj37h0HI6g+COmCAgICAtWA9+/fV/ixXKSKhIaGIi8vDwMHDkRaWhr69OmDlJQUGBgY4ODBg3BxcWGlv3r1aixYsABTp06VcKhav349li5dyonr4J49e+Du7o6BAwcyMWJiYnD8+HHs2rWLtRECUHao/P3790wqHwA8fPgQGhoanByUd3Nzw8WLF+Hv788s3K5du4ZZs2ahffv2rCevM2fOxLVr13D48GE0bNgQcXFxePbsGdzc3ODm5oZFixaxHsPy5cuRkpKCbdu2cWZ1Xt4cpLS0FEFBQbC3t4e9vb2UlTcX5iCOjo6YPn063NzcJNIq4+Pj0bNnT+Tk5LCO8b3TsGFDbN68WepMYVRUFCZMmIDk5GRW+nw5/ykoKCAnJwdGRkbM2SxZU18uznHyDR/Of5/Dt028hoYG7t27h/r168PIyAjnzp1D06ZNkZqaitatW+PVq1es9KsTwiJLQEBAoBrwbwezy8PXROD169fQ19fnxInM3NwcPj4+cHNzk2gPCgrC4sWLK32mQhbW1taYMGGC1IJt9erV2Lp1K+7du8c6Bt/k5+dj5syZ2LFjB3MVX0lJCWPHjsUff/zByo4cAAoLC/Hrr79i165dKCkpgZKSEkpKSjB8+HDs2rULioqKrMcwYMAAhIeHQ0tLC3Z2dlJ9lqfuzecT+S8hEolYm4MAZRO/u3fvwszMTGKRlZ6eDhsbG953674H1NTUcP/+fam6dA8fPoS1tbXcZxTFzn/6+vpITU2VsCcvKSnB33//jblz5+LJkydy6WdmZqJevXoQiUTIzMz86mO52Knhk6qoVVZ+UVoermziLSwscPToUTg6OqJFixYYP348Jk6ciLCwMAwdOhSvX79mpV+dECzcBQQEBKoBERERzM8PHz7E3LlzMWbMGAkXr6CgIF5Tl8ofBmfL06dP0bZtW6n2tm3bcmYikJ6ejr59+0q1u7q64n//+x9r/WfPnmHmzJmMdfjn1yTZLnZLSkpw48YNLFu2DH/88QcePHgAAGjQoAHrxZUYFRUVbN26FQsXLsStW7eQm5sLR0dHTlzIxOjp6eHnn3/mTA+QfD9UBcbGxkhLS5NaQFy6dImz9NnvHSMjIyQlJUk9R4mJiTAwMJBbV09PDyKRCCKRSMrRDvg/5z95ES+cioqK4OPjgwULFvBaJJ1PXr9+jcaNG0u1N27cmPXipLxN/MKFC3mziXdxccGpU6fg6OgId3d3TJ8+HUeOHMGNGzcqVbT4e0BYZAkICAhUAzp27Mj87Ovri9WrV2PYsGFMm6urK+zs7LBlyxbeiu9yiaWlJQ4dOiS12Dl48CBnE3xTU1OEh4fD0tJSov38+fMwNTVlrT9mzBhkZWVhwYIFMq3D2aKoqIhu3brh3r17MDc3h729Paf65TE1NYWpqSlKSkpw69YtvHnzRiIFkg1VXQPn/fv3uHDhAho3bixzwikP48ePh5eXF3bs2AGRSIQnT57gypUrmDlzJhYsWMBJjO+dYcOGYdq0adDW1kaHDh0AlKUKenl5YejQoXLrRkREVInzn7KyMo4ePfpd/z/5rFUmdpQlIty6dUvKJr5p06aYOXMmqxgAsGXLFub82K+//goDAwNcvnwZrq6umDhxImv9asU3s9wQEBAQEJCJuro6paSkSLUnJydz7vzHF0eOHCFFRUXq3r07+fr6kq+vL3Xv3p2UlJTo2LFjnMTYsGEDqaio0KRJkyg4OJiCg4Np4sSJpKqqSps2bWKtr6WlRfHx8ew7+hWaN29O58+f503fy8uLtm3bRkRExcXF5OTkRCKRiDQ1NSkiIoLTWM+ePaPo6GiKjo6mZ8+ecaY7aNAgWrt2LRER5efnk5WVFSkrK5OSkhIdOXKEkxilpaW0dOlS0tTUJJFIRCKRiNTU1Oj333/nRP9HoKCggAYPHkwikYiUlZVJWVmZFBUVyd3dnQoKCljrV4Xzn5ubG61evZrXGHzCt/MfEdGYMWPo3bt3nGjJIjMzU+b/ubS0lDIzM3mL+y0QzmQJCAgIVDMaNWqEfv36YdWqVRLts2fPxsmTJ1kfMK8qbt68ib/++os5G2VtbY0ZM2bA0dGRsxjHjx+Hv7+/RIxZs2ahX79+rLVtbGywd+9eTvv7OSEhIZg3bx6WLFmC5s2bS6UJsjU5qVu3Lk6cOIEWLVrgxIkTmDJlCiIjI7F7925cuHABMTExrPSBsp2lX3/9FQcOHGBSKBUVFTFkyBCsX78eurq6rPSNjY0RGhqKpk2bYt++fVi0aBESExMRFBSELVu2cFrTrbCwEGlpacjNzYWNjQ20tLQ40/5RSE1NRUJCAtTV1WFnZ8fqHFNSUhJsbW2hoKDwr+5+XOz0Ll26FP7+/ujcubPM99u0adNYx+CTrKwsKCkpYf369VK1yoqLi1GvXr1v3MN/h29jjeqEsMgSEBAQqGacPXsWP//8MywtLdGqVSsAwPXr15GamoqjR4+iV69e37iHsvH29saSJUugqamJ6OhotG3bljO3OTGBgYGYMGEC1NTUkJWVBVNTU87T+MSEhYXB398fmzdvljqHwhUKCv9XSaX8OIiIE7czNTU1pKWloW7dupgwYQI0NDSwZs0aZGRkoGnTppVytfwSQ4YMQXx8PNauXStxhtDLywsODg44cOAAK311dXWkpKTA1NQUbm5uqFOnDvz8/JCVlQUbGxvk5uayHoMAd+jo6CAhIaFCZ9mq2vnva2exRCIR0tPTWcfgkx9hgaKgoIBnz55JGJwA3BlrVCeEM1kCAgIC1YxevXohNTUVGzduZHZo+vbti0mTJnFy1ogv1q5dizlz5kBTUxOdOnWSORlgi7e3N4YOHQo1NTWYm5vzEkPMkCFDkJ+fjwYNGkBDQ0PKOpwLFyy+DR5q1aqFu3fvonbt2ggJCcHGjRsBlLkacuEsCACnT59GaGgo2rVrx7R1794dW7duRY8ePVjrm5qa4sqVK6hRowZCQkKYRdubN2+gpqbGWl+AWypz7T4jI4OZbHPhOFqReN8zX3puc3Nzq/17obyxxoIFC3gz1qhOCIssAQEBgWpEUVERevTogU2bNnFS86QqMTMzQ2BgILp16wYiwpUrV75oriA+OF9Z6tSpw+zmEREePXr0RXtttqkza9asYfX3FaG84QkfuLu7Y/DgwYxxR5cuXQCU1eLiyjTCwMBAZkqgrq4uJ+Yav/32G0aMGAEtLS3Ur18fzs7OAIDo6GjY2dmx1hf4dvxIzn98UlXOf3xSVcYa1QkhXVBAQECgmmFoaIjLly9zarNdFZw4cQKTJk3C8+fPv5j2A7BL/dmyZQs8PT2/WpiUq1S7quLt27fYvn07s2vZpEkTeHh4sD7LJObIkSPIzs7GoEGDULduXQBl9cr09PQ4Obu2ZcsWHD58GLt374axsTEAICcnB6NHj8bAgQM5cQy7ceMGsrOz0bVrV+ac1JkzZ6Cnp8cUZRWoHpSvM1YZdHV1kZCQwPsi69GjRzh16hSysrJQWFgocR8Xha35QFw3LioqCm3atJFaoJiZmWHmzJnfxXeGu7s7AgICWJ83/R4QFlkCAgIC1Yzp06dDVVUVfn5+37orcpGbmwsdHR0kJyd/MZWPzQLiw4cPyMzMhL29Pc6fP//FGj1sLY2BsqvEJ06ckFgAubq6cpZqd+PGDXTv3h3q6upo2bIlACA2NhYfP35EWFgYmjVrxkkcAPj06RMvKUWOjo5IS0tDQUEBs3uYlZUFVVVVqUlfXFwc5/EFqhfyLrJGjx4NBwcHqeLiXBIeHg5XV1dYWFjg/v37sLW1xcOHD0FEaNasGSeFrfnkR1ugPHr0CACYiz8/GkK6oICAgEA1o7i4GDt27MD58+dlOmBV16utYrS0tBAREQFzc3POjS+Askmcra0tdu7cCScnJ6iqqnIeAwDS0tLQq1cvPH78GI0aNQIArFixAqampjhz5gwaNGjAOsb06dPh6uqKrVu3Ms9VcXExxo0bh99++w3R0dGs9EtKSrB8+XJs2rQJz549Q0pKCiwsLLBgwQKYmZlh7NixrMfQv39/1hqfU95ERZwq9SWq+/vhv4a8RjRWVlbw9fVFTEwMb85/8+bNw8yZM+Hj4wNtbW0cPXoURkZGGDFiBCfnB/mmqmvS8UFpaSnj8ig2rdHW1saMGTMwf/58CTOg7x1hJ0tAQECgmiFODZGFSCSq9ldby/P8+XM8f/6cKT4phuvCu7m5uVIx2F7tFZ/72rt3L1Mg9dWrVxg5ciQUFBRw5swZVvpAmXNefHy81Pmou3fvokWLFsjPz2el7+vri6CgIPj6+mL8+PG4ffs2LCwscPDgQaxZswZXrlxhpV8Z9u/fD1dXV6nJsyw6deqE48ePQ09P74d6P/wXkHcnqyqc/7S1tZGQkIAGDRpAX18fly5dQpMmTZCYmIh+/frh4cOHrGMIfJ158+Zh+/bt8PHxYVJ9L126hMWLF2P8+PHf3Vnkr1KlVbkEBAQEBP4T3Lx5k5o0aUIKCgpMcVfxTUFBgZMY6enp1KtXL9LQ0CAFBQXmxlUMDQ0NSkpKkmpPSEggTU1N1vpEREZGRhQaGirVHhISQkZGRqz1GzRowBQ71tLSogcPHhAR0b1790hPT4+1fmXQ1tZm4gt8vxQUFND9+/epqKhI5v0XL16kT58+VXGvKkatWrXo7t27RERkbW1NJ0+eJCJu39MCX6d27drM816eEydOUJ06db5Bj/hDSBcUEBAQqMZ8rznr7u7uaNiwIbZv345atWrxUstq5MiRICLs2LGDlxiqqqr48OGDVHtubq7EwXM2DBkyBGPHjsWff/6Jtm3bAgBiYmIwa9YsDBs2jLX+48ePYWlpKdVeWlqKoqIi1vqVgYTEme+a/Px8eHp6IigoCACY1FNPT0+YmJhg7ty5ACBh5V/daN26NS5dugRra2v06tULM2bMwK1bt3Ds2DG0bt36W3fvP8Hr169lOps2btyYk7IY1QlhkSUgICBQzfgRctbT09Nx9OhRmRN8rkhMTMTNmzeZ81Jc06dPH0yYMAHbt29nTCmuXbuGSZMmwdXVlZMYf/75J0QiEdzc3BjHRGVlZUyePJkT4xMbGxtcvHiRscoWc+TIETg6OrLW54uBAwdW+LHHjh3jsScCYubNm4fExERERkZKnF/q0qULFi9ezCyy2MC389/q1auZz1QfHx/k5ubi4MGDsLKyEs72VRFNmzbFunXrEBgYKNG+bt06TsyKqhPCIktAQECgmjF//nxs374dfn5+Ujnrnz59+i5y1jt37ozExEReF1k//fQTsrOzeVtkBQYGYvTo0WjTpg1TiLi4uBiurq4ICAjgJIaKigoCAgKwYsUKPHjwAACY4sdcsHDhQowePRqPHz9GaWkpjh07huTkZAQHB+P06dOcxOADruzrBbjjxIkTOHjwIFq3bi2xa9ykSRPmtcuGf3P+44Ly58Q0NTWxadMmTnQFKs6qVavQu3dvnD9/Hm3atAEAXLlyBdnZ2Th79uw37h23CMYXAgICAtWMOnXqYNOmTVK7JSdPnsSUKVPw+PHjb9SzivPy5UuMHj0aLVu2hK2tLbNIEcPFTtCDBw8wadIkjBw5UmYMrsw1UlNTcf/+fQCAtbU1pwvHCxcuoG3btrxYq4u5ePEifH19kZiYiNzcXDRr1gwLFy5Et27deIspC3kNEQSqBxoaGoxxSvn/ZWJiIjp06IB3796x0m/ZsiV69uzJOP8lJiZKOP9NnjyZo5EIfEuysrKgpKSE9evXS3yuTpkyBcXFxayLyFcnhEWWgICAQDVDTU0NSUlJaNiwoUR7cnIyHBwc8PHjx2/Us4rz999/Y9SoUXj//r3UfVwVCr569SqGDx8u4QgmLoL8vRQj1tLSQnFxMX766Sc4OzujY8eOcHJygrq6+rfuGucIi6zvmw4dOmDQoEHw9PSEtrY2kpKSYG5uDk9PT6SmpiIkJISVPl/Of/r6+hU+r/mjnQmqjigqKuLp06dSNRRfvXoFIyOj7+Jzu6II6YICAgIC1YwfIWfd09MTI0eOxIIFC1CrVi1eYnh4eMDR0RH79+/nzPiiquszvXnzBtevX0dUVBSioqKwZs0aFBYWokWLFujUqROWLl3KOgYAFBYWyrTSr8qrxvXr15fabawIjo6OMv+3IpEIampqsLS0xJgxY75q9S7AnuXLl6Nnz564e/cuiouLERAQgLt37+Ly5cuIiopira+pqcmcw6pduzYePHiAJk2aACjbGZeXNWvWsO6bAHd8aW8nNzeX1x39b4GwkyUgICBQzYiKikLv3r1Rr149mTnr7du3/8Y9/HfKX5XmC01NTc7PfVW0PhMAREREcBZXzJ07d/DHH39g7969KC0tZX1VNzU1FR4eHrh8+bJEOx+7fXwt5ObNm4eNGzfCzs6OMSCJjY1FUlISxowZg7t37yI8PBzHjh1Dv379WMUS+DoPHjyAn5+fROrpnDlzYGdnx1q7f//+6N27N8aPH4+ZM2fi5MmTGDNmDI4dOwZ9fX2cP3+egxEIfCvEF60CAgIwfvx4iXOnJSUluHbtGhQVFRETE/Otusg5wiJLQEBAoBry+PFjbNiwQSpnvU6dOt+4ZxVj9OjRaN++PcaNG8dbjL59+2LMmDH4+eefeYvBNykpKYiMjERkZCSioqJQUFCA9u3b4/+1d/dxNZ//H8Bfp+g+3SyJUCcRqYjMiBCa+5C7yj1zs02TZNnCmLu1hcw2rDZjFGOzjdyXogyRilS6oVCL3FZzU53fH307P63D6HxO58Tr+Xj0+HKd03W9T83je97nuq73u3fv3ujdu7fcO5fOzs5o0KABAgIC0LRp0xo7QkLsjCo6kXvvvffQsmVLLFq0qNr48uXLce3aNXz//fdYsmQJ9u/fj4SEBLnWIuXJzs5GcXExHBwcUFJSAj8/P8THx0sr//27QubLevDggbQxuazjy8+St4E5PV/Vh1YxMTHo1q1btTYYGhoasLS0xPz589G6dWtlhSg4JllERCS4FStWYN26dRg8eDDs7e1rHBPz8fGRe43Nmzdj+fLlmDp1qsw15C2uMXXqVISEhEBfX7/aeElJCebMmYMffvhBrvkBQE1NDY0bN8ZHH32EIUOGwN7eXtB+X7q6ujh37pzMvjRCUXQiZ2BggHPnztXYsczMzETnzp1x//59pKWloUuXLjL7mpEwzp8/j4YNG0p3rX7//Xf8+OOPsLW1xWeffSZY7zihPXsHSE1NTea/r/p0j7O+mzJlCkJCQt6IhJZJFhGRinFxcZHuZCi68pyiiMXi5z4mEomQnZ0t9xov6hcmxBum513Qvn37NszMzKR9reQxd+5cxMbGIjU1FZ06dZL+3nv06CFIGfcuXbpg7dq1Cm0Qq+hErkmTJvjyyy8xceLEauNbt26Fv78//v77b6SmpqJXr164deuWQmKgyv+WAgIC4OHhgezsbNja2mLkyJE4e/YsBg8erLJ3n2JiYqQfBPzX3bFevXrVUVT0JmDhCyIiFePm5obY2FisWbMGZWVlcHJyqlZ5TqgeSoqUk5Oj8DX+ffdHKA8ePIBEIoFEIsHDhw+rJbnl5eWIjIyskXjVVtUb03v37uHEiROIiYnBp59+ikuXLsHR0bFW9xOePRL1xRdfYMGCBVi5cqXM3T4hPk22tbWVqzDBf5kzZw5mzZqFc+fOoUuXLgAq72SFhobik08+AQAcOnQIHTt2VFgMVHm0tepn/Msvv6BXr17YsWMH4uLiMG7cuFolWXVR+e/ZxIlJFNUlJllERComMDAQQGXj27NnzyImJgbHjx9HUFAQ1NTU8OjRIyVH+GqqDkwIeQxOkQwNDSESiSASiWqU0QcqX8fSpUsFXbO8vBxPnz7F48eP8ejRIzx+/Bjp6em1mqsq/ioSiQR9+/at9hwhj0cpOpELDAyEWCzGhg0bsG3bNgCAjY0Nvv/+e3h5eQEAZs2axT5KCiaRSKQfbBw9ehRDhgwBALRo0aLWSbYydr8ePXqE5ORkmUVahOjfR1SFxwWJiFRUVVGE6OhoaVEEFxcX/Pbbb8oO7aVs3boVX375Ja5cuQIAaNOmDfz9/TFhwgTB1oiJicFXX32Fy5cvA6jcVfH395erAmNMTAwkEglcXV2xZ88eGBsbSx/T0NCAhYWFYAVIfHx8cPz4caSmpsLIyAguLi7o1asXevfuXev7Wa9STluIT/arjm3+O1bec3m9uLq6okWLFujXrx+mTZuG1NRUWFtbIyYmBpMmTap1H6u6dPDgQUycOFFmUsj/VkloTLKIiFSMl5dXtaSq6k23g4NDvdkNWrNmDRYtWoQPP/wQzs7OAICTJ0/im2++wfLly+Hr6yv3Gj///DOmTJmCkSNHSteIi4vDb7/9hi1btkh3OWrr2rVraNmypUJ/5qNHj5b+fu3s7ASfPzc3Fy1atJCZAOXl5QnSJ6uu7rmoQq+vN1lycjK8vb2Rm5uLefPmYcmSJQAqj3MWFRVhx44drzxnXVf+a926Ndzc3LB48WKF9e8jqsIki4hIxaipqcHExARTp06Fq6urYEUQ6pJYLMbSpUtrFCv46aef8NlnnwlyZ6tdu3aYMWNGjYRtzZo1+P7776W7W7X1448/Qk9PD6NHj642/ssvv6C0tBSTJk2Sa/5XMXjwYISGhqJp06av9H3PK95RVFQEU1PTevHJfV32+qJX9+jRI6irq9eq0XRdV/5r1KgREhMTFdq/j6gK72QREamYoqIinDhxAsePH8fChQtx+fJldOzYUVp5zs3NTdkh/qf8/Hx07969xnj37t2Rn58vyBrZ2dkYOnRojfFhw4ZJCyLIY9WqVdi0aVONcVNTU8yYMaNOk6zY2Fj8888/r/x9VW9Q/624uFjQqpUnTpzApk2bkJ2djV9++QXm5ubYtm0bxGKx3JUNJ0+ejAYNGmDfvn0yS8RT3RJyRzEqKkp6HFcRzb3/bdSoUTh+/DiTLKoTTLKIiFSMkZERhg0bJr2EnZmZieXLl+PLL7/EF198US8+ube2tsauXbtqJDs7d+4UrNlkixYtcOzYsRr9k44ePYoWLVrIPX9ubq7MUvQWFhbIzc2Ve35FmjdvHoDKeyaLFi2qthNaXl6O06dPC1aNb8+ePZgwYQK8vb1x/vx5PH78GABw//59rFy5EpGRkXLNf+HCBYX3+qL/lpGRgWnTpgm6o1jXlf82bNiA0aNH48SJEwrr30dUhUkWEZGKKSoqklYUrCqKYGhoiKFDh9abEsRLly7F2LFjERsbW+2+1LFjx7Br1y5B1vDz84OPjw8uXLgg3TWLi4vDli1bEBISIvf8pqamSE5OhqWlZbXxpKQkvPXWW3LPr0iJiYkAKt8Ap6SkVGsUq6GhgQ4dOmD+/PmCrLV8+XJs3LgREydOREREhHTc2dkZy5cvl3t+RZeIp5czZcoUhe8oKrryX3h4OA4fPgwtLS0cP3682msQiURMskhYEiIiUilqamoSU1NTiYeHh2T9+vWS5ORkZYdUKwkJCRJvb29Jp06dJJ06dZJ4e3tLzp8/L+gav/76q8TZ2VlibGwsMTY2ljg7O0v27t0ryNwLFiyQWFhYSKKioiRlZWWSsrIyybFjxyQWFhYSPz8/QdZ4WXp6epKsrKxX/r7JkydL7t+/r4CI/p+2trYkJydHIpFUjzMrK0uiqakp9/zHjh2TdOvWTRIdHS25ffu25P79+9W+qG7o6OhILl++rLD5Dxw4IGncuLFEJBLV+FJTUxNkjSZNmkhWrFghKS8vF2Q+ohdh4QsiIhVz6dIltG/f/j+fFxcXBycnJ2hqatZBVG+eJ0+eYMKECfjll1/QoEHlwY+KigpMnDgRGzdurLY7pGj6+vpISkqClZVVna35sqysrLB582b069evWpxbt27F6tWrkZqaKtf8VSXiAdTo/8XCF3WnS5cuWLt2rdx37J6nLir/GRsb4+zZs7yTRXWCSRYRUT3VqFEjXLhwQSXfeEdGRkJdXR3vvvtutfFDhw6hoqICAwcOlHuNs2fPoqKiAl27dq02fvr0aairq8PJyUnuNYDKuyhJSUnQ1taGvb09LCwsBJn3VdQ2ySopKcHq1atx7NgxmUewsrOz5Y5t1apV+Pnnn/HDDz+gf//+iIyMxLVr1+Dr64tFixZhzpw5cs1fVyXi6cWioqIQGBiosKbTdVH5z9fXF40bNxakMA7Rf+GdLCKiekqVPyMLCAjA6tWra4xLJBIEBAQIkmR98MEHWLBgQY0k68aNG/jiiy9w+vRpudcAKpsot2nTRpC5auuTTz6p1hT5ZU2fPh0xMTGYMGGCwu7RBAQEoKKiAn379kVpaSlcXFygqamJ+fPny51gAZVJVFX1wqysLOzevbta9UKqG/369QMA9O3bt9q4UDuKdVH5r7y8HEFBQTh06BAcHBxqJIpr1qxR2Nr05uFOFhFRPaXKR8i0tbVx+fLlGkUjrl69ivbt26OkpETuNfT09JCcnFzj9efk5MDBwQEPHz6Ua/7y8nJs2bLlubtAUVFRcs1fZdu2bdi4cSNycnJw6tQpWFhYYN26dRCLxXB3d5drbkNDQ+zfv19afESRnjx5gszMTBQXF8PW1hZ6enqCzPts9cJt27YhNTUVVlZW2LBhAyIjI+WuXkgvR9E7iqWlpRg9ejQaN26ssMp/ffr0ee5jIpFIsH/TRAB3soiISAEMDAyQnZ1dI8nKzMyErq6uIGtoamri77//rpFk5efnS+9QyeOjjz7Cli1bMHjwYNjZ2SlkF+i7777D4sWLMXfuXKxYsUK6G2BoaIh169bJnWQZGRnVagesNnJzc5GXlwcXFxdoa2s/t0fXq1J09UJ6OYo+llkXlf/qohcXURXuZBER1VOqvJM1c+ZMnDp1Cr/99pv0+E9mZiY8PDzQpUsXhIaGyr2Gp6cn8vPz8fvvv8PAwAAAcO/ePQwfPhympqZyl4o3MTHB1q1bMWjQILljfR5bW1usXLkSw4cPr/b7vHjxInr37i136fKff/4Zv//+O3766adqvbKEVFRUhDFjxiA6OhoikQhXrlyBlZUVpk6dCiMjIwQHB8s1v46ODlJTU2FpaVntZ5SdnQ1bW1s8evRIoFdC/+XevXsICwvD5cuXAQDt27fH1KlTpf/+5GFmZgYfHx8EBARUK3ZCVF9xJ4uIqJ5SxM6KUIKCgjBgwAC0bdsWzZs3BwBcv34dPXv2xFdffSXIGl999RVcXFxgYWEBR0dHAJWNa5s0aYJt27bJPb+GhkaNRsdCy8nJkcb+LE1NTUGOVAYHByMrKwtNmjSBpaVljSNY58+fl3sNX19fNGzYELm5uWjXrp10fOzYsZg3b57cSZaZmRkyMzNr7IqePHlSJT9geF0lJCTg3Xffhba2Nt5++20AlXeYVqxYgcOHD6NTp05yzf/kyROMHTtW8ARr5MiR2LJlCxo1aoSRI0e+8Lm//vqroGvTm41JFhFRPaXKBxEMDAwQHx+PI0eOSCvzOTg4wMXFRbA1zM3NkZycjO3bt0vXmDJlCjw9PWskE7Xh5+eHkJAQbNiwQWEJrVgsxoULF2pULDx48GC1hKW2hg8fLvcc/+Xw4cM4dOiQNJmu0rp1a1y7dk3u+d977z189NFH+OGHHyASiXDz5k2cOnUK8+fPx6JFi+Sen16Or68vhg0bhu+//156HLesrAzTp0/H3LlzERsbK9f8kyZNws6dOwWv/GdgYCD99yvEjhvRy+JxQSIiFVRWVobjx48jKysLXl5e0NfXx82bN9GoUSPBCgqoAnt7e0RGRqJFixbKDqWGESNGIDo6GsbGxmjfvn2NxE2IT71DQ0Px2WefITg4GNOmTUNoaCiysrKwatUqhIaGYty4cXKvoWj6+vo4f/48WrduXe04X9XOR1FRkVzzSyQSrFy5EqtWrUJpaSkASKsXfv7550K8BHoJ2traSExMRNu2bauNp6amwsnJSfq7qS0fHx9s3boVHTp0UFjlv3/++QcVFRXSe6FXr17F3r170a5duxrtJojkxZ0sIiIVc+3aNQwYMAC5ubl4/Pgx+vfvD319fXzxxRd4/PgxNm7cqOwQBXP16lU8ffq0Vt/7008/wcTEBIMHDwYALFiwAJs3b4atrS3Cw8Pl7mdlaGiIESNGyDXHf5k+fTq0tbURGBiI0tJSeHl5oVmzZggJCREswbp37x52796NrKws+Pv7w9jYGOfPn0eTJk1gbm4u9/w9e/bE1q1bpQmPSCRCRUUFgoKCXljN7WWJRCJ8+umn8Pf3V0j1Qno5jRo1Qm5ubo0kKy8vD/r6+nLPn5KSIj06e/HixWqPCbWT7O7ujpEjR2LWrFm4d+8e3nnnHTRs2BC3b9/GmjVrMHv2bEHWIQIASIiISKW4u7tLxo8fL3n8+LFET09PkpWVJZFIJJLo6GiJtbW1kqMT1rOv71W1adNGcuzYMYlEIpHEx8dLtLW1JZs2bZIMHTpUMmLECCHDrBMlJSWSv//+W9A5k5KSJI0bN5ZYW1tLGjRoIP1Zf/rpp5IJEyYIskZKSorE1NRUMmDAAImGhoZk1KhRknbt2kmaNGkiyczMFGQNUr45c+ZImjdvLomIiJDk5uZKcnNzJeHh4ZLmzZtLPvroI2WH91LeeustycWLFyUSiUTy/fffSxwcHCTl5eWSXbt2Sdq2bavk6Oh1w50sIiIVc+LECcTHx0NDQ6PauKWlJW7cuKGkqFRPXl6etDDF3r17MWrUKMyYMQPOzs7o3bu3coOrBR0dHcErAM6bNw+TJ09GUFBQtd2GQYMGwcvLS5A17OzskJGRgQ0bNkBfXx/FxcUYOXIkPvjgAzRt2lSQNUj5vvrqK4hEIkycOBFlZWUAgIYNG2L27NkyG4+rotLSUum/g8OHD2PkyJFQU1PDO++8I8j9QaJnMckiIlIxFRUV0n5Jz7p+/bogx3JeF3p6eigqKkLLli1x+PBhzJs3DwCgpaWFf/75R+75xWLxC48pZWdn12peR0fHlz7+JG/1v7Nnz2LTpk01xs3NzVFQUCDX3M8yMDDAp59+Kth8pHo0NDQQEhKCVatWISsrCwDQqlUruT4YqOvKf9bW1ti7dy9GjBiBQ4cOwdfXFwBQWFiIRo0ayT0/0bOYZBERqRg3NzesW7cOmzdvBlB5H6G4uBhLlixRaM+m+qZ///6YPn06HB0dkZGRIf3ZXLp0qUa579qYO3dutb8/ffoUiYmJOHjwIPz9/Ws9b11U/KuiqamJBw8e1BjPyMhA48aNBVnDxcUFvXv3Ru/evdG9e3doaWkJMi+pJh0dHRgaGkr/LI+6rvy3ePFieHl5wdfXF3379kW3bt0AVO5qyWqlQCQPVhckIlIx169fx7vvvguJRIIrV67AyckJV65cgYmJCWJjY2FqaqrsEAUjT0Ple/fuITAwEHl5eZg9ezYGDBgAAFiyZAk0NDQUtrPyzTffICEhAT/++KNC5hfS9OnTUVRUhF27dsHY2BjJyclQV1fH8OHD4eLignXr1sm9xvLlyxEbG4v4+HiUlZXByckJvXv3Rq9eveDs7KywJshUt8rKyrB06VKsX78excXFACp3k+fMmYMlS5bI3Tahrir/FRQUID8/Hx06dJD25Dpz5gwaNWpUo6gHkTyYZBERqaCysjJEREQgOTkZxcXF6NSpE7y9vaGtra3s0AS1Y8cOuLu7S99Y1QfZ2dno2LGjzB2i2kpISMDly5cBALa2tujcubMg896/fx+jRo1CQkICHj58iGbNmqGgoADdunVDZGSkoD/3srIynD17FjExMTh+/DiioqKgpqaGR48eCbYGKc/s2bPx66+/YtmyZdIdoFOnTuGzzz7D8OHD8d1338k1v5ubW7XKf23btmXlP6rXmGQREZHg1q9fL3NcJBJBS0sL1tbWcHFxgbq6+ivNm5ycDDs7O6ipqSE5OfmFz3VwcHiluV9WUFAQvv32W1y9elXuua5fvw5PT0/ExcVJj2Ddu3cP3bt3R0RERI0Gv7UVFxeHpKQkacLer18/QeZ9VkZGBo4fP47o6GjExMTg8ePHcHFxwW+//Sb4WlT3DAwMEBERgYEDB1Ybj4yMhKenJ+7fvy/X/CYmJoiJiUH79u0RGhqKr7/+GomJidizZw8WL14s/RCCqL7gnSwiIhXzxx9/yBx/NkERi8V1HNWrWbt2LW7duoXS0lIYGRkBAO7evQsdHR3o6emhsLAQVlZWiI6OfqVGxB07dkRBQQFMTU3RsWNHiEQiPPtZYdXfRSKRzOIhr+LfBSokEgkKCgpw69YtfPvtt3LNXWX69Ol4+vQpLl++DBsbGwBAeno6pkyZgunTp+PgwYO1nvvp06fQ1tbGhQsX4OzsDGdnZ0Fi/jcvL69qSVWvXr0QEBAABwcHwfobkfJpamrKvOsoFotrVEKtDVb+o9cNd7KIiFSMmppajeQBqJ5A9OjRA3v37pUmMKomPDwcmzdvRmhoKFq1agUAyMzMxMyZM6Vl1seNGwczMzPs3r37pee9du0aWrZsCZFI9J9vvORtRrx06dJqf1dTU0Pjxo3Ru3dvwe5uaGtrIz4+vsal+3PnzqFnz54oLS2Va34rKyv89ttv6NChg1zzvIiamhpMTEwwdepUuLq6okePHryH9RpatmwZ0tLS8OOPP0JTUxMA8PjxY0ybNg2tW7fGkiVL5JrfwcEB06dPx4gRI2BnZ4eDBw+iW7duOHfuHAYPHixoNUyiusAki4hIxRw7dgyffvopVqxYgbfffhtA5cXsRYsWITAwEAYGBpg5cya6du2KsLAwJUcrW6tWrbBnzx507Nix2nhiYiI8PDyQnZ2N+Ph4eHh4ID8/XzlBqoA2bdrg559/lv6eq5w5cwZeXl7IzMyUa/6wsDD8+uuv2LZtG4yNjeWa63nu3r2LEydO4Pjx44iJicHly5fRsWNHacVBNzc3haxLdWvEiBE4duwYNDU1pUl7UlISnjx5gr59+1Z7bm3Kre/evRteXl4oLy9H3759cfjwYQDAqlWrEBsbiwMHDsj/IojqEJMsIiIVY2dnh82bN6N79+7VxuPi4jBjxgxcunQJR48exdSpU5Gbm6ukKF9MR0cHsbGxcHJyqjZ+9uxZ9OrVC6Wlpbh69Srs7OyklcpexvOOUsoybNiwl35ulQcPHkj75fxXYQsdHR00aCDfqfvff/8dK1euxDfffCP9WSUkJGDOnDn4+OOP5S737ujoiMzMTDx9+hQWFhY1Cl3I24dLlszMTCxfvhzbt29/bs83qn+mTJny0s+tbeVNVv6j1wmTLCIiFaOtrY2zZ8/Czs6u2nhKSgrefvtt/PPPP7h27RratWsn93EyRak63hMaGio9CpeYmIj33nsPZmZm2LdvH/7880988sknSElJeel5q954VZF1J6tKbd7cq6urIz8/H6amptJjm88jEonQunVrfPvtt+jTp88rrwUARkZGKC0tRVlZmTRhq/rzvxOiO3fuvPL8/z7y+G/yHvECgKKiImlFwePHjyM1NRWGhobS+1kfffSR3GsQEdU3TLKIiFRMjx49oK+vj61bt0obxt66dQsTJ05ESUkJYmNjcfToUXzwwQdIT09XcrSyFRQUYMKECTh27Ji0f05ZWRn69u2Lbdu2oUmTJoiOjsbTp09rfZzs6NGj+Pjjj7Fy5cpqJaUDAwOxcuVK9O/f/5XnjImJgbOzMxo0aICYmJgXPvfx48fYu3cvoqKikJaWVqvX8NNPP730cydNmlSrNRRNXV0dJiYm6NmzJ3r16oXevXvD3t5e2WGRwP755x9IJBLpfbtr167ht99+g62tLY+EEsnAJIuISMWkp6fD3d0dOTk50sp7eXl5sLKywu+//442bdpg7969ePjwISZMmKDkaF8sLS0NGRkZAAAbGxtpBT0h2NnZYePGjejRo0e18RMnTmDGjBl1UvK5sLAQgwYNQkJCgsLXUlWXLl1C+/btlR0GKdi/+1jZ2NhAQ0ODfayInoNJFhGRCqqoqMDhw4erJSj9+/evcVxOVZ08ebJG8iO05x2rTE5ORteuXfHPP//IvUZFRQUyMzNRWFiIioqKao+5uLjIPX+VwsJCmWvI2+urvLwca9euxa5du5Cbm4snT55Ue7w2RxD/zdXVFb/++qu0z1eVBw8eYPjw4YiKipJ7DVI+9rEiejVMsoiISHAaGhowNzeHp6cnxo8fD1tbW8HXcHFxgZaWlvT4IQD8/fffmDhxIh49evSfx/3+y19//QUvLy9cu3ZNZjl9IQo6nDt3DpMmTcLly5cVssbixYsRGhoKPz8/BAYG4tNPP8XVq1exd+9eLF68GD4+PnLND1Tek6vqXfaswsJCmJub4+nTp3KvQcqno6ODtLQ0tGzZEmPGjEH79u2xZMkS5OXlwcbGRmXvhxIpC5sRExGpoJKSEsTExMjcfRDijbGi3bx5ExEREQgPD8fq1avh4OAAb29veHp6onnz5oKs8cMPP2DEiBFo2bJltWOVrVu3xt69e+Wef9asWXBycsL+/fvRtGlThTTWnTp1Ktq0aYOwsDA0adJE8DW2b9+O77//HoMHD8Znn30GT09PtGrVCg4ODvjrr7/k+m8pOTlZ+ufU1NRqfYzKy8tx8OBBmJubyxU/qQ5ra2vs3bsXI0aMwKFDh+Dr6wugMpmuqshJRP+PO1lERComMTERgwYNQmlpKUpKSmBsbIzbt29DR0cHpqamyM7OVnaIryQnJwc7duxAeHg40tLS4OLiItgRMolEgiNHjkgLT7Rr1w79+vUTJFnR1dVFUlISrK2t5Z7refT19ZGYmKiwNXR1dXH58mW0bNkSTZs2xf79+9GpUydkZ2fD0dER9+/fr/Xcz1ZflPVWQltbG19//TWmTp1a6zVIdTzbx8rV1RVHjhwBwD5WRM/DnSwiIhXj6+uLoUOHYuPGjTAwMMBff/2Fhg0bYvz48fWyHLZYLEZAQAA6dOiARYsWyX2M71kikQhubm4vrG5mb2+PyMhI6W7Xy+ratSsyMzMVmmT17dtXoYlc8+bNkZ+fj5YtW6JVq1Y4fPgwOnXqhLNnz0JTU1OuuXNyciCRSGBlZYUzZ85IK2EClcdFTU1Noa6uLu9LIBUxatQo9OjRQ9rHqkrfvn0xYsQIJUZGpJq4k0VEpGIMDQ1x+vRp2NjYwNDQEKdOnUK7du1w+vRpTJo0qdblwpUhLi4O27dvx+7du/Ho0SO4u7vD29sbAwYMqLMY9PX1kZSUBCsrq1f6vt9++w2BgYHw9/eHvb29tBR9FXmLUgDA7du3MWnSJLz99tuws7OrsUZtGio/KyAgAI0aNcInn3yCnTt3Yvz48bC0tERubi58fX2xevVqueanN09mZiaysrLg4uICbW1tSCQShRylJarvuJNFRKRiGjZsKK0iaGpqitzcXLRr1w4GBgbIy8tTcnQvZ+HChYiIiMCNGzfg5uaGkJAQuLu7S3vs1AceHh4AUO24W1XzY6EKX5w6dQpxcXEyj1oJscazSdTYsWPRsmVLnDp1Cq1bt8bQoUPlmvtZ27Ztw8aNG5GTk4NTp07BwsICa9euhZWVFdzd3QVbh5SnqKgIY8aMQXR0NEQiEa5cuQIrKytMmzYNRkZGCA4OVnaIRCqlftQCJiJ6gzg6OuLs2bMAgF69emHx4sXYvn075s6dW6NcuaqKjY2Fv78/bt68iX379sHT07NeJVhA5XG4f39lZ2dL/1cIc+bMwfjx45Gfn4+KiopqX0Ikcf/WrVs3zJs3T9AE67vvvsO8efMwaNAg3Lt3Txq3kZER1q1bJ9g6pFy+vr5o2LAhcnNzq/1bHjt2LA4ePKjEyIhUE48LEhGpmISEBDx8+BB9+vRBYWEhJk6ciPj4eLRu3Ro//PBDtfsQqi41NVVmhUR5j8G9itoeF6wL+vr6uHDhAlq1aqWwNdLT0/H1119L+xi1a9cOc+bMEawxtK2tLVauXInhw4dX+1lfvHgRvXv3xu3btwVZh5TLzMwMhw4dQocOHar9nrOzs+Hg4IDi4mJlh0ikUnhckIhIhUgkEpiamkp3rExNTevlp8Q5OTkYMWIEkpOTpUfsAEjvbihil0YRsrKysG7dOmmCYmtri48++kiwpGjkyJGIjo5WWJK1Z88ejBs3Dk5OTujWrRuAyv5fdnZ2iIiIkB6JlEdOTg4cHR1rjGtqaqKkpETu+Uk1lJSUyNyNvnPnjtxFVIheR0yyiIhUiEQigbW1NS5duoTWrVsrO5xa8/HxgaWlJY4ePQqxWIwzZ86gqKgIfn5++Oqrr5Qd3ks5dOgQhg0bho4dO8LZ2RlAZSGP9u3b488//0T//v3lXqNNmzZYuHAhTp48KbO4hrw90RYsWICFCxdi2bJl1caXLFmCBQsWCJJkicViXLhwARYWFtXGDx48iHbt2sk9P6mGnj17YuvWrfj8888BVH5gUlFRgaCgIPTp00fJ0RGpHh4XJCJSMe3bt0dYWBjeeecdZYdSayYmJoiKioKDgwMMDAxw5swZ2NjYICoqCn5+fkhMTKyzWHbs2AF3d3fo6uq+0vc5Ojri3XffrVGBLyAgAIcPH8b58+fljk0sFj/3MZFIJPfdLx0dHSQnJ9coEX/lyhV06NABpaWlcs0PAKGhofjss88QHByMadOmITQ0FFlZWVi1ahVCQ0Mxbtw4udcg5bt06RJcXV3RqVMnREVFYdiwYbh06RLu3LmDuLg4hR55JaqPuJNFRKRiVq9eDX9/f3z33Xf1ptDFv5WXl0NfXx9AZcJ18+ZN2NjYwMLCAunp6YKssX79epnjIpEIWlpasLa2houLC7y8vGo1/+XLl7Fr164a41OnThWsoENOTo4g8zxP7969ceLEiRpJ1smTJ9GzZ09B1pg+fTq0tbURGBiI0tJSeHl5oVmzZggJCWGC9Zp4+vQpfHx88Oeff+LIkSPQ19dHcXExRo4ciQ8++ABNmzZVdohEKodJFhGRipk4cSJKS0vRoUMHaGhoQFtbu9rjd+7cUVJkL8/Ozg5JSUkQi8Xo2rUrgoKCoKGhgc2bNwtWgGLt2rW4desWSktLYWRkBAC4e/cudHR0oKenh8LCQlhZWSE6OvqVGxEDQOPGjXHhwoUaxzYvXLgAU1NTQV6Dog0bNgwff/wxzp07J90Z/euvv/DLL79g6dKl+OOPP6o9t7a8vb3h7e2N0tJSFBcX15ufD72chg0bIjk5GUZGRvj000+VHQ5RvcDjgkREKuann3564eOTJk2qo0hq79ChQygpKcHIkSORmZmJIUOGICMjA2+99RZ27twJV1dXudcIDw/H5s2bERoaKj2qlJmZiZkzZ2LGjBlwdnbGuHHjYGZmht27d7/y/MuWLcPatWsREBCA7t27A6i8k/XFF19g3rx5WLRokdyvAQCuX7+OP/74Q2YVxjVr1sg1d1W/tf8iRE+uwsJC6S5l27Zt0bhxY7nmI9Xi6+sLTU1NNrAmeklMsoiIqE7cuXMHRkZG0gqD8mrVqhX27NmDjh07VhtPTEyEh4cHsrOzER8fDw8PD+Tn57/y/BKJBOvWrUNwcDBu3rwJAGjWrBn8/f3h4+MjyOs4duwYhg0bBisrK6SlpcHOzg5Xr16FRCKR3n1RdQ8fPsT777+P8PBwVFRUAADU1dUxduxYfPPNNzAwMFByhCSEOXPmYOvWrWjdujU6d+5c446jvB8IEL1u2IyYiEgFZWVlITAwEJ6enigsLAQAHDhwAJcuXVJyZLVnbGwsWIIFAPn5+SgrK6sxXlZWhoKCAgCVSdHDhw9rNb9IJIKvry+uX7+O+/fv4/79+7h+/To++ugjwV7HwoULMX/+fKSkpEBLSwt79uxBXl4eevXqhdGjRwuyxsuwt7dHXl5erb53+vTpOH36NPbv34979+7h3r172LdvHxISEjBz5kyBIyVluXjxIjp16gR9fX1kZGQgMTFR+nXhwgVlh0ekcriTRUSkYmJiYjBw4EA4OzsjNjYWly9fhpWVFVavXo2EhIRaHX17HQ0ePBgFBQUIDQ2V9mlKTEzEe++9BzMzM+zbtw9//vknPvnkE6SkpLzy/Dk5OSgrK6txJ+vKlSto2LAhLC0t5X4NzzYjNjIywsmTJ9G+fXskJSXB3d0dV69elXuNl42jtg2bdXV1cejQIfTo0aPa+IkTJzBgwAD2yiKiNxJ3soiIVExAQACWL1+OI0eOQENDQzru6uqKv/76S4mRqZawsDAYGxujc+fO0NTUhKamJpycnGBsbIywsDAAgJ6eHoKDg2s1/+TJkxEfH19j/PTp05g8ebI8oUvp6upK72E1bdoUWVlZ0sdu374tyBqK9tZbb8k8EmhgYCAtSEJE9KZhdUEiIhWTkpKCHTt21Bg3NTWtN2+864KZmRmOHDmCtLQ0ZGRkAABsbGxgY2MjfY48TVITExOlTYif9c477+DDDz+s9bz/nuvkyZNo164dBg0aBD8/P6SkpODXX3+tN33SAgMDMW/ePGzbtg1mZmYAgIKCAvj7+wtWHISIqL5hkkVEpGIMDQ2Rn59fo1FtYmIizM3NlRSV6jl58iR69OiBtm3bom3btoLPLxKJZN7nun//vtyV+KqsWbMGxcXFAIClS5eiuLgYO3fuROvWrVW6kICjo2O1e2lXrlxBy5Yt0bJlSwBAbm4uNDU1cevWLd7LIqI3EpMsIiIVM27cOHz88cf45ZdfIBKJUFFRgbi4OMyfPx8TJ05Udngqw9XVFebm5vD09MT48eNha2sr6PwuLi5YtWoVwsPDoa6uDqCyyfKqVatq3D+qrWfvQOnq6mLjxo2CzKtow4cPV3YIREQqjYUviIhUzJMnT/DBBx9gy5YtKC8vR4MGDVBeXg4vLy9s2bJF+ob/TXf79m1EREQgPDwcp06dgoODA7y9veHp6YnmzZvLPX9qaipcXFxgaGiInj17Aqgs5vDgwQNERUXBzs5O7jWio6Ofe6Rx06ZNdbYLJE/hi5cVHh6OYcOG1Sj9TUT0OmKSRUSkonJzc3Hx4kUUFxfD0dGxRpU7+n85OTnYsWMHwsPDkZaWBhcXF0F6TN28eRMbNmxAUlIStLW14eDggA8//BDGxsYCRA1oamrCx8cHK1euRMOGDQFUJo9TpkzByZMncffuXUHW+S87duyAu7u7QhOgRo0a4cKFCwpN5IiIVAWTLCIiFVN114heTXl5OQ4cOIBFixYhOTlZsHtT/+X999/HsmXLYGJi8srfGx8fj4kTJ0JPTw87duxATk4Opk2bBhsbG2zduhUWFhZyxbZ+/XqZ4yKRCFpaWrC2toaLi0ud7I7WxW4ZEZGqYJJFRKRiNDQ0FHrX6HUTFxeH7du3Y/fu3Xj06BHc3d3h7e2NAQMG1Mn68u7QFBcXY9asWdi9ezcqKirw+eefY8GCBYI0PBaLxbh16xZKS0ul5dTv3r0LHR0d6OnpobCwEFZWVoiOjkaLFi3kXu9FmGQR0ZuEfbKIiFTMzZs34efnh5iYGNjZ2aFjx4748ssvcf36dWWHplIWLlwIsViMPn36IDc3FyEhISgoKMC2bdvqLMECAHk/q8zIyEBCQgKaN2+OBg0aID09HaWlpYLEtnLlSnTp0gVXrlxBUVERioqKkJGRga5duyIkJAS5ubkwMzODr6+vIOsREVEl7mQREakwRd01eh04OzvD29sbY8aMqdVRPaHIs0OzevVqLFmyBDNmzMCXX36JzMxMTJgwAQ8ePMDPP/+Mbt26yRVbq1atsGfPHnTs2LHaeGJiIjw8PJCdnY34+Hh4eHggPz9frrX+C3eyiOhNwhLuREQqTCwWIyAgAB06dMCiRYsQExOj7JBURlxcHIDKKoAJCQl48uRJtceHDRumjLBeSUhICPbu3YuBAwcCAOzs7HDmzBl88skn6N27Nx4/fizX/Pn5+SgrK6sxXlZWhoKCAgBAs2bNZPYDIyKi2mOSRUSkomTdNVq1apWyw1IZOTk5GDFiBJKTkyESiaTH9qruMtVV4Qt5pKSk1NiFa9iwIb788ksMGTJE7vn79OmDmTNnIjQ0FI6OjgAqd7Fmz54NV1dXaQz/bnytCBYWFtIKikRErzveySIiUjGqctdI1fn4+MDS0hKFhYXQ0dHBpUuXEBsbCycnJxw/flzZ4b0UExMT3Lt3D6GhoVi4cCHu3LkDADh//jysra3lnj8sLAzGxsbo3LkzNDU1oampCScnJxgbGyMsLAwAoKenh+DgYLnXAiqLeDx48KDaV5WLFy8qvLgGEZGq4J0sIiIVoyp3jVSdiYkJoqKi4ODgAAMDA5w5cwY2NjaIioqCn58fEhMT6ySO2bNn4/PPP6/V7yo5ORn9+vWDgYEBrl69ivT0dFhZWSEwMBC5ubnYunWrIDGmpaUhIyMDAGBjYwMbGxtB5gUqdxQ//PBDHD9+HI8ePZKOSyQSiESierGjSEQkNB4XJCJSMa/DXaO6UF5eDn19fQCVCdfNmzdhY2MDCwsLpKenC7LGvXv3cObMGRQWFqKioqLaYxMnTgQAfPfdd7We39fXF5MnT0ZQUJD0tQDAoEGD4OXlVet5q1T1XGvbti3atm0r93yyjB8/HhKJBD/88AOaNGkiSOl5IqL6jkkWEZGKeR3uGtUFOzs7JCUlQSwWo2vXrggKCoKGhgY2b94sSAW7P//8E97e3iguLkajRo2qJQ8ikUiaZMkjISEBmzdvrjFubm4uLUwhD1dXV4X3XEtKSsK5c+cE3R0jIqrveCeLiEjFvA53jepCYGCgdHdp2bJlyMnJQc+ePREZGYn169fLPb+fnx+mTp2K4uJi3Lt3D3fv3pV+Vd2dkpempma1e0tVMjIy0LhxY7nnr4uea126dEFeXp5g8xERvQ54J4uISMWoyl2j+ujOnTswMjIS5Miarq4uUlJSFNrXafr06SgqKsKuXbtgbGyM5ORkqKurY/jw4XBxccG6desEW0tRPdeysrIwa9YsjB8/HnZ2djUqCDo4OMi9BhFRfcPjgkREKqYu7hq9royNjQWb691330VCQoJCk6zg4GCMGjUKpqam+Oeff9CrVy8UFBSgW7duWLFihaBrKarn2q1bt5CVlYUpU6ZIx6qOubLwBRG9qZhkERGpGEXfNaLn++OPP6R/Hjx4MPz9/ZGamgp7e/saOzRCFCAxMDDAkSNHEBcXh6SkJBQXF6NTp07o16+f3HM/S5E916ZOnQpHR0eEh4ez8AUR0f/wuCARkYo5dOgQSkpKMHLkSGRmZmLIkCHIyMjAW2+9hZ07d0qbyJLw1NRe7qpyXe/Q2NvbIzIy8pX7TC1cuBARERG4ceMG3Nzc4O3tDXd3d+jo6AgWm66uLpKSkgTp60VE9LpgkkVEVA8IedeI6h99fX0kJSW98k5mXfRcGzp0KCZPngwPDw+FzE9EVB/xuCARUT0g5F0jqr179+7B0NBQ2WG8tLrouTZ06FD4+voiJSVFYccqiYjqG+5kERERyfDFF1/A0tISY8eOBQCMHj0ae/bsQdOmTREZGYkOHTrUWSy13cmqi55rLzpiycIXRPSmYp8sIiIiGTZu3Ci9A3XkyBEcPXoUBw8exMCBA+Hv76/k6F5OXfRcq6ioeO4XEywielPxuCAREZEMBQUF0iRr3759GDNmDNzc3GBpaYmuXbsqObqXc+rUKURFRcHExARqampQU1NDjx49sGrVKvj4+LDnGhGRgjDJIiIiksHIyAh5eXlo0aIFDh48iOXLlwMAJBJJvdmhUVTPtfXr12PGjBnQ0tLC+vXrX/hcHx+fWq9DRFRfMckiIiKSYeTIkfDy8kLr1q1RVFSEgQMHAgASExPrvFz5pk2b0KRJk1f+PkX1XFu7di28vb2hpaWFtWvXPvd5IpGISRYRvZFY+IKIiEiGp0+fIiQkBHl5eZg8eTIcHR0BVCYY+vr6mD59utxrPG8XSCQSQUtLC9bW1nBxcYG6unqt5mfPNSIi5WCSRUREpCRisRi3bt1CaWkpjIyMAAB3796Fjo4O9PT0UFhYCCsrK0RHR79yI+LnUXTPtfLycqSkpMDCwkL6moiI3jRMsoiIiP7njz/+wMCBA9GwYUP88ccfL3yuEP2fwsPDsXnzZoSGhqJVq1YAgMzMTMycORMzZsyAs7Mzxo0bBzMzM+zevVvu9RRh7ty5sLe3x7Rp01BeXg4XFxecOnUKOjo62LdvH3r37q3sEImI6hyTLCIiov9RU1NDQUEBTE1N66T/U6tWrbBnzx507Nix2nhiYiI8PDyQnZ2N+Ph4eHh4ID8/X+71FKF58+bYu3cvnJycsHfvXnzwwQeIjo7Gtm3bEBUVJW2ITET0JmGfLCIiov+pqKiAqamp9M+K7v+Un5+PsrKyGuNlZWUoKCgAADRr1gwPHz4UZD1FuH37NszMzAAAkZGRGD16NNq0aYOpU6ciJSVFydERESkHkywiIiIl6dOnD2bOnFmtX1ViYiJmz54tLUqRkpICsVisrBD/U5MmTZCamory8nIcPHgQ/fv3BwCUlpbWumAHEVF9xxLuRERE//NfPZ+eJURp8rCwMEyYMAGdO3dGw4YNAVTuYvXt2xdhYWEAAD09PQQHB8u9lqJMmTIFY8aMQdOmTSESidCvXz8AwOnTp9G2bVslR0dEpBy8k0VERPQ/L7tjJBKJkJ2dLdi6aWlpyMjIAADY2NjAxsZGsLnrwu7du5GXl4fRo0ejefPmAICffvoJhoaGcHd3V3J0RER1j0kWERGRkpw8eRI9evRQdhh1wt7eHpGRkYKVoiciUmW8k0VERKQkrq6uEIvF+OSTT5CamqrscBTq6tWrePr0qbLDICKqE7yTRUREJMO8efNkjotEImhpacHa2hru7u4wNjau9Ro3b95EREQEwsPDsXr1ajg4OMDb2xuenp7SY3dERFT/8LggERGRDH369MH58+dRXl4uvSOVkZEBdXV1tG3bFunp6RCJRDh58iRsbW3lXi8nJwc7duxAeHg40tLS4OLigqioKLnnVRX6+vpISkqClZWVskMhIlI4HhckIiKSwd3dHf369cPNmzdx7tw5nDt3DtevX0f//v3h6emJGzduwMXFBb6+voKsJxaLERAQgNWrV8Pe3h4xMTGCzEtERHWPO1lEREQymJub48iRIzV2qS5dugQ3NzfcuHED58+fh5ubG27fvi3XWnFxcdi+fTt2796NR48ewd3dHd7e3hgwYIBc86oS7mQR0ZuEd7KIiIhkuH//PgoLC2skWbdu3cKDBw8AAIaGhnjy5Emt11i4cCEiIiJw48YNuLm5ISQkBO7u7tDR0ZErdiIiUi4mWURERDK4u7tj6tSpCA4ORpcuXQAAZ8+exfz58zF8+HAAwJkzZ9CmTZtarxEbGwt/f3+MGTMGJiYmQoStsjZt2oQmTZooOwwiojrB44JEREQyFBcXw9fXF1u3bkVZWRkAoEGDBpg0aRLWrl0LXV1dXLhwAQDQsWNHudZKTU1Fbm5ujV2xYcOGyTVvXVi/fr3M8WerMLq4uEBdXb2OIyMiUh4mWURERC9QXFyM7OxsAICVlRX09PQEmzsnJwcjRoxAcnIyRCIRqv4vWSQSAQDKy8sFW0tRxGIxbt26hdLSUhgZGQEA7t69Cx0dHejp6aGwsBBWVlaIjo5mI2IiemOwuiAREdEL6OnpwcHBAQ4ODoImWADg4+MDS0tLFBYWQkdHB5cuXUJsbCycnJxw/PhxQddSlJUrV6JLly64cuUKioqKUFRUhIyMDHTt2hUhISHIzc2FmZmZYFUYiYjqA+5kERERyVBSUoLVq1fj2LFjKCwsREVFRbXHq3a35GFiYoKoqCg4ODjAwMAAZ86cgY2NDaKiouDn54fExES511C0Vq1aYc+ePTWOTCYmJsLDwwPZ2dmIj4+Hh4cH8vPzlRMkEVEdY+ELIiIiGaZPn46YmBhMmDABTZs2lR7hE1J5eTn09fUBVCZcN2/ehI2NDSwsLJCeni74eoqQn58vvbP2rLKyMhQUFAAAmjVrhocPH9Z1aERESsMki4iISIYDBw5g//79cHZ2VtgadnZ2SEpKglgsRteuXREUFAQNDQ1s3ry53vST6tOnD2bOnInQ0FA4OjoCqNzFmj17NlxdXQEAKSkpEIvFygyTiKhO8U4WERGRDEZGRjA2NlboGoGBgdJjiMuWLUNOTg569uyJyMjI51btUzVhYWEwNjZG586doampCU1NTTg5OcHY2BhhYWEAKu+1BQcHKzlSIqK6wztZREREMvz888/4/fff8dNPP9Vpc+A7d+7AyMhIIccTFSktLQ0ZGRkAABsbG9jY2Cg5IiIi5WGSRUREJIOjoyOysrIgkUhgaWmJhg0bVnv8/PnzSopMtZw8eRI9evRQdhhERCqFd7KIiIhkGD58uLJDqBdcXV1hbm4OT09PjB8/Hra2tsoOiYhI6biTRURERLV2+/ZtREREIDw8HKdOnYKDgwO8vb3h6emJ5s2bKzs8IiKlYJJFRET0HPfu3cPu3buRlZUFf39/GBsb4/z582jSpAnMzc2VHZ7KycnJwY4dOxAeHo60tDS4uLggKipK2WEREdU5JllEREQyJCcno1+/fjAwMMDVq1eRnp4OKysrBAYGIjc3F1u3blV2iCqpvLwcBw4cwKJFi5CcnIzy8nJlh0REVOdYwp2IiEiGefPmYfLkybhy5Qq0tLSk44MGDUJsbKwSI1NNcXFxeP/999G0aVN4eXnBzs4O+/fvV3ZYRERKwcIXREREMpw9exabNm2qMW5ubo6CggIlRKSaFi5ciIiICNy4cQNubm4ICQmBu7t7nZa9JyJSNUyyiIiIZNDU1MSDBw9qjGdkZKBx48ZKiEg1xcbGwt/fH2PGjIGJiYmywyEiUgm8k0VERCTD9OnTUVRUhF27dsHY2BjJyclQV1fH8OHD4eLignXr1ik7RJWSmpqK3NxcPHnypNr4sGHDlBQREZHyMMkiIiKS4f79+xg1ahQSEhLw8OFDNGvWDAUFBejWrRsiIyOhq6ur7BBVQk5ODkaMGIHk5GSIRCJUva0QiUQAwMIXRPRGYpJFRET0AnFxcUhKSkJxcTE6deqEfv36KTsklTJ06FCoq6sjNDQUYrEYZ86cQVFREfz8/PDVV1+hZ8+eyg6RiKjOMckiIiKSg729PSIjI9GiRQtlh6IUJiYmiIqKgoODAwwMDHDmzBnY2NggKioKfn5+SExMVHaIRER1jiXciYiI5HD16lU8ffpU2WEoTXl5OfT19QFUJlw3b94EAFhYWCA9PV2ZoRERKQ2rCxIREVGt2dnZISkpCWKxGF27dkVQUBA0NDSwefNmWFlZKTs8IiKlYJJFREREtRYYGIiSkhIAwLJlyzBkyBD07NkTb731Fnbu3Knk6IiIlIN3soiIiOSgr6+PpKQk7to8486dOzAyMpJWGCQietNwJ4uIiIgEZWxsrOwQiIiUioUviIiIiIiIBMQki4iISA6bNm1CkyZNlB0GERGpEN7JIiIikmH9+vUyx0UiEbS0tGBtbQ0XFxeoq6vXcWRERKTqmGQRERHJIBaLcevWLZSWlsLIyAgAcPfuXejo6EBPTw+FhYWwsrJCdHT0G9uImIiIZONxQSIiIhlWrlyJLl264MqVKygqKkJRUREyMjLQtWtXhISEIDc3F2ZmZvD19VV2qEREpGK4k0VERCRDq1atsGfPHnTs2LHaeGJiIjw8PJCdnY34+Hh4eHggPz9fOUESEZFK4k4WERGRDPn5+SgrK6sxXlZWhoKCAgBAs2bN8PDhw7oOjYiIVByTLCIiIhn69OmDmTNnIjExUTqWmJiI2bNnw9XVFQCQkpICsVisrBCJiEhFMckiIiKSISwsDMbGxujcuTM0NTWhqakJJycnGBsbIywsDACgp6eH4OBgJUdKRESqhneyiIiIXiAtLQ0ZGRkAABsbG9jY2Cg5IiIiUnVMsoiIiGQ4efIkevTooewwiIioHmKSRUREJIOGhgbMzc3h6emJ8ePHw9bWVtkhERFRPcE7WURERDLcvHkTfn5+iImJgZ2dHTp27Igvv/wS169fV3ZoRESk4riTRURE9B9ycnKwY8cOhIeHIy0tDS4uLoiKilJ2WEREpKKYZBEREb2E8vJyHDhwAIsWLUJycjLKy8uVHRIREakoHhckIiJ6gbi4OLz//vto2rQpvLy8YGdnh/379ys7LCIiUmHcySIiIpJh4cKFiIiIwI0bN+Dm5gZvb2+4u7tDR0dH2aEREZGKY5JFREQkg7OzM7y9vTFmzBiYmJgoOxwiIqpHmGQRERG9QGpqKnJzc/HkyZNq48OGDVNSREREpOoaKDsAIiIiVZSTk4MRI0YgOTkZIpEIVZ9JikQiAGDhCyIiei4WviAiIpLBx8cHlpaWKCwshI6ODi5duoTY2Fg4OTnh+PHjyg6PiIhUGI8LEhERyWBiYoKoqCg4ODjAwMAAZ86cgY2NDaKiouDn54fExERlh0hERCqKO1lEREQylJeXQ19fH0BlwnXz5k0AgIWFBdLT05UZGhERqTjeySIiIpLBzs4OSUlJEIvF6Nq1K4KCgqChoYHNmzfDyspK2eEREZEK43FBIiIiGQ4dOoSSkhKMHDkSmZmZGDJkCDIyMvDWW29h586dcHV1VXaIRESkophkERERvaQ7d+7AyMhIWmGQiIhIFiZZREREREREAmLhCyIiIiIiIgExySIiIiIiIhIQkywiIiIiIiIBMckiIiIiIiISEJMsIiIiIiIiATHJIiKiemny5MkQiUQ1vjIzM+Wee8uWLTA0NJQ/SCIieiM1UHYAREREtTVgwAD8+OOP1cYaN26spGhke/r0KRo2bKjsMIiIqA5xJ4uIiOotTU1NmJmZVftSV1fH77//jk6dOkFLSwtWVlZYunQpysrKpN+3Zs0a2NvbQ1dXFy1atMD777+P4uJiAMDx48cxZcoU3L9/X7o79tlnnwEARCIR9u7dWy0GQ0NDbNmyBQBw9epViEQi7Ny5E7169YKWlha2b98OAAgNDUW7du2gpaWFtm3b4ttvv5XO8eTJE3z44Ydo2rQptLS0YGFhgVWrVinuB0dERArFnSwiInqtnDhxAhMnTsT69evRs2dPZGVlYcaMGQCAJUuWAADU1NSwfv16iMViZGdn4/3338eCBQvw7bffonv37li3bh0WL16M9PR0AICent4rxRAQEIDg4GA4OjpKE63Fixdjw4YNcHR0RGJiIt577z3o6upi0qRJWL9+Pf744w/s2rULLVu2RF5eHvLy8oT9wRARUZ1hkkVERPXWvn37qiVAAwcOxN27dxEQEIBJkyYBAKysrPD5559jwYIF0iRr7ty50u+xtLTE8uXLMWvWLHz77bfQ0NCAgYEBRCIRzMzMahXX3LlzMXLkSOnflyxZguDgYOmYWCxGamoqNm3ahEmTJiE3NxetW7dGjx49IBKJYGFhUat1iYhINTDJIiKieqtPnz747rvvpH/X1dWFg4MD4uLisGLFCul4eXk5Hj16hNLSUujo6ODo0aNYtWoV0tLS8ODBA5SVlVV7XF5OTk7SP5eUlCArKwvTpk3De++9Jx0vKyuDgYEBgMoiHv3794eNjQ0GDBiAIUOGwM3NTe44iIhIOZhkERFRvaWrqwtra+tqY8XFxVi6dGm1naQqWlpauHr1KoYMGYLZs2djxYoVMDY2xsmTJzFt2jQ8efLkhUmWSCSCRCKpNvb06VOZcT0bDwB8//336Nq1a7XnqaurAwA6deqEnJwcHDhwAEePHsWYMWPQr18/7N69+z9+AkREpIqYZBER0WulU6dOSE9Pr5F8VTl37hwqKioQHBwMNbXK+k+7du2q9hwNDQ2Ul5fX+N7GjRsjPz9f+vcrV66gtLT0hfE0adIEzZo1Q3Z2Nry9vZ/7vEaNGmHs2LEYO3YsRo0ahQEDBuDOnTswNjZ+4fxERKR6mGQREdFrZfHixRgyZAhatmyJUaNGQU1NDUlJSbh48SKWL18Oa2trPH36FF9//TWGDh2KuLg4bNy4sdoclpaWKC4uxrFjx9ChQwfo6OhAR0cHrq6u2LBhA7p164by8nJ8/PHHL1WefenSpfDx8YGBgQEGDBiAx48fIyEhAXfv3sW8efOwZs0aNG3aFI6OjlBTU8Mvv/wCMzMz9uoiIqqnWMKdiIheK++++y727duHw4cPo0uXLnjnnXewdu1aaTGJDh06YM2aNfjiiy9gZ2eH7du31yiX3r17d8yaNQtjx45F48aNERQUBAAIDg5GixYt0LNnT3h5eWH+/PkvdYdr+vTpCA0NxY8//gh7e3v06tULW7ZsgVgsBgDo6+sjKCgITk5O6NKlC65evYrIyEjpThsREdUvIsm/D5cTERERERFRrfEjMiIiIiIiIgExySIiIiIiIhIQkywiIiIiIiIBMckiIiIiIiISEJMsIiIiIiIiATHJIiIiIiIiEhCTLCIiIiIiIgExySIiIiIiIhIQkywiIiIiIiIBMckiIiIiIiISEJMsIiIiIiIiAf0f9W0+k8ibrhUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exclude 'code' column\n",
    "columns_to_exclude = ['code']\n",
    "\n",
    "# Get columns for correlation (excluding 'code' and only considering 'grade')\n",
    "columns_for_correlation = final_df.columns.difference(columns_to_exclude + ['grade'])\n",
    "\n",
    "# Create a correlation matrix for selected columns with 'grade'\n",
    "correlation_matrix = final_df[columns_for_correlation].corrwith(final_df['grade'])\n",
    "\n",
    "# Visualize the correlations with 'grade' using a bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = sns.color_palette(\"coolwarm\", n_colors=len(correlation_matrix))\n",
    "color_mapping = dict(zip(sorted(correlation_matrix.unique()), colors))\n",
    "\n",
    "# Map correlation values to colors\n",
    "correlation_colors = correlation_matrix.map(color_mapping)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.bar(correlation_matrix.index, correlation_matrix.values, color=correlation_colors)\n",
    "plt.title('Correlation with Grade')\n",
    "plt.xlabel('Features')\n",
    "# Set y-axis ticks for both the upper and lower parts\n",
    "plt.yticks(np.arange(-1.0, 1.1, 0.1))\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.ylabel('Correlation Coefficient')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_df length:  126\n",
      "final_df shape:  (126, 31)\n",
      "column names:  Index(['code', '#user_prompts', 'total_discomfort_count',\n",
      "       'total_comfort_count', 'prompt_avg_words', 'response_avg_words',\n",
      "       'response_confusion_total_count', 'similarity_between_prompts',\n",
      "       'avg_sim_between_prompt_codeComment', 'similarity_between_fullpoints',\n",
      "       'total_message_length', 'average_word_count_per_sentence',\n",
      "       'average_word_length', 'english_conjunctions_count',\n",
      "       'example_words_count', 'total_parentheses_count', 'Q0', 'Q1', 'Q2',\n",
      "       'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'grade',\n",
      "       'avg_discomfort_count_per_prompt', 'avg_comfort_count_per_prompt',\n",
      "       'avg_example_words_count_per_prompt',\n",
      "       'avg_parentheses_count_per_prompt',\n",
      "       'avg_english_conjunctions_count_per_prompts'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>#user_prompts</th>\n",
       "      <th>total_discomfort_count</th>\n",
       "      <th>total_comfort_count</th>\n",
       "      <th>prompt_avg_words</th>\n",
       "      <th>response_avg_words</th>\n",
       "      <th>response_confusion_total_count</th>\n",
       "      <th>similarity_between_prompts</th>\n",
       "      <th>avg_sim_between_prompt_codeComment</th>\n",
       "      <th>similarity_between_fullpoints</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>grade</th>\n",
       "      <th>avg_discomfort_count_per_prompt</th>\n",
       "      <th>avg_comfort_count_per_prompt</th>\n",
       "      <th>avg_example_words_count_per_prompt</th>\n",
       "      <th>avg_parentheses_count_per_prompt</th>\n",
       "      <th>avg_english_conjunctions_count_per_prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0031c86e-81f4-4eef-9e0e-28037abf9883</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.071429</td>\n",
       "      <td>160.642857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.959773</td>\n",
       "      <td>0.558252</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788218</td>\n",
       "      <td>0.428342</td>\n",
       "      <td>0.461473</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.666667</td>\n",
       "      <td>169.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913921</td>\n",
       "      <td>0.556858</td>\n",
       "      <td>0.988546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.684214</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.491343</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.111111</td>\n",
       "      <td>160.444444</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.802151</td>\n",
       "      <td>0.331554</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249203</td>\n",
       "      <td>0.297617</td>\n",
       "      <td>0.538953</td>\n",
       "      <td>0.142434</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.904731</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.980123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.553139</td>\n",
       "      <td>0.538424</td>\n",
       "      <td>0.426416</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.697674</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.889234</td>\n",
       "      <td>0.470122</td>\n",
       "      <td>0.928597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916046</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.945931</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>3.151163</td>\n",
       "      <td>0.686047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   code  #user_prompts   \n",
       "0  0031c86e-81f4-4eef-9e0e-28037abf9883           14.0  \\\n",
       "1  0225686d-b825-4cac-8691-3a3a5343df2b           18.0   \n",
       "2  041f950b-c013-409a-a642-cffff60b9d4b            9.0   \n",
       "3  04f91058-d0f8-4324-83b2-19c671f433dc           20.0   \n",
       "4  089eb66d-4c3a-4f58-b98f-a3774a2efb34           86.0   \n",
       "\n",
       "   total_discomfort_count  total_comfort_count  prompt_avg_words   \n",
       "0                     8.0                  0.0         63.071429  \\\n",
       "1                     0.0                  0.0         39.666667   \n",
       "2                     8.0                  1.0         99.111111   \n",
       "3                     3.0                  0.0         17.750000   \n",
       "4                    16.0                  1.0         30.697674   \n",
       "\n",
       "   response_avg_words  response_confusion_total_count   \n",
       "0          160.642857                             2.0  \\\n",
       "1          169.166667                             1.0   \n",
       "2          160.444444                            12.0   \n",
       "3          148.500000                             3.0   \n",
       "4          123.000000                            19.0   \n",
       "\n",
       "   similarity_between_prompts  avg_sim_between_prompt_codeComment   \n",
       "0                    0.959773                            0.558252  \\\n",
       "1                    0.913921                            0.556858   \n",
       "2                    0.802151                            0.331554   \n",
       "3                    0.904731                            0.419597   \n",
       "4                    0.889234                            0.470122   \n",
       "\n",
       "   similarity_between_fullpoints  ...        Q5        Q6        Q7        Q8   \n",
       "0                       0.984955  ...  0.788218  0.428342  0.461473  0.285456  \\\n",
       "1                       0.988546  ...  0.987573  0.684214  0.729532  0.491343   \n",
       "2                       0.950704  ...  0.249203  0.297617  0.538953  0.142434   \n",
       "3                       0.980123  ...  0.659323  0.553139  0.538424  0.426416   \n",
       "4                       0.928597  ...  0.916046  0.555504  0.945931  0.590542   \n",
       "\n",
       "   grade  avg_discomfort_count_per_prompt  avg_comfort_count_per_prompt   \n",
       "0   48.0                         0.571429                      0.000000  \\\n",
       "1   99.0                         0.000000                      0.000000   \n",
       "2   90.0                         0.888889                      0.111111   \n",
       "3   97.0                         0.150000                      0.000000   \n",
       "4  100.0                         0.186047                      0.011628   \n",
       "\n",
       "   avg_example_words_count_per_prompt  avg_parentheses_count_per_prompt   \n",
       "0                            0.142857                          1.000000  \\\n",
       "1                            0.000000                          3.611111   \n",
       "2                            0.000000                         11.111111   \n",
       "3                            0.000000                          0.600000   \n",
       "4                            0.023256                          3.151163   \n",
       "\n",
       "   avg_english_conjunctions_count_per_prompts  \n",
       "0                                    2.285714  \n",
       "1                                    0.555556  \n",
       "2                                    1.444444  \n",
       "3                                    0.300000  \n",
       "4                                    0.686047  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"final_df length: \",len(final_df))\n",
    "print(\"final_df shape: \", final_df.shape)\n",
    "print(\"column names: \", final_df.columns)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW ITS TIME FOR FEATURE ELIMINATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop(['grade','code'], axis=1)\n",
    "y = final_df['grade']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION METHOD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user_prompts: 0.1896487360285515\n",
      "Q5: 0.15330566724509082\n",
      "Q6: 0.17103750227666437\n",
      "Q7: 0.17630391941924742\n",
      "average_word_count_per_sentence: -0.25799434101254387\n",
      "avg_english_conjunctions_count_per_prompts: -0.2555532902441094\n",
      "prompt_avg_words: -0.2227621637016801\n",
      "response_avg_words: -0.15739381478450687\n",
      "similarity_between_fullpoints: 0.22090334639171993\n",
      "similarity_between_prompts: 0.2242246425441813\n",
      "#user_prompts\n",
      "Q5\n",
      "Q6\n",
      "Q7\n",
      "average_word_count_per_sentence\n",
      "avg_english_conjunctions_count_per_prompts\n",
      "prompt_avg_words\n",
      "response_avg_words\n",
      "similarity_between_fullpoints\n",
      "similarity_between_prompts\n"
     ]
    }
   ],
   "source": [
    "# Set a correlation threshold (e.g., 0.2)\n",
    "correlation_threshold = 0.15\n",
    "\n",
    "# Filter out features with correlation coefficients below the threshold\n",
    "significant_correlations = correlation_matrix[abs(correlation_matrix) >= correlation_threshold]\n",
    "\n",
    "# Print out individual correlation coefficients\n",
    "for feature, correlation in significant_correlations.items():\n",
    "    print(f\"{feature}: {correlation}\")\n",
    "\n",
    "for feature in significant_correlations.keys():\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION METHOD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt_avg_words', 'response_avg_words',\n",
      "       'response_confusion_total_count', 'similarity_between_fullpoints',\n",
      "       'average_word_count_per_sentence', 'average_word_length', 'Q3', 'Q4',\n",
      "       'Q5', 'Q8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming X and y are your feature and target datasets\n",
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=10)  # Adjust the number of features as needed\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "# Selected features\n",
    "selected_features = X.columns[fit.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE SELECTION METHOD 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mutual_info_classif\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming X and y are your feature and target datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mutual_info_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmutual_info_classif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Select top k features based on mutual information scores\u001b[39;00m\n\u001b[0;32m      7\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m  \u001b[38;5;66;03m# Adjust k as needed\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:467\u001b[0m, in \u001b[0;36mmutual_info_classif\u001b[1;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmutual_info_classif\u001b[39m(\n\u001b[0;32m    392\u001b[0m     X, y, \u001b[38;5;241m*\u001b[39m, discrete_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    393\u001b[0m ):\n\u001b[0;32m    394\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    Mutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m           of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _estimate_mi(X, y, discrete_features, \u001b[38;5;28;01mTrue\u001b[39;00m, n_neighbors, copy, random_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py:218\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    210\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    217\u001b[0m ]:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Assuming X and y are your feature and target datasets\n",
    "mutual_info_scores = mutual_info_classif(X, y, discrete_features=False)\n",
    "\n",
    "# Select top k features based on mutual information scores\n",
    "k = 10  # Adjust k as needed\n",
    "selected_features = X.columns[np.argsort(mutual_info_scores)[-k:]]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 100\n",
      "Test set size: 26\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting and Analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=0,criterion='squared_error', max_depth=10)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 has MSE 162.16591798948502\n",
      "Node 1 has MSE 103.80359156455597\n",
      "Node 2 has MSE 65.92542640729152\n",
      "Node 3 has MSE 147.05555555555657\n",
      "Node 4 has MSE 56.743801652894035\n",
      "Node 5 has MSE 33.25\n",
      "Node 6 has MSE 0.0\n",
      "Node 7 has MSE 4.222222222222626\n",
      "Node 8 has MSE 0.0\n",
      "Node 9 has MSE 1.0\n",
      "Node 10 has MSE 0.0\n",
      "Node 11 has MSE 0.0\n",
      "Node 12 has MSE 15.918367346939704\n",
      "Node 13 has MSE 0.25\n",
      "Node 14 has MSE 0.0\n",
      "Node 15 has MSE 0.0\n",
      "Node 16 has MSE 6.959999999999127\n",
      "Node 17 has MSE 0.0\n",
      "Node 18 has MSE 2.888888888886868\n",
      "Node 19 has MSE 0.0\n",
      "Node 20 has MSE 0.25\n",
      "Node 21 has MSE 0.0\n",
      "Node 22 has MSE 0.0\n",
      "Node 23 has MSE 0.0\n",
      "Node 24 has MSE 39.47803234818639\n",
      "Node 25 has MSE 79.34693877551126\n",
      "Node 26 has MSE 20.5\n",
      "Node 27 has MSE 0.25\n",
      "Node 28 has MSE 0.0\n",
      "Node 29 has MSE 0.0\n",
      "Node 30 has MSE 0.25\n",
      "Node 31 has MSE 0.0\n",
      "Node 32 has MSE 0.0\n",
      "Node 33 has MSE 34.888888888889596\n",
      "Node 34 has MSE 0.25\n",
      "Node 35 has MSE 0.0\n",
      "Node 36 has MSE 0.0\n",
      "Node 37 has MSE 0.0\n",
      "Node 38 has MSE 31.57158089267432\n",
      "Node 39 has MSE 46.489795918366326\n",
      "Node 40 has MSE 15.040000000000873\n",
      "Node 41 has MSE 0.0\n",
      "Node 42 has MSE 5.1875\n",
      "Node 43 has MSE 0.0\n",
      "Node 44 has MSE 0.25\n",
      "Node 45 has MSE 0.0\n",
      "Node 46 has MSE 0.0\n",
      "Node 47 has MSE 6.25\n",
      "Node 48 has MSE 0.0\n",
      "Node 49 has MSE 0.0\n",
      "Node 50 has MSE 25.247914500510888\n",
      "Node 51 has MSE 22.574968749424443\n",
      "Node 52 has MSE 40.328888888889196\n",
      "Node 53 has MSE 42.805555555556566\n",
      "Node 54 has MSE 12.25\n",
      "Node 55 has MSE 0.0\n",
      "Node 56 has MSE 0.0\n",
      "Node 57 has MSE 14.0\n",
      "Node 58 has MSE 0.0\n",
      "Node 59 has MSE 2.66666666666697\n",
      "Node 60 has MSE 5.876543209877127\n",
      "Node 61 has MSE 0.6875\n",
      "Node 62 has MSE 0.25\n",
      "Node 63 has MSE 0.0\n",
      "Node 64 has MSE 2.0\n",
      "Node 65 has MSE 0.25\n",
      "Node 66 has MSE 0.6666666666660603\n",
      "Node 67 has MSE 15.125314186539981\n",
      "Node 68 has MSE 9.65890665155166\n",
      "Node 69 has MSE 2.0\n",
      "Node 70 has MSE 0.0\n",
      "Node 71 has MSE 0.0\n",
      "Node 72 has MSE 8.025791030770051\n",
      "Node 73 has MSE 28.5\n",
      "Node 74 has MSE 3.50593313895115\n",
      "Node 75 has MSE 18.950301450213374\n",
      "Node 76 has MSE 18.986020761247346\n",
      "Node 77 has MSE 5.029603998464154\n",
      "Node 78 has MSE 0.0\n",
      "Node 79 has MSE 8.764087988136453\n",
      "Node 80 has MSE 3.930795847751142\n",
      "Node 81 has MSE 6.222222222222626\n",
      "Node 82 has MSE 1.0\n",
      "Node 83 has MSE 0.0\n",
      "Node 84 has MSE 0.0\n",
      "Node 85 has MSE 0.0\n",
      "Node 86 has MSE -1.1641532182693481e-10\n"
     ]
    }
   ],
   "source": [
    "extracted_MSEs = regressor.tree_.impurity   \n",
    "for idx, MSE in enumerate(regressor.tree_.impurity):\n",
    "    print(\"Node {} has MSE {}\".format(idx,MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1540\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dot_data \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mexport_graphviz(regressor, out_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feature_names\u001b[38;5;241m=\u001b[39mfinal_df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mSource(dot_data)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\backend\\rendering.py:324\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mFileExistsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput file exists: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mfspath(outfile)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m--> 324\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\graphviz\\backend\\execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "# Plotting the Tree \n",
    "dot_data = tree.export_graphviz(regressor, out_file=None, feature_names=final_df.columns[1:-1])\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"hw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 3.0366629401688727\n",
      "MSE TEST: 184.90068812917733\n",
      "R2 Train: 0.981274345572627\n",
      "R2 TEST: -0.8645354830216723\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "print(\"MSE Train:\", mean_squared_error(y_train,y_train_pred))\n",
    "print(\"MSE TEST:\", mean_squared_error(y_test,y_test_pred))\n",
    "\n",
    "print(\"R2 Train:\", r2_score(y_train,y_train_pred))\n",
    "print(\"R2 TEST:\", r2_score(y_test,y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HASAN FIRAT YILMAZ ---> NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (100, 10)\n",
      "Shape of X_test: (26, 10)\n",
      "Shape of y_train: (100,)\n",
      "Shape of y_test: (26,)\n"
     ]
    }
   ],
   "source": [
    "# Extract selected features from the DataFrame\n",
    "X = final_df[significant_correlations.keys()].values\n",
    "\n",
    "# Assuming 'grade' is the target variable\n",
    "y = final_df['grade'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_75 (Dense)            (None, 64)                704       \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2817 (11.00 KB)\n",
      "Trainable params: 2817 (11.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 39ms/step - loss: 7874.8232 - mae: 87.7979 - val_loss: 5840.8389 - val_mae: 75.7023\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5057.7842 - mae: 70.0085 - val_loss: 3233.7620 - val_mae: 55.6371\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2785.4111 - mae: 51.3297 - val_loss: 1366.8257 - val_mae: 34.7410\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1391.9637 - mae: 32.4686 - val_loss: 469.4691 - val_mae: 19.5340\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 900.1807 - mae: 20.8548 - val_loss: 376.3887 - val_mae: 15.4534\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 943.8089 - mae: 20.0974 - val_loss: 473.6714 - val_mae: 15.9518\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 924.2629 - mae: 19.6428 - val_loss: 378.0555 - val_mae: 15.1290\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 807.0779 - mae: 18.9561 - val_loss: 318.0711 - val_mae: 14.9724\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 735.6465 - mae: 18.7806 - val_loss: 307.9877 - val_mae: 14.8610\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 716.6142 - mae: 18.7562 - val_loss: 303.5010 - val_mae: 14.6471\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 693.3206 - mae: 18.4913 - val_loss: 305.0717 - val_mae: 14.4479\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 677.2188 - mae: 18.2351 - val_loss: 307.8438 - val_mae: 14.3308\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 671.8494 - mae: 18.1839 - val_loss: 310.9659 - val_mae: 14.2276\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 659.4952 - mae: 18.2059 - val_loss: 310.5005 - val_mae: 14.1636\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 647.8122 - mae: 18.2874 - val_loss: 308.8226 - val_mae: 14.1202\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 639.0034 - mae: 18.4123 - val_loss: 309.8812 - val_mae: 14.1007\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 640.1389 - mae: 18.6283 - val_loss: 313.8472 - val_mae: 14.2287\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 625.6027 - mae: 18.4421 - val_loss: 320.4436 - val_mae: 14.2194\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 621.8137 - mae: 18.3167 - val_loss: 323.3037 - val_mae: 14.2874\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 620.1179 - mae: 18.4489 - val_loss: 317.1298 - val_mae: 14.3396\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 612.7215 - mae: 18.3194 - val_loss: 323.0722 - val_mae: 14.2860\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 612.5771 - mae: 18.3095 - val_loss: 322.5698 - val_mae: 14.3905\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 602.4037 - mae: 18.1997 - val_loss: 333.3011 - val_mae: 14.4224\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 602.5114 - mae: 18.0519 - val_loss: 339.9756 - val_mae: 14.4318\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 600.5392 - mae: 17.9865 - val_loss: 332.9858 - val_mae: 14.3990\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 594.1142 - mae: 18.0538 - val_loss: 323.1344 - val_mae: 14.5752\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 594.4108 - mae: 18.3572 - val_loss: 321.8362 - val_mae: 14.6401\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 590.5328 - mae: 18.4387 - val_loss: 328.4135 - val_mae: 14.6572\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 587.4058 - mae: 18.0784 - val_loss: 342.4366 - val_mae: 14.7530\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 587.7644 - mae: 17.9093 - val_loss: 348.3530 - val_mae: 14.8297\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 581.4442 - mae: 17.8438 - val_loss: 339.2017 - val_mae: 14.7578\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 574.9334 - mae: 18.0423 - val_loss: 326.9257 - val_mae: 14.7638\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 573.0658 - mae: 18.2238 - val_loss: 326.6950 - val_mae: 14.8188\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 575.1948 - mae: 18.3064 - val_loss: 333.6960 - val_mae: 14.8418\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 570.1861 - mae: 18.0438 - val_loss: 345.1421 - val_mae: 15.0044\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 560.8975 - mae: 17.8289 - val_loss: 333.1297 - val_mae: 14.7810\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 585.9768 - mae: 18.6734 - val_loss: 361.2079 - val_mae: 15.4514\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 587.0281 - mae: 18.9124 - val_loss: 371.3517 - val_mae: 15.6985\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 562.6935 - mae: 18.4723 - val_loss: 391.0783 - val_mae: 16.1055\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 557.6175 - mae: 18.2279 - val_loss: 379.5221 - val_mae: 15.8219\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 558.8297 - mae: 18.5630 - val_loss: 385.7870 - val_mae: 15.8501\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 575.9802 - mae: 18.8259 - val_loss: 386.8921 - val_mae: 16.1216\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 551.1962 - mae: 18.4015 - val_loss: 378.2134 - val_mae: 16.0157\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 549.0198 - mae: 18.3317 - val_loss: 394.1801 - val_mae: 16.2037\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 543.5831 - mae: 17.8424 - val_loss: 368.6212 - val_mae: 15.6888\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 529.8022 - mae: 17.6932 - val_loss: 337.7365 - val_mae: 15.1068\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 536.8267 - mae: 17.8099 - val_loss: 334.8283 - val_mae: 15.0704\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 532.2084 - mae: 17.5516 - val_loss: 355.9908 - val_mae: 15.4482\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 513.8518 - mae: 17.6145 - val_loss: 357.0926 - val_mae: 15.5525\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 541.7492 - mae: 18.2573 - val_loss: 371.9068 - val_mae: 15.9994\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 514.8442 - mae: 17.8856 - val_loss: 374.4343 - val_mae: 15.9925\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 506.7487 - mae: 17.5175 - val_loss: 388.9228 - val_mae: 15.9947\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 526.6147 - mae: 17.5784 - val_loss: 354.3156 - val_mae: 15.3072\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 511.6264 - mae: 17.2424 - val_loss: 321.9367 - val_mae: 14.6668\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 504.9377 - mae: 17.0720 - val_loss: 316.1239 - val_mae: 14.4767\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 502.5632 - mae: 17.0538 - val_loss: 326.8535 - val_mae: 14.7055\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 499.4528 - mae: 17.0591 - val_loss: 321.0584 - val_mae: 14.6141\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 494.1335 - mae: 16.9766 - val_loss: 304.1432 - val_mae: 14.1585\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 490.0049 - mae: 16.8005 - val_loss: 296.0267 - val_mae: 13.9034\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 486.4941 - mae: 16.7650 - val_loss: 291.3417 - val_mae: 13.8015\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 487.5823 - mae: 16.9184 - val_loss: 287.5676 - val_mae: 13.8254\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 481.2456 - mae: 16.7667 - val_loss: 295.1154 - val_mae: 13.6462\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 476.1669 - mae: 16.7198 - val_loss: 304.3336 - val_mae: 13.6909\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 478.6073 - mae: 16.7103 - val_loss: 294.0975 - val_mae: 13.5265\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 470.9247 - mae: 16.6317 - val_loss: 287.2789 - val_mae: 13.4693\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 468.2620 - mae: 16.4804 - val_loss: 278.9360 - val_mae: 13.3316\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 472.2574 - mae: 16.5150 - val_loss: 271.1137 - val_mae: 13.3243\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 460.1298 - mae: 16.2359 - val_loss: 276.0758 - val_mae: 13.1493\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 459.2374 - mae: 16.3589 - val_loss: 274.8947 - val_mae: 13.1632\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 459.3789 - mae: 16.4514 - val_loss: 275.8401 - val_mae: 13.1282\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 452.9176 - mae: 16.3714 - val_loss: 266.6311 - val_mae: 13.2191\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 476.8532 - mae: 16.9398 - val_loss: 289.5496 - val_mae: 13.7289\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 461.1927 - mae: 16.6886 - val_loss: 309.0604 - val_mae: 13.8741\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 457.3046 - mae: 16.7523 - val_loss: 311.5349 - val_mae: 13.9514\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 450.6730 - mae: 16.7059 - val_loss: 294.3322 - val_mae: 13.6353\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 451.9964 - mae: 16.6360 - val_loss: 314.2520 - val_mae: 13.4432\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 438.5314 - mae: 16.3932 - val_loss: 270.9176 - val_mae: 13.0685\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 433.4013 - mae: 16.0497 - val_loss: 270.3766 - val_mae: 12.9478\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 425.0972 - mae: 15.9819 - val_loss: 289.4677 - val_mae: 12.8244\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 428.0236 - mae: 16.1583 - val_loss: 287.8459 - val_mae: 12.7642\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 432.8158 - mae: 16.0837 - val_loss: 267.4184 - val_mae: 12.9596\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 417.7672 - mae: 15.8860 - val_loss: 272.6642 - val_mae: 12.7085\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 410.3365 - mae: 15.6917 - val_loss: 282.0988 - val_mae: 12.5320\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 414.9417 - mae: 15.8432 - val_loss: 268.2822 - val_mae: 12.3734\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 406.7971 - mae: 15.5570 - val_loss: 257.8791 - val_mae: 12.3915\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 403.0087 - mae: 15.4321 - val_loss: 256.8531 - val_mae: 12.2892\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 409.1962 - mae: 15.6209 - val_loss: 279.7978 - val_mae: 12.4749\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 397.4736 - mae: 15.3703 - val_loss: 251.9304 - val_mae: 12.2788\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 392.4568 - mae: 15.2651 - val_loss: 254.8432 - val_mae: 12.2181\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 388.3496 - mae: 15.1724 - val_loss: 256.3559 - val_mae: 12.1611\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 385.7999 - mae: 15.1425 - val_loss: 261.9980 - val_mae: 12.0965\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 383.7991 - mae: 15.1542 - val_loss: 260.8179 - val_mae: 11.9594\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 387.4324 - mae: 15.1491 - val_loss: 256.4716 - val_mae: 12.0836\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 380.4804 - mae: 15.0699 - val_loss: 266.8370 - val_mae: 11.9484\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 387.3294 - mae: 15.2777 - val_loss: 261.5716 - val_mae: 11.9333\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 378.4089 - mae: 14.9128 - val_loss: 255.5284 - val_mae: 12.0011\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 372.9002 - mae: 14.9237 - val_loss: 269.6763 - val_mae: 12.1724\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 371.6897 - mae: 15.0177 - val_loss: 253.2802 - val_mae: 12.0268\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 372.9530 - mae: 14.9833 - val_loss: 251.2195 - val_mae: 12.0647\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 370.8116 - mae: 14.8126 - val_loss: 268.1460 - val_mae: 12.2796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x228544ea410>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(len(significant_correlations),)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "Mean Squared Error on Clipped Predictions: 192.1741820541882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Clip predictions to the range [0, 100]\n",
    "predictions_clipped = np.clip(predictions, 0, 100)\n",
    "\n",
    "# Calculate MSE on clipped predictions\n",
    "mse_clipped = mean_squared_error(y_test, predictions_clipped)\n",
    "\n",
    "print(f'Mean Squared Error on Clipped Predictions: {mse_clipped}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF YOU ARE NOT MERT, IGNORE THIS\n",
    "\n",
    "## FINALLY LETS ADD 1 MORE FEATURE ABOUT CHATGPT CODE RESPONSE\n",
    "\n",
    "#### FROM THE GIVEN CODE ANSWERS, WE SELECT THE STUDENTS WHO RECEIVE 100 AND ARE CLOSEST TO EACH OTHER. THEN LET'S MEASURE THE SIMILAR  CODES OF EACH STUDENT TO THESE STUDENTS' CODES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity1(code_dict):\n",
    "    # Extract code values from the dictionary\n",
    "    code_values = list(code_dict.values())\n",
    "\n",
    "    # Use TfidfVectorizer to convert code values into TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(code_values)\n",
    "\n",
    "    # Calculate cosine similarity between the TF-IDF vectors\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Create a dictionary to store similarities\n",
    "    similarity_dict = {}\n",
    "    names = list(code_dict.keys())\n",
    "\n",
    "    # Fill the similarity dictionary\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            pair = f\"{names[i]} - {names[j]}\"\n",
    "            similarity_dict[pair] = similarity_matrix[i, j]\n",
    "\n",
    "    return similarity_dict\n",
    "\n",
    "# Example usage\n",
    "similarity_dict1 = calculate_similarity1(code_dict)\n",
    "\n",
    "# Print the similarity values\n",
    "for pair, similarity in similarity_dict1.items():\n",
    "    print(f\"Similarity between {pair}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_students = scores[scores[\"grade\"] == 100]\n",
    "\n",
    "# Eğer birden fazla varsa, tüm öğrencilerin kodlarını bir liste olarak alabilirsiniz\n",
    "top_students_codes = top_students[\"code\"].tolist()\n",
    "\n",
    "max_similiars = []\n",
    "\n",
    "for pair, similarity in similarity_dict1.items():\n",
    "    if similarity >= 0.1:\n",
    "        #max_similiars.append(pair)\n",
    "        element1, element2 = pair.split(\" - \")\n",
    "        if element1 in top_students_codes and element2 in top_students_codes:\n",
    "            max_similiars.append(element1)\n",
    "            max_similiars.append(element2)\n",
    "    \n",
    "max_similiars = list(set(max_similiars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_similarities = {}\n",
    "\n",
    "print(average_similarities)\n",
    "\n",
    "for code in scores[\"code\"]:\n",
    "    points = []\n",
    "    for best in max_similiars:\n",
    "        if code != best:\n",
    "            pair1 = code + \" - \" + best\n",
    "            pair2 = best + \" - \" + code\n",
    "            if pair1 in similarity_dict1:\n",
    "                #print(\"p1 \" + str(similarity_dict1[pair1]))\n",
    "                points.append(similarity_dict1[pair1])\n",
    "            elif pair2 in similarity_dict1:\n",
    "                #print(\"p2 \" + str(similarity_dict1[pair2]))\n",
    "                points.append(similarity_dict1[pair2])\n",
    "    if len(points) != 0:\n",
    "        avg = sum(points) / len(points)\n",
    "    else:\n",
    "        avg = 0\n",
    "        print(code)\n",
    "    average_similarities[code] = avg\n",
    "    \n",
    "\n",
    "print(average_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values[0] = 'user_id'\n",
    "\n",
    "df['code_similarity_compare2_bestgrades'] = df['new_column_name'].map(average_similarities)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
